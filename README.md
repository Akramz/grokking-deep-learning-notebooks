# Grokking Deep Learning by Andrew W. Trask

> https://www.manning.com/books/grokking-deep-learning

<div style="text-align:center"><img style="width:100%" src="static/imgs/Cover.png"></div>

This repo is home to notes & the code that accompanies Andrew W. Trask's "Grokking Deep Learning" book. It provides a solid foundation in deep learning so that you can master any major deep learning framework.

The book requires no math background beyond basic arithmetic. It doesn't rely on a high-level library that might hide what's going on. Anyone can read the book and understand how deep learning really works. You won't just read the theory, you'll discover it yourself.
    
> (You can Buy the Book from [Manning Publications](https: //www.manning.com/books/grokking-deep-learning) or [Amazon](https://www.amazon.com/Grokking-Deep-Learning-Andrew-Trask/dp/1617293709)).

# Roadmap

"Grokking Deep Learning" has 16 chapters. We provide links for the available notebooks:

1. Introducing Deep Learning: Why you should Learn It?
2. fundamental Concepts: How Do Machines Learn?
3. [Introduction to Neural Learning](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/03.forward_propagation.ipynb): Forward Propagation
4. [Introduction to Neural Learning](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/04.gradient_descent.ipynb): Gradient Descent
5. [Learning Multiple Weights at a Time](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/05.Generalizing_GD.ipynb): Generalizing Gradient Descent
6. [Building your first deep neural network](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/06.Back_propagation.ipynb): Introduction to Backpropagation
7. How to Picture Neural Networks: In your Head & on Paper
8. [Learning Signal & Ignoring Noise](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/08.Regularization_Batching.ipynb): Introduction to Regularization & Batching
9. [Modeling Probabilities & Non-Linearities](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/09.Probabilities_Non-Linearities.ipynb): Activation Functions
10. [Neural Learning about Edges & Corners](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/10.Intro_to_CNNs.ipynb): Introduction to Convolutional Neural Networks
11. [Neural Networks that Understand Language](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/11.NNs_that_Understand_Language.ipynb): King - Man + Woman == ?
12. [Neural Networks that write like Shakespeare](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/12.RNNs.ipynb): Recurrent Layers for Variable Length Data
13. [Introducing Automatic Optimization](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/13.DL_framework.ipynb): Let's build a deep learning framework
14. [Learning to Write like Shakespeare](https://nbviewer.jupyter.org/github/Akramz/grokking-deep-learning-notebooks/blob/master/14.LSTMs_LM.ipynb): Long Short-term Memory
15. Deep Learning on Unseen Data: Introducing Federated Learning
16. Where to Go from Here: A brief Guide

> Hidden Notebooks are mostly based on original content from the book.

---
