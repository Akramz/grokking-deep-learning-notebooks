---

title: Building your first Deep Neural Network: Introduction to Backpropagation
keywords: fastai
sidebar: home_sidebar


---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 06.Back_propagation.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this Chapter:</p>
<ul>
<li>The Streetlight Problem.</li>
<li>Matrices and the Matrix relationship.</li>
<li>Full, Batch, and Stochastic Gradient Descent.</li>
<li>Neural Networks learn Correlation.</li>
<li>Overfitting.</li>
<li>Creating your Own correlation.</li>
<li>Backpropagation: Long-distance error attribution.</li>
<li>Linear versus Non-Lienar.</li>
<li>The Secret to Sometimes Correlation.</li>
<li>Your first Deep Network.</li>
<li>Backpropagation in Code: Bringing it all together.</li>
</ul>
<blockquote><p><em>"O Deep Thought Computer," he Said, "The task we have designed you to perform is this. We want you to tell us..." he paused. "The Answer"</em> - Douglas Adams, The Hitchhiker's Guide to the Galaxy</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Streetlight-Problem">The Streetlight Problem<a class="anchor-link" href="#The-Streetlight-Problem">&#182;</a></h2><h3 id="This-toy-problem-considers-how-a-network-learn-entire-datasets">This toy problem considers how a network learn entire datasets<a class="anchor-link" href="#This-toy-problem-considers-how-a-network-learn-entire-datasets">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:33%" file="static/imgs/06/streetlight_data.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preparing-the-Data">Preparing the Data<a class="anchor-link" href="#Preparing-the-Data">&#182;</a></h2><h3 id="Neural-Networks-Don't-Read-Sreetlights">Neural Networks Don't Read Sreetlights<a class="anchor-link" href="#Neural-Networks-Don't-Read-Sreetlights">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>You have two datasets<ul>
<li>On the one hand, you have six streetlight states.</li>
<li>On the other hand, you have six observations of whether people walked.</li>
</ul>
</li>
<li>To Prepare this data for the neural network, you have to first split it into two groups<ul>
<li>What you know</li>
<li>What you want to know</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Matrices-&amp;-the-Matrix-Relationship">Matrices &amp; the Matrix Relationship<a class="anchor-link" href="#Matrices-&amp;-the-Matrix-Relationship">&#182;</a></h2><h3 id="translate-the-Streelight-into-math">translate the Streelight into math<a class="anchor-link" href="#translate-the-Streelight-into-math">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:33%" file="static/imgs/06/symbols-to-numbers.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Good-Data-Matrices-perfectly-mimic-the-outside-world">Good Data Matrices perfectly mimic the outside world<a class="anchor-link" href="#Good-Data-Matrices-perfectly-mimic-the-outside-world">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The data matrix doesn't have to be all 1s and 0s.</li>
<li>A Matrix should mimic the patterns that exist in the real world.<ul>
<li>So you can ask the computer to mimic them.</li>
</ul>
</li>
<li>An infinite number of matrices exist that perfectly reflect the streetlight patterns in the dataset.</li>
<li>The underlying pattern isn't the same as the matrix.<ul>
<li><strong>It's a Property of the Matrix</strong>.</li>
<li><strong>the Pattern is what the matrix is expressing.</strong></li>
<li>The Pattern also existed in the streetlights.</li>
</ul>
</li>
<li>the Resulting Matrix is called a <strong>Lossless Representation</strong> <ul>
<li>because you can perfectly convert back and forth between your stop/walk notes and the matrix.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creating-a-Matrix-or-Two-in-Python">Creating a Matrix or Two in Python<a class="anchor-link" href="#Creating-a-Matrix-or-Two-in-Python">&#182;</a></h2><h3 id="Import-the-Matrices-into-Python">Import the Matrices into Python<a class="anchor-link" href="#Import-the-Matrices-into-Python">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Let's Create the Streetlight pattern matrix</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">streetlights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>What is NumPy ?<ul>
<li>Numpy is really just a fancy wrapper for an array of arrays that provides special, matrix-oriented functions.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">walk_vs_stop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-a-Neural-Network">Building a Neural Network<a class="anchor-link" href="#Building-a-Neural-Network">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># I will attempt to build it.</span>
<span class="n">ws</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">streetlights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">x_i</span> <span class="o">=</span> <span class="n">streetlights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y_i</span> <span class="o">=</span> <span class="n">walk_vs_stop</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">lr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>

<span class="k">for</span> <span class="n">interation</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="c1"># predict.</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">x_i</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ws</span><span class="p">)</span>
    <span class="c1"># MSE error.</span>
    <span class="n">error</span> <span class="o">=</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">y_i</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="c1"># update weights.</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ws</span><span class="p">)):</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">y_i</span><span class="p">)</span>
        <span class="n">ws</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">gradient</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction : &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; Reality : &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">y_i</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot; Error : &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Prediction : 0.9104498947095488 Reality : 0 Error : 0.8289190107766286
Prediction : 0.5462699368257292 Reality : 0 Error : 0.2984108438795862
Prediction : 0.3277619620954375 Reality : 0 Error : 0.10742790379665101
Prediction : 0.1966571772572625 Reality : 0 Error : 0.03867404536679436
Prediction : 0.11799430635435748 Reality : 0 Error : 0.013922656332045966
Prediction : 0.07079658381261444 Reality : 0 Error : 0.005012156279536542
Prediction : 0.04247795028756862 Reality : 0 Error : 0.0018043762606331512
Prediction : 0.025486770172541195 Reality : 0 Error : 0.0006495754538279355
Prediction : 0.01529206210352474 Reality : 0 Error : 0.00023384716337805747
Prediction : 0.009175237262114888 Reality : 0 Error : 8.418497881610151e-05
Prediction : 0.005505142357268955 Reality : 0 Error : 3.030659237379679e-05
Prediction : 0.0033030854143614174 Reality : 0 Error : 1.0910373254567137e-05
Prediction : 0.0019818512486168283 Reality : 0 Error : 3.927734371644081e-06
Prediction : 0.0011891107491700526 Reality : 0 Error : 1.4139843737917637e-06
Prediction : 0.0007134664495019871 Reality : 0 Error : 5.090343745649715e-07
Prediction : 0.00042807986970117007 Reality : 0 Error : 1.8325237484337073e-07
Prediction : 0.00025684792182067984 Reality : 0 Error : 6.597085494360206e-08
Prediction : 0.0001541087530924079 Reality : 0 Error : 2.3749507779696742e-08
Prediction : 9.246525185546695e-05 Reality : 0 Error : 8.549822800694933e-09
Prediction : 5.547915111325796e-05 Reality : 0 Error : 3.0779362082477123e-09
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Book Implementation.</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">48</span><span class="p">,</span> <span class="o">-.</span><span class="mi">7</span><span class="p">])</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">streetlights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">goal_prediction</span> <span class="o">=</span> <span class="n">walk_vs_stop</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">error</span> <span class="o">=</span> <span class="p">(</span><span class="n">goal_prediction</span> <span class="o">-</span> <span class="n">prediction</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">-</span> <span class="n">goal_prediction</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="nb">input</span> <span class="o">*</span> <span class="n">delta</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; Prediction: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">prediction</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Error:[0.04] Prediction: -0.19999999999999996
Error:[0.0256] Prediction: -0.15999999999999992
Error:[0.016384] Prediction: -0.1279999999999999
Error:[0.01048576] Prediction: -0.10239999999999982
Error:[0.00671089] Prediction: -0.08191999999999977
Error:[0.00429497] Prediction: -0.06553599999999982
Error:[0.00274878] Prediction: -0.05242879999999994
Error:[0.00175922] Prediction: -0.04194304000000004
Error:[0.0011259] Prediction: -0.03355443200000008
Error:[0.00072058] Prediction: -0.02684354560000002
Error:[0.00046117] Prediction: -0.021474836479999926
Error:[0.00029515] Prediction: -0.01717986918399994
Error:[0.00018889] Prediction: -0.013743895347199997
Error:[0.00012089] Prediction: -0.010995116277759953
Error:[7.73712525e-05] Prediction: -0.008796093022207963
Error:[4.95176016e-05] Prediction: -0.007036874417766459
Error:[3.1691265e-05] Prediction: -0.0056294995342132115
Error:[2.02824096e-05] Prediction: -0.004503599627370569
Error:[1.29807421e-05] Prediction: -0.003602879701896544
Error:[8.30767497e-06] Prediction: -0.002882303761517324
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-the-Whole-Dataset">Learning the Whole Dataset<a class="anchor-link" href="#Learning-the-Whole-Dataset">&#182;</a></h2><h3 id="The-Neural-Network-has-been-learning-only-one-streetlight.-Don't-we-want-it-to-learn-them-all?">The Neural Network has been learning only one streetlight. Don't we want it to learn them all?<a class="anchor-link" href="#The-Neural-Network-has-been-learning-only-one-streetlight.-Don't-we-want-it-to-learn-them-all?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Thus far, you've trained neural networks that learned how to model a single training example. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># let&#39;s generalize the algorithm ourselves.</span>
<span class="c1"># I will attempt to build it.</span>
<span class="n">ws</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">streetlights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">lr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">epoches</span> <span class="o">=</span> <span class="mi">7</span>

<span class="k">for</span> <span class="n">interation</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoches</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">streetlights</span><span class="p">)):</span>
        <span class="c1"># predict.</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">streetlights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ws</span><span class="p">)</span>
        <span class="c1"># MSE error.</span>
        <span class="n">error</span> <span class="o">=</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">walk_vs_stop</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="c1"># update weights.</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ws</span><span class="p">)):</span>
            <span class="n">gradient</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">streetlights</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">walk_vs_stop</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">ws</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">gradient</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction : &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; Reality : &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">walk_vs_stop</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot; Error : &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Prediction : 1.115349567974397 Reality : 0 Error : 1.2440046587806741
Prediction : 1.3518921380661582 Reality : 1 Error : 0.12382807683277211
Prediction : 0.5656721671456411 Reality : 0 Error : 0.3199850006832461
Prediction : 1.1311599954363323 Reality : 1 Error : 0.017202944402858703
Prediction : 1.0455368512360337 Reality : 1 Error : 0.0020736048204926623
Prediction : 0.42412551132053866 Reality : 0 Error : 0.17988244935290837
Prediction : 0.2544753067923232 Reality : 0 Error : 0.06475768176704702
Prediction : 0.8916019471190477 Reality : 1 Error : 0.011750137868381727
Prediction : 0.30315781133565767 Reality : 0 Error : 0.09190465857382621
Prediction : 0.7455365893202238 Reality : 1 Error : 0.06475162737478443
Prediction : 0.9761149702762076 Reality : 1 Error : 0.0005704946449064446
Prediction : 0.22029560260112177 Reality : 0 Error : 0.04853015252539137
Prediction : 0.13217736156067306 Reality : 0 Error : 0.017470854909140892
Prediction : 0.9151743893333657 Reality : 1 Error : 0.007195384224967422
Prediction : 0.24466646645020773 Reality : 0 Error : 0.059861679805230626
Prediction : 0.7517764129295008 Reality : 1 Error : 0.06161494917814569
Prediction : 0.9994607751381775 Reality : 1 Error : 2.9076345160744196e-07
Prediction : 0.14673552558025332 Reality : 0 Error : 0.021531314467313177
Prediction : 0.08804131534815196 Reality : 0 Error : 0.007751273208232738
Prediction : 0.9527210968972254 Reality : 1 Error : 0.00223529467860155
Prediction : 0.20798614798150436 Reality : 0 Error : 0.04325823775218423
Prediction : 0.784329850389976 Reality : 1 Error : 0.046513613432810116
Prediction : 1.016303488386044 Reality : 1 Error : 0.00026580373355387184
Prediction : 0.10369070239994599 Reality : 0 Error : 0.010751761764194165
Prediction : 0.06221442143996758 Reality : 0 Error : 0.003870634235109898
Prediction : 0.9766010682636437 Reality : 1 Error : 0.000547510006402663
Prediction : 0.17776101220928803 Reality : 0 Error : 0.031598977461670646
Prediction : 0.8146558655182924 Reality : 1 Error : 0.03435244818677332
Prediction : 1.0245460923090115 Reality : 1 Error : 0.0006025106476425136
Prediction : 0.07568467210027496 Reality : 0 Error : 0.00572816959092614
Prediction : 0.045410803260164986 Reality : 0 Error : 0.002062141052733411
Prediction : 0.990508560313319 Reality : 1 Error : 9.008742732590274e-05
Prediction : 0.15204761106721787 Reality : 0 Error : 0.023118476031247955
Prediction : 0.8409927728007651 Reality : 1 Error : 0.0252832983015891
Prediction : 1.0274985048542418 Reality : 1 Error : 0.0007561677692187581
Prediction : 0.05683843758883725 Reality : 0 Error : 0.0032306079875401472
Prediction : 0.03410306255330234 Reality : 0 Error : 0.0011630188755144522
Prediction : 0.9983108028841172 Reality : 1 Error : 2.8533868963066987e-06
Prediction : 0.13008937271752158 Reality : 0 Error : 0.016923244894038247
Prediction : 0.8636789114246024 Reality : 1 Error : 0.0185834391903814
Prediction : 1.027497042617125 Reality : 1 Error : 0.0007560873526879909
Prediction : 0.04381082931838769 Reality : 0 Error : 0.001919388765564898
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># our final weights predictions. Compared with ground truths</span>
<span class="p">[</span><span class="n">ws</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">streetlight</span><span class="p">)</span> <span class="k">for</span> <span class="n">streetlight</span> <span class="ow">in</span> <span class="n">streetlights</span><span class="p">],</span> <span class="n">streetlights</span><span class="p">,</span> <span class="n">walk_vs_stop</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>([0.026286497591032618,
  1.0077360597065974,
  0.11707414150199424,
  0.9169484157956358,
  1.0077360597065974,
  0.026286497591032618],
 array([[1, 0, 1],
        [0, 1, 1],
        [0, 0, 1],
        [1, 1, 1],
        [0, 1, 1],
        [1, 0, 1]]),
 array([[0],
        [1],
        [0],
        [1],
        [1],
        [0]]))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Book Implementation.</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">48</span><span class="p">,</span> <span class="o">-.</span><span class="mi">7</span><span class="p">])</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">error_for_all_lights</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">row_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">walk_vs_stop</span><span class="p">)):</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">streetlights</span><span class="p">[</span><span class="n">row_index</span><span class="p">]</span>
        <span class="n">goal_prediction</span> <span class="o">=</span> <span class="n">walk_vs_stop</span><span class="p">[</span><span class="n">row_index</span><span class="p">]</span>
        
        <span class="n">prediction</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        
        <span class="n">error</span> <span class="o">=</span> <span class="p">(</span><span class="n">goal_prediction</span> <span class="o">-</span> <span class="n">prediction</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">error_for_all_lights</span> <span class="o">+=</span> <span class="n">error</span>
        
        <span class="n">delta</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">-</span> <span class="n">goal_prediction</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="nb">input</span> <span class="o">*</span> <span class="n">delta</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">error_for_all_lights</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Error:[2.65612311]
Error:[0.96287018]
Error:[0.55091659]
Error:[0.36445837]
Error:[0.25167687]
Error:[0.17797575]
Error:[0.12864461]
Error:[0.09511037]
Error:[0.07194564]
Error:[0.05564915]
Error:[0.04394764]
Error:[0.03535797]
Error:[0.028907]
Error:[0.02395166]
Error:[0.02006311]
Error:[0.01695209]
Error:[0.01442082]
Error:[0.01233174]
Error:[0.01058739]
Error:[0.00911723]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Full,-Batch,-and-Stochastic-Gradient-Descent">Full, Batch, and Stochastic Gradient Descent<a class="anchor-link" href="#Full,-Batch,-and-Stochastic-Gradient-Descent">&#182;</a></h2><h3 id="Stochastic-Gradient-Descent-updates-weights-one-example-at-a-time">Stochastic Gradient Descent updates weights one example at a time<a class="anchor-link" href="#Stochastic-Gradient-Descent-updates-weights-one-example-at-a-time">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>This Idea of learning one example at a time is called <strong>Stochastic Gradient Descent</strong>.<ul>
<li>It performs a prediction and weight update for each training example separately.</li>
<li>It iterates through the entire dataset many times until it can find a weight configuration that works well for the entire dataset.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(Full)-Gradient-Descent-updates-weights-one-dataset-at-a-time">(Full) Gradient Descent updates weights one dataset at a time<a class="anchor-link" href="#(Full)-Gradient-Descent-updates-weights-one-dataset-at-a-time">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Instead of updating the weights once for each training example, the weight calculates the loss over the entire dataset.<ul>
<li>Changing the weights only each time it computes a full average.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Batch-Gradient-Descent-updates-weights-taking-in-n-examples">Batch Gradient Descent updates weights taking in n examples<a class="anchor-link" href="#Batch-Gradient-Descent-updates-weights-taking-in-n-examples">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Instead of updating the weights using one example or after the entire dataset of examples, you choose a batch size (typically between 8 and 256).<ul>
<li>After which the weights are updated.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Networks-Learn-Correlation">Neural Networks Learn Correlation<a class="anchor-link" href="#Neural-Networks-Learn-Correlation">&#182;</a></h2><h3 id="What-did-the-last-neural-network-learn?">What did the last neural network learn?<a class="anchor-link" href="#What-did-the-last-neural-network-learn?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The correlation is located wherever the weights were set to high numbers.</li>
<li>Inversely, randomness with respect to the input is found wherever the weights converge to 0.</li>
<li>How did the network Identify Correlation?<ul>
<li>In the Process of Gradient Descent, each training example asserts either <em>up pressure</em> or <em>down pressure</em> on the weights.</li>
<li>On average, there was more <em>up pressure</em> for the middle weight and more <em>down pressure</em> for the other two.</li>
<li>Where does the pressure come from?</li>
<li>Why is it different for different weights?</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Up-and-Down-Pressue">Up and Down Pressue<a class="anchor-link" href="#Up-and-Down-Pressue">&#182;</a></h2><h3 id="It-comes-from-the-Data">It comes from the Data<a class="anchor-link" href="#It-comes-from-the-Data">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%" file="static/imgs/06/weight_update.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Edge-Case:-Overfitting">Edge Case: Overfitting<a class="anchor-link" href="#Edge-Case:-Overfitting">&#182;</a></h2><h3 id="Sometimes-Correlation-happens-accidentally">Sometimes Correlation happens accidentally<a class="anchor-link" href="#Sometimes-Correlation-happens-accidentally">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Error is shared among all of the weigths</li>
<li>If a particular configuration of weights accidentally creates perfect correlation between the prediction and the output dataset<ul>
<li><strong>The Neural Network will stop Learning</strong></li>
</ul>
</li>
<li>In essence, <strong>It memorized</strong> the two training examples instead of finding the correlation that will generalize to any possible streetlight configuration.</li>
<li>The greatest challenge you'll face with deep learning is convincing your neural network to <strong>generalize</strong> instead of just <strong>memorize</strong>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Edge-Case:-Conflicting-Pressure">Edge Case: Conflicting Pressure<a class="anchor-link" href="#Edge-Case:-Conflicting-Pressure">&#182;</a></h2><h3 id="Sometimes-correlation-fights-itself">Sometimes correlation fights itself<a class="anchor-link" href="#Sometimes-correlation-fights-itself">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>As other nodes learn, they absorb some of the error; they absorb part of the correlation.</li>
<li>This causes the network to predict with moderate correlative power, which reduces the error.</li>
<li>the other weights then only try to adjust their weights to correctly predict what's left.</li>
<li><strong>Regularization</strong> forces weights with conflicting pressure to move toward 0.</li>
<li>Regularization aims to say that only weights with really strong correlation can stay on.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%" file="static/imgs/06/latent_correlation.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-Indirect-Correlation">Learning Indirect Correlation<a class="anchor-link" href="#Learning-Indirect-Correlation">&#182;</a></h2><h3 id="If-your-Data-doesn't-have-correlation,-create-intermediate-data-that-does!">If your Data doesn't have correlation, create intermediate data that does!<a class="anchor-link" href="#If-your-Data-doesn't-have-correlation,-create-intermediate-data-that-does!">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Neural networks search for correlation between their input and output <strong>layers</strong>.</li>
<li>Because the Input dataset doesn't correlate with the output dataset, you'll use the input dataset to create an intermediate dataset that does have correlation with the output.<ul>
<li>It's kind of like <strong>cheating</strong>.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%" file="static/imgs/06/hidden-layer.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>the middle layer represents the intermediate dataset.</li>
<li><strong>this network is still just a function</strong><ul>
<li>It has a bunch of weights that are collected together in a particular way.</li>
<li>Gradient Descent still works because you can calculate how much each weight contributes to the error and adjust it to reduce the error to 0.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Stacking-Neural-Networks:-A-Review">Stacking Neural Networks: A Review<a class="anchor-link" href="#Stacking-Neural-Networks:-A-Review">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>When you look at the stacked neural network architecture and ignore the lower weights &amp; only consider their output to be the dataset.<ul>
<li>the top half of the neural network is just like the networks trained in the preceding chapter.</li>
<li>You can use all the same learning logic to help them learn.</li>
</ul>
</li>
<li>The part that you don't yet understand is how to update the weights of the first layer.<ul>
<li>What do they use as their error measure?</li>
</ul>
</li>
<li>The cached/normalized error measure is called <em>delta</em>.<ul>
<li>You want to figure out how to know the <em>delta</em> values at the first layer so they can help the second layer make accurate predictions.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Backpropagation:-Long-distance-Error-Attribution">Backpropagation: Long-distance Error Attribution<a class="anchor-link" href="#Backpropagation:-Long-distance-Error-Attribution">&#182;</a></h2><h3 id="The-Weighted-average-error">The Weighted average error<a class="anchor-link" href="#The-Weighted-average-error">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%" file="static/imgs/06/backpropagation.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>How do you use the <em>delta</em> at layer 2 to figure out the <em>delta</em> at layer 1?<ul>
<li>You multiply it by each of the respective weights for layer 1.</li>
<li>It's like the prediction logic in reverse.</li>
</ul>
</li>
<li>this process of moving the <em>delta</em> signal around is called <strong>backpropagation</strong>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Backpropagation:-Why-does-this-work?">Backpropagation: Why does this work?<a class="anchor-link" href="#Backpropagation:-Why-does-this-work?">&#182;</a></h2><h3 id="The-weigthed-average-delta">The weigthed average delta<a class="anchor-link" href="#The-weigthed-average-delta">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The delta variable told you the <strong>direction and amount</strong> the value of this node should change next time.</li>
<li>All backpropagation lets you do is say:<ul>
<li>Hey, If you want this node to be x amount higher, then each of these previous four nodes needs to be x*weights_1_2 amount higher/lower.</li>
<li>Because these weights were amplifying the prediction by weights_1_2 times.</li>
</ul>
</li>
<li>Once you know this, you can update each weight matrix as you did before.<ul>
<li>For each weight, multiply its output delta by its input value.</li>
<li>&amp; adjust the weight by that much (or you can scale it by alpha).</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Linear-vs.-Nonlinear">Linear vs. Nonlinear<a class="anchor-link" href="#Linear-vs.-Nonlinear">&#182;</a></h2><h3 id="This-is-probably-the-hardest-Concept-in-the-Book,-Let's-Take-it-slowly">This is probably the <strong>hardest</strong> Concept in the Book, Let's Take it slowly<a class="anchor-link" href="#This-is-probably-the-hardest-Concept-in-the-Book,-Let's-Take-it-slowly">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:66%" file="static/imgs/06/linearity-problem.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Why-the-Neural-Network-still-doesn't-work">Why the Neural Network still doesn't work<a class="anchor-link" href="#Why-the-Neural-Network-still-doesn't-work">&#182;</a></h2><h3 id="If-you-trained-the-three-layer-network-as-it-is-now,-it-wouldn't-converge.">If you trained the three layer network as it is now, it wouldn't converge.<a class="anchor-link" href="#If-you-trained-the-three-layer-network-as-it-is-now,-it-wouldn't-converge.">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The middle nodes don't get to add anything to the conversation.<ul>
<li>they don't get to have correlation of their own.</li>
<li>they're more or less correlated to various input nodes.</li>
</ul>
</li>
<li>But because you know that in teh new dataset there is no correlation between any of the inputs/outputs, how can the middle layer help?<ul>
<li>It mixes up a bunch of correlation that's already useless.</li>
<li><strong>What you really need is for the middle layer to be able to selectively correlate with the input</strong>.</li>
</ul>
</li>
<li><strong>You want the middle layer to sometimes correlate with an input, and sometimes not correlate</strong>.<ul>
<li>That gives it correlation of its own.</li>
</ul>
</li>
<li>This gives the middle layer the opportunity to not just always be x% correlated with one input and y% correlated with another input.<ul>
<li>Instead, it can be x% correlated with one input only when it wants to be.</li>
</ul>
</li>
<li>this is called <strong>Conditional Correlation</strong> or <strong>sometimes correlation</strong>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Secret-to-Sometimes-Correlation">The Secret to Sometimes Correlation<a class="anchor-link" href="#The-Secret-to-Sometimes-Correlation">&#182;</a></h2><h3 id="Turn-off-the-node-when-the-value-is-below-0">Turn off the node when the value is below 0<a class="anchor-link" href="#Turn-off-the-node-when-the-value-is-below-0">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>If a Node's value dropped below 0, normally the node would still have the same correlation to the input as always.<ul>
<li>it would just happen to be negative in value.</li>
<li>But if you turn off the node when it would be negative, then it has zero correlation to any inputs whenever It's negative.</li>
<li>What does this mean ?</li>
</ul>
</li>
<li><strong>The Node can now pick &amp; choose when it wants to be correlated to something.</strong><ul>
<li>This allows it to say something like:<ul>
<li>Make me perfectly correlated to the left input, but only when the right input is turned off.</li>
</ul>
</li>
</ul>
</li>
<li>This wasn't possible before, Now the node can be conditional.<ul>
<li>Now <strong>It can speak of itself</strong></li>
</ul>
</li>
<li>the fancy term for this "if the node would be negative, set it to 0" logic is <strong>nonlinearity</strong>.<ul>
<li>Without this tweak, the neural network is linear.</li>
</ul>
</li>
<li>There are many kinds of nonlinearities, but the one discussed here is, in many cases, the best one to use.<ul>
<li>It's also the simplest. (ReLU)</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Your-First-Deep-Neural-Network">Your First Deep Neural Network<a class="anchor-link" href="#Your-First-Deep-Neural-Network">&#182;</a></h2><h3 id="Here's-how-to-make-the-prediction">Here's how to make the prediction<a class="anchor-link" href="#Here's-how-to-make-the-prediction">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%" file="static/imgs/06/introducing-relu.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">ReLU</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># weights to connect the 3 layers.</span>
<span class="n">ws_0_1</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">ws_1_2</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">ws_0_1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ws_1_2</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((3, 4), (4, 1))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_0</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">layer_1</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_0</span><span class="p">,</span> <span class="n">ws_0_1</span><span class="p">))</span>
<span class="n">layer_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span> <span class="n">ws_1_2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Backpropagating-in-Code">Backpropagating in Code<a class="anchor-link" href="#Backpropagating-in-Code">&#182;</a></h2><h3 id="You-can-learn-the-amount-that-each-weight-contributes-to-the-final-error">You can learn the amount that each weight contributes to the final error<a class="anchor-link" href="#You-can-learn-the-amount-that-each-weight-contributes-to-the-final-error">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">ReLU_grad</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
        <span class="c1"># get input X[i] &amp; target y[i]</span>
        <span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        
        <span class="c1"># calculate prediction</span>
        <span class="n">hs</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">ws_0_1</span><span class="p">))</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hs</span><span class="p">,</span> <span class="n">ws_1_2</span><span class="p">)</span>
        
        <span class="c1"># calculate error, pure error.</span>
        <span class="n">error</span> <span class="o">=</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">y_i</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">-</span> <span class="n">y_i</span>
        
        <span class="c1"># calculate gradients of 1st layer.</span>
        <span class="n">grad_0_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">ws_0_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">line_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ws_0_1</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">col_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ws_0_1</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                <span class="n">grad_0_1</span><span class="p">[</span><span class="n">line_i</span><span class="p">][</span><span class="n">col_i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">x_i</span><span class="p">[</span><span class="n">line_i</span><span class="p">]</span> <span class="o">*</span> <span class="n">ws_1_2</span><span class="p">[</span><span class="n">col_i</span><span class="p">]</span> <span class="o">*</span> <span class="n">ReLU_grad</span><span class="p">(</span><span class="n">hs</span><span class="p">[</span><span class="n">col_i</span><span class="p">])</span>
        
        <span class="c1"># update weights of 1st layer.</span>
        <span class="n">ws_0_1</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad_0_1</span>
        
        <span class="c1"># calculate gradients of 2nd layer.</span>
        <span class="n">grad_1_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">ws_1_2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">line_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ws_1_2</span><span class="p">)):</span>
            <span class="n">grad_1_2</span><span class="p">[</span><span class="n">line_i</span><span class="p">]</span><span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">hs</span><span class="p">[</span><span class="n">line_i</span><span class="p">]</span>
        
        <span class="c1"># update weights of 2nd layer.</span>
        <span class="n">ws_1_2</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad_1_2</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;error: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>
<span class="n">ws_1_2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>error: [0.]
error: [0.07710452]
error: [0.03764561]
error: [0.00240581]
error: [9.22274338e-06]
error: [0.]
error: [0.]
error: [0.]
error: [0.]
error: [0.]
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[-0.5910955 ],
       [ 1.13962134],
       [-0.94522481],
       [ 1.11202675]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Book Implementation.</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">layer_2_error</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
        <span class="n">layer_0</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_0</span><span class="p">,</span> <span class="n">ws_0_1</span><span class="p">))</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span> <span class="n">ws_1_2</span><span class="p">)</span>
        
        <span class="n">layer_2_error</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">layer_2</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer_2</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ws_1_2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">*</span><span class="n">ReLU_grad</span><span class="p">(</span><span class="n">layer_1</span><span class="p">)</span>
        
        <span class="n">ws_1_2</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">layer_1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_2_delta</span><span class="p">)</span>
        <span class="n">ws_0_1</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">layer_0</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_1_delta</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iteration</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error : &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">layer_2_error</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>() (1, 1) (1, 4)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Remember, the goal is <strong>error attribution</strong>.<ul>
<li>It's about figuring out how much each weight contributed to the overall error.</li>
</ul>
</li>
<li>Now that you know how much the final prediction should move up or down, you need to figure out how much each middle node should move up/down.<ul>
<li>These are effectively <strong>intermediate predictions</strong></li>
</ul>
</li>
<li>Once you have the delta at layer 1, you can use the same processes as before for calculating a weight update.</li>
<li>Backpropagation is abount calculating <em>deltas</em> for intermediate layers so you can perform gradient descent.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Why-do-Deep-Networks-Matter?">Why do Deep Networks Matter?<a class="anchor-link" href="#Why-do-Deep-Networks-Matter?">&#182;</a></h2><h3 id="What's-the-point-of-creating-&quot;intermediate-datasets&quot;-that-have-correlation?">What's the point of creating "intermediate datasets" that have correlation?<a class="anchor-link" href="#What's-the-point-of-creating-&quot;intermediate-datasets&quot;-that-have-correlation?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The two layer network might have a problem classifying cat vs. non-cats pectures, why ?</li>
<li>Just like the last streetlight dataset, no individual pixel correlates with whether there's a cat in the picture.<ul>
<li>only different configuration of pixels correlate with whether there's a cat.</li>
</ul>
</li>
<li><strong>Deep Learning is all about creating intermediate layers (datasets) wherein each node in an intermediate layer represents the presence or absence of a different configuration of inputs</strong>.</li>
<li>Because intermediate layers detect (presence or not) various pixel configurations, it then gives the final layer the information it needs to correctly predict the presence/absence of cat.</li>
<li>Some Neural Networks have hundreds of layers.</li>
<li><strong>The Rest of this book will be dedicated to studying different phenomena within these layers in an effort to explore the full power of deep neural networks</strong>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Challenge:-Build-a-3-layer-Neural-Network-from-Memory!">Challenge: Build a 3-layer Neural Network from Memory!<a class="anchor-link" href="#Challenge:-Build-a-3-layer-Neural-Network-from-Memory!">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((4, 3), (4, 1))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># init weights.</span>
<span class="n">ws_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ws_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">ws_1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ws_2</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((3, 4), (4, 1))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">grad_relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
        <span class="c1"># get input/output</span>
        <span class="n">layer_in</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># calculate prediction</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">layer_in</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ws_1</span><span class="p">))</span>
        <span class="n">layer_out</span> <span class="o">=</span> <span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ws_2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># calculate delta 2</span>
        <span class="n">delta_2</span> <span class="o">=</span> <span class="n">layer_out</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># calc error for logs</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">delta_2</span> <span class="o">**</span> <span class="mi">2</span>
        
        <span class="c1"># calculate delta 1</span>
        <span class="c1"># delta_2.dot(ws_2.T) -&gt; (1, 4)</span>
        <span class="c1"># grad_relu(hs) -&gt; (4,)</span>
        <span class="c1"># * : element wise multiplication.</span>
        <span class="n">delta_1</span> <span class="o">=</span> <span class="n">delta_2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ws_2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">*</span><span class="n">grad_relu</span><span class="p">(</span><span class="n">layer_1</span><span class="p">)</span>
        
        <span class="c1"># update weights</span>
        <span class="n">ws_2</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="p">(</span><span class="n">layer_1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta_2</span><span class="p">))</span>
        <span class="n">ws_1</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="p">(</span><span class="n">layer_in</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta_1</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error : &quot;</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Error :  [[2.05239252]]
Error :  [[0.00109065]]
Error :  [[1.64704463e-09]]
Error :  [[1.55952904e-15]]
Error :  [[1.26140843e-21]]
Error :  [[1.09092376e-27]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.73333695e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.73333695e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.79483996e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.10933565e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.73333695e-31]]
Error :  [[1.10933565e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.10933565e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.79483996e-31]]
Error :  [[1.79483996e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.10933565e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.73333695e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.73333695e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.73333695e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.73333695e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.79483996e-31]]
Error :  [[1.10933565e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.10933565e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.73333695e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.10933565e-31]]
Error :  [[1.50992908e-31]]
Error :  [[1.30192864e-31]]
Error :  [[1.50992908e-31]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test weights.</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
    <span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y: &#39;</span><span class="p">,</span> <span class="n">y_i</span><span class="p">,</span> <span class="s1">&#39; y_hat: &#39;</span><span class="p">,</span> <span class="n">relu</span><span class="p">(</span><span class="n">x_i</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ws_1</span><span class="p">))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ws_2</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>y:  [1]  y_hat:  0.9999999999999999
y:  [1]  y_hat:  0.9999999999999997
y:  [0]  y_hat:  2.7755575615628914e-16
y:  [0]  y_hat:  3.608224830031759e-16
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Sketches">Sketches<a class="anchor-link" href="#Sketches">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:66%" file="static/imgs/06/backprop.jpg" %}</p>

</div>
</div>
</div>
</div>
 

