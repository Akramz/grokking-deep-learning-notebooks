---

title: Neural Networks that understand Language: King - Man + Woman == ?
keywords: fastai
sidebar: home_sidebar


---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 11.NNs_that_Understand_Language.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this Chapter:</p>
<ul>
<li>Natural Language Processing</li>
<li>Supervised NLP</li>
<li>Capturing Word Correlation in Input Data</li>
<li>Intro to an Embedding Layer</li>
<li>Neural Architecture</li>
<li>Comparing Word Embeddings</li>
<li>Filling in the Blank</li>
<li>Meaning is derived from Loss</li>
<li>Word Analogies</li>
</ul>
<blockquote><p>"Man is a Slow, Sloppy, and Brilliant Thinker; Computers are Fast, Accurate, and Stupid!" — John Pfeiffer, Fortune, 1961</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-does-it-mean-to-understand-language?">What does it mean to understand language?<a class="anchor-link" href="#What-does-it-mean-to-understand-language?">&#182;</a></h2><h3 id="What-kinds-of-predictions-do-people-make-about-language?">What kinds of predictions do people make about language?<a class="anchor-link" href="#What-kinds-of-predictions-do-people-make-about-language?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:33%;" file="static/imgs/11/domains_intersections.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Natural-Language-Processing-(NLP)">Natural Language Processing (NLP)<a class="anchor-link" href="#Natural-Language-Processing-(NLP)">&#182;</a></h2><h3 id="NLP-is-divided-into-a-collection-of-tasks-and-challenges">NLP is divided into a collection of tasks and challenges<a class="anchor-link" href="#NLP-is-divided-into-a-collection-of-tasks-and-challenges">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Here are a few types of classification problems that are common in NLP:<ul>
<li>Using the Characters of a document to predict where words start and end.</li>
<li>Using the Words of a document to predict where sentences start and end.</li>
<li>Using the Words in a sentence to predict the part of speech of each word.</li>
<li>Using the Words of a sentence to predict where phrases start and end.</li>
<li>Using words in a sentence to predict where named entities (person, place, thing) references start and end.</li>
<li>Using sentences in a document to predict which pronouns refer to the same person/place/thing.</li>
<li>Using words in a sentence to predict the sentiment of a sentence.</li>
</ul>
</li>
<li>NLP tasks seek to do one of three things:<ul>
<li><strong>label a region of text</strong>.</li>
<li><strong>Link two or more regions of Text</strong>.</li>
<li><strong>Try to fill in missing information based on Context</strong>.</li>
</ul>
</li>
<li>Until recently, most of the SoTA NLP Algorithms where <strong>advanced, probabilistic, non-parametric</strong> models (but not Deep Learning).</li>
<li>The recent development and popularization of two major neural algorithms have swept the field of NLP:<ul>
<li><strong>Neural Word Embeddings</strong>.</li>
<li><strong>Recurrent Neural Networks</strong>.</li>
</ul>
</li>
<li>NLP plays a very special role in <strong>AGI</strong> (Artificial General Intelligence), because <strong>language is the bedrock of consious logic and communication in humans</strong>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Supervised-NLP">Supervised NLP<a class="anchor-link" href="#Supervised-NLP">&#182;</a></h2><h3 id="Words-go-in,-&amp;-predictions-come-out">Words go in, &amp; predictions come out<a class="anchor-link" href="#Words-go-in,-&amp;-predictions-come-out">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:75%;" file="static/imgs/11/input_text.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="IMDB-Movie-Reviews-Dataset">IMDB Movie Reviews Dataset<a class="anchor-link" href="#IMDB-Movie-Reviews-Dataset">&#182;</a></h2><h3 id="You-can-predict-whether-people-post-positive/negative-reviews">You can predict whether people post positive/negative reviews<a class="anchor-link" href="#You-can-predict-whether-people-post-positive/negative-reviews">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The IMDB Reviews Dataset is a collection of Review/Rating Pairs that often looks like the following:<blockquote><p>"This Movie was terrible, The Plot was Dry, The acting unconvincing, and I spilled popcorn on my shirt!" — Rating: 1 Stars.</p>
</blockquote>
</li>
<li>The entire dataset consists of around 50K reviews<ul>
<li>The <strong>Input Reviews are usually a few sentences</strong> &amp; the <strong>Output rating is between 1 and 5 stars</strong>.</li>
<li>It should be obvious that this sentiment dataset might be very different from other sentiment datasets, such as product reviews or hospital patient reviews.</li>
</ul>
</li>
<li>Data Processing:<ul>
<li>You'll adjust the range of stars from 1 to 5 into 0 to 1.<ul>
<li>So you can use Binary Softmax (Sigmoid).</li>
</ul>
</li>
<li>The input data is a list of characters, this presents a few problems:<ul>
<li>The input data is text instead of numbers.</li>
<li><strong>Input is Variable-Length Text.</strong></li>
</ul>
</li>
</ul>
</li>
<li>"What about the Input Text will have Correlation with the Output?"<ul>
<li>Representing that property might work well.</li>
<li>I wouldn't expect any characters (in a list of characters) to have correlation with the output (rating).</li>
<li>But several words would have a bit of correlation with the output rating<ul>
<li>"Terrible", "Unconvincing" are such word examples.</li>
</ul>
</li>
<li>These words have significant <strong>negative</strong> correlation with the rating.<ul>
<li>By <strong>Negative</strong>, I mean as the frequency of these words increases, ratings tend to decrease in number of stars.</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Capturing-Word-Correlation-in-Input-Data">Capturing Word Correlation in Input Data<a class="anchor-link" href="#Capturing-Word-Correlation-in-Input-Data">&#182;</a></h2><h3 id="Bag-of-words:-Given-a-review's-Vocabulary,-predict-the-sentiment">Bag of words: Given a review's Vocabulary, predict the sentiment<a class="anchor-link" href="#Bag-of-words:-Given-a-review's-Vocabulary,-predict-the-sentiment">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">IMDB_PATH</span> <span class="o">=</span> <span class="s1">&#39;/Users/mohamedakramzaytar/data/2019/Q2/kaggle/IMDB/imdb_master.csv&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls <span class="nv">$IMDB_PATH</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-red-fg">/Users/mohamedakramzaytar/data/2019/Q2/kaggle/IMDB/imdb_master.csv</span>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">IMDB_PATH</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;ISO-8859-1&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># added encoding to fix error</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>type</th>
      <th>review</th>
      <th>label</th>
      <th>file</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>test</td>
      <td>Once again Mr. Costner has dragged out a movie...</td>
      <td>neg</td>
      <td>0_2.txt</td>
    </tr>
    <tr>
      <th>1</th>
      <td>test</td>
      <td>This is an example of why the majority of acti...</td>
      <td>neg</td>
      <td>10000_4.txt</td>
    </tr>
    <tr>
      <th>2</th>
      <td>test</td>
      <td>First of all I hate those moronic rappers, who...</td>
      <td>neg</td>
      <td>10001_1.txt</td>
    </tr>
    <tr>
      <th>3</th>
      <td>test</td>
      <td>Not even the Beatles could write songs everyon...</td>
      <td>neg</td>
      <td>10002_3.txt</td>
    </tr>
    <tr>
      <th>4</th>
      <td>test</td>
      <td>Brass pictures (movies is not a fitting word f...</td>
      <td>neg</td>
      <td>10003_3.txt</td>
    </tr>
    <tr>
      <th>5</th>
      <td>test</td>
      <td>A funny thing happened to me while watching "M...</td>
      <td>neg</td>
      <td>10004_2.txt</td>
    </tr>
    <tr>
      <th>6</th>
      <td>test</td>
      <td>This German horror film has to be one of the w...</td>
      <td>neg</td>
      <td>10005_2.txt</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># let&#39;s take a look at one review:</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">review</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">label</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#34;Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner&#39;s character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he&#39;s better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher&#39;s ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.&#34;,
 &#39;neg&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>What's commonly done in this case is to create a matrix where each row represents a review.</li>
<li><strong>Each column represents whether a review contains a particular word in the vocabulary.</strong></li>
<li>To create a vector for a review, you just loop over the content and put $1$s in places where the corresponding vocabulary words are present in the review.</li>
<li>How big are these vectors?<ul>
<li>Well, it depends on the global vocabulary of the reviews.</li>
<li>If you have 2,000 unique words, you need vectors of length 2,000.</li>
</ul>
</li>
<li>This form of storage, called <strong>one-hot encoding</strong>, is the most common way to store binary information, in our case, the presence/absence of particular vocabulary words from the text of a review.</li>
<li>If our vocabulary have only 4 words, than the one-hot encoding might actually look like this:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">one_hots</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">one_hots</span><span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">one_hots</span><span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">one_hots</span><span class="p">[</span><span class="s1">&#39;dog&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">one_hots</span><span class="p">[</span><span class="s1">&#39;sat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:75%;" file="static/imgs/11/one-hots.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;sat&#39;</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">one_hots</span><span class="p">[</span><span class="n">sentence</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="n">one_hots</span><span class="p">[</span><span class="n">sentence</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">+</span> <span class="n">one_hots</span><span class="p">[</span><span class="n">sentence</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sent Encoding:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sent Encoding:[1 1 0 1]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We create a vector for each term in the vocabulary.</li>
<li>This allows you to use vector addition to represent a set of words present in a sentence.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Predicting-Movie-Reviews">Predicting Movie Reviews<a class="anchor-link" href="#Predicting-Movie-Reviews">&#182;</a></h2><h3 id="With-the-Previous-Strategy-and-the-previous-network,-you-can-predict-sentiment">With the Previous Strategy and the previous network, you can predict sentiment<a class="anchor-link" href="#With-the-Previous-Strategy-and-the-previous-network,-you-can-predict-sentiment">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>You build a vector for each word and use the two-layer network to predict sentiment.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Using the strategy we just identified, you can build a vector for each word in the sentiment dataset and use the previous two-layer network to predict the sentiment.</li>
<li>I Strongly recommend attempting this from memory.</li>
<li>Open a new Jupyter Notebook, load in the dataset, build you one-hot vectors, and then build a neural network to predict the rating of each movie review (positive or negative).</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">IMDB_PATH</span> <span class="o">=</span> <span class="s1">&#39;/Users/mohamedakramzaytar/data/2019/Q2/kaggle/IMDB/imdb_master.csv&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">IMDB_PATH</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;ISO-8859-1&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s1">&#39;neg&#39;</span><span class="p">,</span> <span class="s1">&#39;pos&#39;</span><span class="p">])]</span>
<span class="n">all_reviews_text</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">review</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># we get unique tokens</span>
<span class="n">all_tokens</span> <span class="o">=</span> <span class="n">all_reviews_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
<span class="n">unique_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">Counter</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">)</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10000</span><span class="p">)]</span>
<span class="nb">len</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_tokens</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(11557297, 10000)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># create a function out of it</span>
<span class="k">def</span> <span class="nf">get_tokens</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># create one-hot representations of each token</span>
<span class="n">word_to_index</span><span class="p">,</span> <span class="n">index_to_word</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_tokens</span><span class="p">):</span>
    <span class="n">word_to_index</span><span class="p">[</span><span class="n">word</span><span class="p">],</span> <span class="n">index_to_word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;words_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)))</span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>words_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>50000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>231.145940</td>
    </tr>
    <tr>
      <th>std</th>
      <td>171.326419</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>126.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>173.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>280.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2470.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>we will take a word one-hot vector of size 10,000</strong>.</li>
<li>&amp; so the review length doesn't matter, we'll just add up each word in the review to get a final representation of the review in a 10,000 vector:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Let's Preprocess the training data:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># we delete columns we&#39;re not interested in</span>
<span class="k">del</span><span class="p">([</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;file&#39;</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;words_count&#39;</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># now we transform label into a number</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="s1">&#39;pos&#39;</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">del</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/mohamedakramzaytar/.envs/research/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># shuffle train now ..</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">review</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">],</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>
    <span class="n">one_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">get_tokens</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">word_to_index</span><span class="p">:</span>
            <span class="n">one_hot</span><span class="p">[</span><span class="n">word_to_index</span><span class="p">[</span><span class="n">token</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">one_hot</span><span class="p">)</span>
    <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((25000, 10000), (25000,))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we have the representations we need to move forward and create a dense neural network to train.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Do it From Memory Later..</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Intro-to-an-embedding-layer">Intro to an embedding layer<a class="anchor-link" href="#Intro-to-an-embedding-layer">&#182;</a></h2><h3 id="Here-is-one-more-trick-to-make-the-network-faster">Here is one more trick to make the network faster<a class="anchor-link" href="#Here-is-one-more-trick-to-make-the-network-faster">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:33%" file="static/imgs/11/dumb_network.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">IMDB_PATH</span> <span class="o">=</span> <span class="s1">&#39;/Users/mohamedakramzaytar/data/2019/Q2/kaggle/IMDB/reviews.txt&#39;</span>
<span class="n">IMDB_LABEL_PATH</span> <span class="o">=</span> <span class="s1">&#39;/Users/mohamedakramzaytar/data/2019/Q2/kaggle/IMDB/labels.txt&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">IMDB_PATH</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">raw_reviews</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">IMDB_LABEL_PATH</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">raw_labels</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">raw_reviews</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(25000, 25000)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># python&#39;s map object is an iterator</span>
<span class="c1"># you can also convert map objects to lists, tupes, ..</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">set</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)),</span> <span class="n">raw_reviews</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># let&#39;s extract the vocab</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sent</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
            <span class="n">vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">):</span>
    <span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># transform all reviews to vectors</span>
<span class="n">input_dataset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="n">sent_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sent</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">sent_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="s2">&quot;&quot;</span>
    <span class="n">input_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">sent_indices</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># same for target data</span>
<span class="n">target_dataset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">raw_labels</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="s2">&quot;positive</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">:</span>
        <span class="n">target_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">target_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">embedding_layer_size</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W0</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">embedding_layer_size</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.1</span>
<span class="n">W1</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">embedding_layer_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># training loop</span>
<span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    
    <span class="c1"># leave last 1000 for testing</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">):</span>
        <span class="c1"># Forward Propagation</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">input_dataset</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">target_dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W0</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">))</span>
        
        <span class="c1"># Gradients Calc</span>
        <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer_2</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        
        <span class="c1"># Backpropagation</span>
        <span class="n">W0</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">-=</span> <span class="n">layer_1_delta</span><span class="o">*</span><span class="n">lr</span>  <span class="c1"># update only corresponding embeddings (w/o attached input to gradient).</span>
        <span class="n">W1</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span> <span class="n">layer_2_delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">lr</span>
        
        <span class="c1"># training accuracy</span>
        <span class="k">if</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">layer_2_delta</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">):</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">%</span><span class="k">1000</span> == 0):
            <span class="n">progress</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">Iter:&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">iter</span><span class="p">),</span> <span class="s1">&#39; Progress:&#39;</span><span class="p">,</span> <span class="n">progress</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">progress</span><span class="p">[</span><span class="mi">4</span><span class="p">:</span><span class="mi">6</span><span class="p">],</span> <span class="s1">&#39;% Training Accuracy:&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">total</span><span class="p">)),</span> <span class="s1">&#39;%&#39;</span><span class="p">)</span>
            
    <span class="c1"># test set evaluation</span>
    <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1000</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">input_dataset</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">target_dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W0</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">))</span>
        <span class="k">if</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">layer_2</span><span class="o">-</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">):</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy: &quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">correct</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">total</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Iter: &lt;built-in function iter&gt;  Progress: 0 .  % Training Accuracy: 0.0 %
Iter: &lt;built-in function iter&gt;  Progress: 04 .  % Training Accuracy: 0.45854145854145856 %
Iter: &lt;built-in function iter&gt;  Progress: 08 .  % Training Accuracy: 0.591704147926037 %
Iter: &lt;built-in function iter&gt;  Progress: 12 .  % Training Accuracy: 0.6691102965678107 %
Iter: &lt;built-in function iter&gt;  Progress: 16 .  % Training Accuracy: 0.7000749812546864 %
Iter: &lt;built-in function iter&gt;  Progress: 2 .  % Training Accuracy: 0.7204559088182364 %
Iter: &lt;built-in function iter&gt;  Progress: 24 .  % Training Accuracy: 0.7382102982836194 %
Iter: &lt;built-in function iter&gt;  Progress: 28 .  % Training Accuracy: 0.7546064847878875 %
Iter: &lt;built-in function iter&gt;  Progress: 32 .  % Training Accuracy: 0.7671541057367829 %
Iter: &lt;built-in function iter&gt;  Progress: 36 .  % Training Accuracy: 0.7763581824241751 %
Iter: &lt;built-in function iter&gt;  Progress: 4 .  % Training Accuracy: 0.785921407859214 %
Iter: &lt;built-in function iter&gt;  Progress: 44 .  % Training Accuracy: 0.792018907372057 %
Iter: &lt;built-in function iter&gt;  Progress: 48 .  % Training Accuracy: 0.7962669777518541 %
Iter: &lt;built-in function iter&gt;  Progress: 52 .  % Training Accuracy: 0.8014768094761942 %
Iter: &lt;built-in function iter&gt;  Progress: 56 .  % Training Accuracy: 0.8062281265623884 %
Iter: &lt;built-in function iter&gt;  Progress: 6 .  % Training Accuracy: 0.8081461235917605 %
Iter: &lt;built-in function iter&gt;  Progress: 64 .  % Training Accuracy: 0.8090119367539529 %
Iter: &lt;built-in function iter&gt;  Progress: 68 .  % Training Accuracy: 0.8115993176871948 %
Iter: &lt;built-in function iter&gt;  Progress: 72 .  % Training Accuracy: 0.8143436475751347 %
Iter: &lt;built-in function iter&gt;  Progress: 76 .  % Training Accuracy: 0.8165359717909584 %
Iter: &lt;built-in function iter&gt;  Progress: 8 .  % Training Accuracy: 0.8197090145492726 %
Iter: &lt;built-in function iter&gt;  Progress: 84 .  % Training Accuracy: 0.8218656254464073 %
Iter: &lt;built-in function iter&gt;  Progress: 88 .  % Training Accuracy: 0.8243261669924095 %
Iter: &lt;built-in function iter&gt;  Progress: 92 .  % Training Accuracy: 0.825920612147298 %
Test Accuracy:  0.849
Iter: &lt;built-in function iter&gt;  Progress: 0 .  % Training Accuracy: 0.8491508491508492 %
Iter: &lt;built-in function iter&gt;  Progress: 04 .  % Training Accuracy: 0.8675662168915542 %
Iter: &lt;built-in function iter&gt;  Progress: 08 .  % Training Accuracy: 0.8760413195601466 %
Iter: &lt;built-in function iter&gt;  Progress: 12 .  % Training Accuracy: 0.8837790552361909 %
Iter: &lt;built-in function iter&gt;  Progress: 16 .  % Training Accuracy: 0.8830233953209358 %
Iter: &lt;built-in function iter&gt;  Progress: 2 .  % Training Accuracy: 0.8845192467922013 %
Iter: &lt;built-in function iter&gt;  Progress: 24 .  % Training Accuracy: 0.8835880588487359 %
Iter: &lt;built-in function iter&gt;  Progress: 28 .  % Training Accuracy: 0.8853893263342082 %
Iter: &lt;built-in function iter&gt;  Progress: 32 .  % Training Accuracy: 0.8879013442950783 %
Iter: &lt;built-in function iter&gt;  Progress: 36 .  % Training Accuracy: 0.8887111288871112 %
Iter: &lt;built-in function iter&gt;  Progress: 4 .  % Training Accuracy: 0.8910099081901646 %
Iter: &lt;built-in function iter&gt;  Progress: 44 .  % Training Accuracy: 0.8917590200816599 %
Iter: &lt;built-in function iter&gt;  Progress: 48 .  % Training Accuracy: 0.8921621413737405 %
Iter: &lt;built-in function iter&gt;  Progress: 52 .  % Training Accuracy: 0.8932933361902721 %
Iter: &lt;built-in function iter&gt;  Progress: 56 .  % Training Accuracy: 0.894140390640624 %
Iter: &lt;built-in function iter&gt;  Progress: 6 .  % Training Accuracy: 0.8946315855259046 %
Iter: &lt;built-in function iter&gt;  Progress: 64 .  % Training Accuracy: 0.8933592141638728 %
Iter: &lt;built-in function iter&gt;  Progress: 68 .  % Training Accuracy: 0.893894783623132 %
Iter: &lt;built-in function iter&gt;  Progress: 72 .  % Training Accuracy: 0.8945844955528657 %
Iter: &lt;built-in function iter&gt;  Progress: 76 .  % Training Accuracy: 0.8956052197390131 %
Iter: &lt;built-in function iter&gt;  Progress: 8 .  % Training Accuracy: 0.8965763535069758 %
Iter: &lt;built-in function iter&gt;  Progress: 84 .  % Training Accuracy: 0.8969137766465161 %
Iter: &lt;built-in function iter&gt;  Progress: 88 .  % Training Accuracy: 0.8973522890309117 %
Iter: &lt;built-in function iter&gt;  Progress: 92 .  % Training Accuracy: 0.896879296695971 %
Test Accuracy:  0.845
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Interpreting-the-Output">Interpreting the Output<a class="anchor-link" href="#Interpreting-the-Output">&#182;</a></h2><h3 id="What-did-the-Neural-Network-learn-along-the-way?">What did the Neural Network learn along the way?<a class="anchor-link" href="#What-did-the-Neural-Network-learn-along-the-way?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The Network was looking for correlation between the input data points and the output data points.</li>
<li>It's extremely beneficial to know what kind of patterns the network detected while training and took as signal for predicting sentiment.</li>
<li>Just because the network was able to find correlation between the input and the output doesn't mean that it found every pattern of language.</li>
<li>Understanding what the difference between what the network is able to currently learn from data sets and what it should learn to truly understand language is very important &amp; essential to solve artificial general intelligence.</li>
<li>What about language was our network able to learn?<ul>
<li>Let's start by considering was what <strong>presented to the network</strong><ul>
<li>Presented Each review's vocabulary and asked for the network to classify if it's positive or negative.</li>
</ul>
</li>
<li>You'd expect the network to know which words have strong correlation with negative opinions and which are positive.</li>
</ul>
</li>
<li>But this isn't the whole story.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Architecture">Neural Architecture<a class="anchor-link" href="#Neural-Architecture">&#182;</a></h2><h3 id="How-did-the-choice-of-architecture-effect-what-the-network-was-able-to-learn?">How did the choice of architecture effect what the network was able to learn?<a class="anchor-link" href="#How-did-the-choice-of-architecture-effect-what-the-network-was-able-to-learn?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Hidden layers are about grouping input data points coming from the previous layer into n groups.<ul>
<li>Each hidden neuron takes in a data point and asks "is this data point in my group?"</li>
<li>As the hidden layer learns, it searches for useful groupings.</li>
</ul>
</li>
<li>What are useful groupings?<ul>
<li>The grouping must be useful in the prediction of the output label.<ul>
<li>If it's not useful in predicting the output label, the network summarization won't allow the layer to find the groupings.</li>
</ul>
</li>
<li>A Grouping is useful if it finds hidden and interesting structure in the data.<ul>
<li>bad groupings just memorize data.</li>
<li>good groupings capture phenomenas that are useful linguistically.</li>
</ul>
</li>
</ul>
</li>
<li>For example, understanding the difference between "terrible" and "not terrible" is a powerful grouping.</li>
<li>But because the input to the network is a vocabulary and not a sequence, "It is Great, Not terribe" will be interpreted exactly like "It is Terrible, Not Good".</li>
<li>If you can construct two examples with the same activation hidden layer &amp; the pattern is present in the first example while absent in the 2nd, then the network couldn't detect the pattern you're interested in.</li>
<li>2 Data Points (Movie Reviews) get the same prediction if they subscribe to most of the trained groupings.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="What-should-you-see-in-the-weights-connecting-weights-to-hidden-neurons?">What should you see in the weights connecting weights to hidden neurons?<a class="anchor-link" href="#What-should-you-see-in-the-weights-connecting-weights-to-hidden-neurons?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:25%" file="static/imgs/11/embedding_weights.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Comparing-Word-Embeddings">Comparing Word Embeddings<a class="anchor-link" href="#Comparing-Word-Embeddings">&#182;</a></h2><h3 id="How-Can-you-Visualize-Weight-Similarity?">How Can you Visualize Weight Similarity?<a class="anchor-link" href="#How-Can-you-Visualize-Weight-Similarity?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>You can get the embedding of each word by simply extracting the corresponding row from the first weight matrix.</li>
<li>You do word-to-word comparison by simply calculating the euclidian distance between the two vectors.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">math</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">similar</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s1">&#39;beautiful&#39;</span><span class="p">):</span>
    <span class="n">target_index</span> <span class="o">=</span> <span class="n">word2index</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">word2index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">raw_difference</span> <span class="o">=</span> <span class="n">W0</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">-</span> <span class="n">W0</span><span class="p">[</span><span class="n">target_index</span><span class="p">]</span>
        <span class="n">squared_difference</span> <span class="o">=</span> <span class="n">raw_difference</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">squared_difference</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">scores</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>This will allow you to easily find out the similar words to a target word, examples:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;beautiful&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(&#39;beautiful&#39;, -0.0), (&#39;beautifully&#39;, -0.7234740527429394), (&#39;episodes&#39;, -0.7431900463968468), (&#39;realistic&#39;, -0.757880033742247), (&#39;beauty&#39;, -0.759955286643346), (&#39;atmosphere&#39;, -0.7601443881195916), (&#39;recommended&#39;, -0.7610825019283651), (&#39;fun&#39;, -0.7701812509518946), (&#39;great&#39;, -0.7834113731660364), (&#39;bit&#39;, -0.7858516072936133)]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;terrible&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(&#39;terrible&#39;, -0.0), (&#39;disappointment&#39;, -0.7148509282587314), (&#39;annoying&#39;, -0.7671560931689875), (&#39;boring&#39;, -0.7899973527799934), (&#39;worse&#39;, -0.796032596035763), (&#39;laughable&#39;, -0.797488012028028), (&#39;avoid&#39;, -0.8111283880874369), (&#39;dull&#39;, -0.8210389457432301), (&#39;mess&#39;, -0.833565219519962), (&#39;disappointing&#39;, -0.8393998496880327)]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;average&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(&#39;average&#39;, -0.0), (&#39;manipulative&#39;, -0.6258354687765075), (&#39;barbershop&#39;, -0.6512567886916747), (&#39;gyneth&#39;, -0.6527740640628336), (&#39;kolya&#39;, -0.6560375177956016), (&#39;neverheless&#39;, -0.6569103115275596), (&#39;broker&#39;, -0.6607965580519881), (&#39;ghatak&#39;, -0.6613206616357246), (&#39;triumf&#39;, -0.6639680365540314), (&#39;shawn&#39;, -0.6645095432239714)]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;love&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(&#39;love&#39;, -0.0), (&#39;know&#39;, -0.6807296076265122), (&#39;classic&#39;, -0.7058610625390093), (&#39;although&#39;, -0.7089204276967219), (&#39;genius&#39;, -0.7132786925108467), (&#39;touched&#39;, -0.7141661782554475), (&#39;delicious&#39;, -0.7160007781267519), (&#39;packed&#39;, -0.7161515900219529), (&#39;satire&#39;, -0.7171565782119897), (&#39;carrie&#39;, -0.7175034627599344)]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>This is a standard phenomenon in the correlation summarization.</li>
<li>It seeks to create similar latent representations within the network to facilitate information compression to arrive to the correct target label.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-is-the-meaning-of-a-neuron?">What is the meaning of a neuron?<a class="anchor-link" href="#What-is-the-meaning-of-a-neuron?">&#182;</a></h2><h3 id="Meaning-is-entirely-based-on-the-target-labels-being-predicted">Meaning is entirely based on the target labels being predicted<a class="anchor-link" href="#Meaning-is-entirely-based-on-the-target-labels-being-predicted">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Notice that "Beautiful" &amp; "Atmosphere" are nearly identical, but <strong>only in the context of sentiment prediction</strong>.<ul>
<li>but in the other hand, their meaning is quite different (one is an adjective &amp; the other is a noun).</li>
</ul>
</li>
<li>The meaning of a neuron in the network depends entirely on the target labels.</li>
<li>The Neural Network is entirely ignorant of any other meaning outside the task it was trained on.</li>
<li>How do you make the meaning of a neuron more broad?<ul>
<li>Well, if you give it a task that requires broad understanding of language, it will learn new complexities and its neurons will become much more general.</li>
</ul>
</li>
<li>The Task you'll use to learn more interesting word embeddings is the "fill in the blank" task.<ul>
<li>There is nearly infinite training data (the internet).<ul>
<li>Which means infinite signal to the network.</li>
</ul>
</li>
<li>Being able to learn to fill the blank requires at least some context language understanding.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Filling-in-the-Blank">Filling in the Blank<a class="anchor-link" href="#Filling-in-the-Blank">&#182;</a></h2><h3 id="Learn-Richer-Word-Meanings-by-having-A-Richer-Signal">Learn Richer Word Meanings by having A Richer Signal<a class="anchor-link" href="#Learn-Richer-Word-Meanings-by-having-A-Richer-Signal">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>This example uses almost the same previous architecture with minor modifications.</li>
<li>You'll split the text into 5 words sentences, then remove one word (focus term), and train the network to predict the focus term.</li>
<li>you'll use a technique called <strong>negative sampling</strong> to make the network train a bit more faster.</li>
<li>Consider that in order to predict the focus term, you need one label for each possible word.<ul>
<li>This would require several thousand labels, which would cause the network to train slowly.</li>
<li>To overcome this, let's randomly ignore most of the labels for each forward propagation.<ul>
<li>Although this seems crude, it's a technique that works well in practice.</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">IMDB_PATH</span> <span class="o">=</span> <span class="s1">&#39;/Users/mohamedakramzaytar/data/2019/Q2/kaggle/IMDB/reviews.txt&#39;</span>
<span class="n">IMDB_LABEL_PATH</span> <span class="o">=</span> <span class="s1">&#39;/Users/mohamedakramzaytar/data/2019/Q2/kaggle/IMDB/labels.txt&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">IMDB_PATH</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">raw_reviews</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">raw_reviews</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>25000</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">),</span> <span class="n">raw_reviews</span><span class="p">))</span>
<span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(185, 127, 537)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word_counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
        <span class="n">word_counter</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">word_counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">()</span>  <span class="c1"># least common in this case.</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>most_common()</code> just sorts out the data, it doesn't take the Top N most common tokens unless you force it to (by giving it an argument i think).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">word_counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">())))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">):</span>
    <span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">concatenated</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">input_dataset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="n">review_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">review_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word2index</span><span class="p">[</span><span class="n">token</span><span class="p">])</span>
            <span class="n">concatenated</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word2index</span><span class="p">[</span><span class="n">token</span><span class="p">])</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="s2">&quot;&quot;</span>
    <span class="n">input_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">review_indices</span><span class="p">)</span>
<span class="n">concatenated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">concatenated</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="p">(</span><span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">hidden_size</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">negative</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W0</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.2</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">*</span><span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W0</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">W1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((74075, 50), (74075, 50))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>W1</code> Could simply be replaced by: <code>np.zeros(len(vocab), hidden_size)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer_2_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">negative</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">layer_2_target</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">similar</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s1">&#39;beautiful&#39;</span><span class="p">):</span>
    <span class="n">target_index</span> <span class="o">=</span> <span class="n">word2index</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
    
    <span class="n">scores</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">word2index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">raw_difference</span> <span class="o">=</span> <span class="n">W0</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">-</span> <span class="n">W0</span><span class="p">[</span><span class="n">target_index</span><span class="p">]</span>
        <span class="n">squared_difference</span> <span class="o">=</span> <span class="n">raw_difference</span> <span class="o">*</span> <span class="n">raw_difference</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">squared_difference</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">scores</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">review_i</span><span class="p">,</span> <span class="n">review</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_dataset</span> <span class="o">*</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">target_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">review</span><span class="p">)):</span>
        <span class="c1"># predict only a random subset, because it&#39;s really expensive to predict every vocab</span>
        <span class="c1"># We can&#39;t do a softmax over all possible words, we will predict for the target word + a subset of the total vocab</span>
        <span class="n">target_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">review</span><span class="p">[</span><span class="n">target_i</span><span class="p">]]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">concatenated</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">negative</span><span class="p">)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">concatenated</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()])</span>
        
        <span class="c1"># get tokens on the right &amp; on Left of target word</span>
        <span class="n">left_context</span> <span class="o">=</span> <span class="n">review</span><span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_i</span><span class="o">-</span><span class="n">window</span><span class="p">):</span><span class="n">target_i</span><span class="p">]</span>
        <span class="n">right_context</span> <span class="o">=</span> <span class="n">review</span><span class="p">[</span><span class="n">target_i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">review</span><span class="p">),</span> <span class="n">target_i</span><span class="o">+</span><span class="n">window</span><span class="p">)]</span>
        
        <span class="c1"># feed forward</span>
        <span class="c1"># context words w/o target word</span>
        <span class="c1"># mean instead of sum, interesting</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">W0</span><span class="p">[</span><span class="n">left_context</span><span class="o">+</span><span class="n">right_context</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># using sigmoid here is kind of weird because there is only one true target token</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">[</span><span class="n">target_samples</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="n">layer_2</span> <span class="o">-</span> <span class="n">layer_2_target</span>
        <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">[</span><span class="n">target_samples</span><span class="p">])</span>
        
        <span class="c1"># update weights</span>
        <span class="n">W0</span><span class="p">[</span><span class="n">left_context</span><span class="o">+</span><span class="n">right_context</span><span class="p">]</span> <span class="o">-=</span> <span class="n">layer_1_delta</span><span class="o">*</span><span class="n">lr</span>
        <span class="n">W1</span><span class="p">[</span><span class="n">target_samples</span><span class="p">]</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_2_delta</span><span class="p">,</span> <span class="n">layer_1</span><span class="p">)</span><span class="o">*</span><span class="n">lr</span>
        
    <span class="k">if</span><span class="p">(</span><span class="n">review_i</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">Progress:&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">review_i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span><span class="o">*</span><span class="n">epochs</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;terrible&#39;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;terrible&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:0.0 [(&#39;terrible&#39;, -0.0), (&#39;cognac&#39;, -0.3738881216269329), (&#39;derisive&#39;, -0.38706720946311435), (&#39;grease&#39;, -0.38977976159778677), (&#39;accessory&#39;, -0.39072454239376825), (&#39;constructs&#39;, -0.3918349061764808), (&#39;misreads&#39;, -0.3923191534753908), (&#39;rambles&#39;, -0.39428401242305783), (&#39;mecha&#39;, -0.39500026848095804), (&#39;starlets&#39;, -0.39594037298290563)]
Progress:0.01 [(&#39;terrible&#39;, -0.0), (&#39;ill&#39;, -0.6255941821256622), (&#39;awesome&#39;, -0.6375994436921958), (&#39;competent&#39;, -0.6407977227851339), (&#39;troubled&#39;, -0.6531069241561729), (&#39;jr&#39;, -0.6534538265536488), (&#39;blockbuster&#39;, -0.6563001235939745), (&#39;brief&#39;, -0.6606079018272691), (&#39;marty&#39;, -0.6607438906298844), (&#39;aubrey&#39;, -0.6627754935036241)]
Progress:0.02 [(&#39;terrible&#39;, -0.0), (&#39;superb&#39;, -1.0578247838536894), (&#39;awesome&#39;, -1.2031760650904362), (&#39;compelling&#39;, -1.203498585352637), (&#39;pointless&#39;, -1.2124866217538417), (&#39;solid&#39;, -1.216145731204235), (&#39;fantastic&#39;, -1.2247588874668456), (&#39;sad&#39;, -1.2297465716290998), (&#39;okay&#39;, -1.2341042974148884), (&#39;perfect&#39;, -1.2502682371546312)]
Progress:0.03 [(&#39;terrible&#39;, -0.0), (&#39;superb&#39;, -1.4173156292288298), (&#39;brilliant&#39;, -1.4875116922641962), (&#39;perfect&#39;, -1.5170961849725428), (&#39;horrible&#39;, -1.5732355723485705), (&#39;compelling&#39;, -1.5815101395261246), (&#39;pointless&#39;, -1.6060673108285273), (&#39;badly&#39;, -1.6468294582841656), (&#39;stupid&#39;, -1.6488984383079257), (&#39;l&#39;, -1.6518984452663394)]
Progress:0.04 [(&#39;terrible&#39;, -0.0), (&#39;nice&#39;, -1.683959997768794), (&#39;horrible&#39;, -1.7672745714606068), (&#39;fantastic&#39;, -1.8066476678564944), (&#39;solid&#39;, -1.8253155697827514), (&#39;tragic&#39;, -1.8281140356567775), (&#39;l&#39;, -1.8396191035745912), (&#39;offered&#39;, -1.8427081985972027), (&#39;hilarious&#39;, -1.8475482678940365), (&#39;cute&#39;, -1.8604495512809063)]
Progress:0.05 [(&#39;terrible&#39;, -0.0), (&#39;fantastic&#39;, -1.7564688069262742), (&#39;ridiculous&#39;, -1.8343097595982265), (&#39;solid&#39;, -1.843036191101936), (&#39;essentially&#39;, -1.862819359929147), (&#39;perfectly&#39;, -1.8945823965636441), (&#39;horrible&#39;, -1.9269976010367644), (&#39;okay&#39;, -1.9873786149160608), (&#39;cute&#39;, -2.002522987747186), (&#39;superb&#39;, -2.038013500856629)]
Progress:0.06 [(&#39;terrible&#39;, -0.0), (&#39;fantastic&#39;, -1.5907144132818436), (&#39;fine&#39;, -1.740056287624307), (&#39;brilliant&#39;, -1.7481647060197738), (&#39;solid&#39;, -1.7848664966171082), (&#39;rare&#39;, -1.8973813479793888), (&#39;pure&#39;, -1.8988931914062774), (&#39;superb&#39;, -1.911135800067484), (&#39;essentially&#39;, -1.9155299440297227), (&#39;magnificent&#39;, -1.9211939087368792)]
Progress:0.07 [(&#39;terrible&#39;, -0.0), (&#39;fantastic&#39;, -1.9307404652909796), (&#39;teenager&#39;, -2.0242149273983916), (&#39;solid&#39;, -2.0396191900714813), (&#39;remarkable&#39;, -2.0540900669800206), (&#39;brilliant&#39;, -2.056155455895821), (&#39;fine&#39;, -2.0943223550532393), (&#39;l&#39;, -2.0970854130645815), (&#39;essentially&#39;, -2.1049908836385174), (&#39;magnificent&#39;, -2.119813035821666)]
Progress:0.08 [(&#39;terrible&#39;, -0.0), (&#39;brilliant&#39;, -2.1573804177384326), (&#39;fantastic&#39;, -2.2054813183792814), (&#39;unique&#39;, -2.205794040972634), (&#39;student&#39;, -2.2058162358278706), (&#39;magnificent&#39;, -2.2490557020027055), (&#39;remarkable&#39;, -2.264642428899016), (&#39;essentially&#39;, -2.297700281145124), (&#39;superb&#39;, -2.309181793638192), (&#39;l&#39;, -2.3130805275452353)]
Progress:0.09 [(&#39;terrible&#39;, -0.0), (&#39;unique&#39;, -1.9630919416089674), (&#39;fantastic&#39;, -2.0017978782819768), (&#39;brilliant&#39;, -2.0115258979749178), (&#39;manner&#39;, -2.113221728858162), (&#39;student&#39;, -2.150926559163908), (&#39;remarkable&#39;, -2.1678453823681), (&#39;bizarre&#39;, -2.180299630618594), (&#39;terrific&#39;, -2.1918570386195984), (&#39;magnificent&#39;, -2.1925882438873225)]
Progress:0.1 [(&#39;terrible&#39;, -0.0), (&#39;unique&#39;, -2.02151020498893), (&#39;fantastic&#39;, -2.0813491086642415), (&#39;student&#39;, -2.147945067647603), (&#39;teenager&#39;, -2.1729225111939443), (&#39;dreadful&#39;, -2.192235865755016), (&#39;brilliant&#39;, -2.23070301673223), (&#39;magnificent&#39;, -2.2319957580080834), (&#39;manner&#39;, -2.2419896635097984), (&#39;terrific&#39;, -2.2506979890320093)]
Progress:0.11 [(&#39;terrible&#39;, -0.0), (&#39;fantastic&#39;, -2.3168089920155888), (&#39;painful&#39;, -2.3266853862642494), (&#39;dreadful&#39;, -2.3290950212721757), (&#39;lame&#39;, -2.3642578911010124), (&#39;bizarre&#39;, -2.369931187801232), (&#39;remarkable&#39;, -2.3720170156094884), (&#39;superb&#39;, -2.372061354714734), (&#39;worthwhile&#39;, -2.3725085611023746), (&#39;pleasant&#39;, -2.3811028219427346)]
Progress:0.12 [(&#39;terrible&#39;, -0.0), (&#39;lame&#39;, -2.3573421435559703), (&#39;brilliant&#39;, -2.391402038723787), (&#39;remarkable&#39;, -2.4114585303152554), (&#39;bizarre&#39;, -2.4462875880208723), (&#39;fantastic&#39;, -2.450324469372958), (&#39;painful&#39;, -2.4643121222565854), (&#39;worthwhile&#39;, -2.4826372313668417), (&#39;format&#39;, -2.5329476035469005), (&#39;desperate&#39;, -2.5464341479260217)]
Progress:0.13 [(&#39;terrible&#39;, -0.0), (&#39;lame&#39;, -2.33859580353737), (&#39;brilliant&#39;, -2.4357519045570863), (&#39;ridiculous&#39;, -2.5251522445430843), (&#39;remarkable&#39;, -2.5745306165121518), (&#39;painful&#39;, -2.596220289648302), (&#39;fantastic&#39;, -2.610795105522625), (&#39;laughable&#39;, -2.6615759389412004), (&#39;horrible&#39;, -2.6788430511057686), (&#39;bizarre&#39;, -2.6910619524599357)]
Progress:0.14 [(&#39;terrible&#39;, -0.0), (&#39;lame&#39;, -2.414217897492103), (&#39;ridiculous&#39;, -2.4426944555115107), (&#39;brilliant&#39;, -2.522655956850569), (&#39;fantastic&#39;, -2.7372657365855613), (&#39;horrible&#39;, -2.7591080021125456), (&#39;dumb&#39;, -2.772351104710049), (&#39;laughable&#39;, -2.788620030170762), (&#39;remarkable&#39;, -2.8129700346752684), (&#39;magnificent&#39;, -2.815448415667037)]
Progress:0.15 [(&#39;terrible&#39;, -0.0), (&#39;lame&#39;, -2.574654836846541), (&#39;brilliant&#39;, -2.745990424687773), (&#39;horrible&#39;, -2.908739975653882), (&#39;fantastic&#39;, -2.910928136904808), (&#39;ridiculous&#39;, -2.9361261613932017), (&#39;dumb&#39;, -2.9741038347785436), (&#39;hilarious&#39;, -2.987939515056298), (&#39;magnificent&#39;, -3.0720018531771953), (&#39;terrific&#39;, -3.0856641564248104)]
Progress:0.16 [(&#39;terrible&#39;, -0.0), (&#39;lame&#39;, -2.645191599403652), (&#39;horrible&#39;, -2.9023544876882506), (&#39;brilliant&#39;, -2.9362584250853185), (&#39;terrific&#39;, -3.141542083933236), (&#39;poor&#39;, -3.1519976150292273), (&#39;hilarious&#39;, -3.1899855291119223), (&#39;ridiculous&#39;, -3.191819365917436), (&#39;magnificent&#39;, -3.2502556923295214), (&#39;fantastic&#39;, -3.2663297418038963)]
Progress:0.17 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.830254682249065), (&#39;lame&#39;, -2.907228813694319), (&#39;brilliant&#39;, -3.17236785320915), (&#39;fantastic&#39;, -3.3439621459443494), (&#39;ridiculous&#39;, -3.348598059543297), (&#39;terrific&#39;, -3.3691563150239636), (&#39;superb&#39;, -3.4218623345382992), (&#39;hilarious&#39;, -3.4472865736157123), (&#39;dumb&#39;, -3.4539699986762007)]
Progress:0.18 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.5072729054906064), (&#39;lame&#39;, -2.850755952257121), (&#39;brilliant&#39;, -2.9832245382458757), (&#39;superb&#39;, -3.186094209153268), (&#39;fantastic&#39;, -3.2640191519598933), (&#39;terrific&#39;, -3.2782088714976334), (&#39;weak&#39;, -3.298794160886496), (&#39;fascinating&#39;, -3.3610986749666116), (&#39;magnificent&#39;, -3.3791976492104765)]
Progress:0.19 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.7642326110888344), (&#39;brilliant&#39;, -3.1541110782382815), (&#39;superb&#39;, -3.308760119311531), (&#39;fantastic&#39;, -3.3385058210297442), (&#39;lame&#39;, -3.361227413349471), (&#39;weak&#39;, -3.4086592003712717), (&#39;compelling&#39;, -3.4809043134909636), (&#39;poor&#39;, -3.4965046290468775), (&#39;dreadful&#39;, -3.563763961481057)]
Progress:0.2 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.927752839793251), (&#39;brilliant&#39;, -3.429295832912943), (&#39;fantastic&#39;, -3.4595304862158947), (&#39;superb&#39;, -3.5896065584985704), (&#39;lame&#39;, -3.629101884230367), (&#39;dreadful&#39;, -3.680165013460219), (&#39;compelling&#39;, -3.714928706450099), (&#39;fascinating&#39;, -3.7301713086965713), (&#39;poor&#39;, -3.7676582111221912)]
Progress:0.21 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.076741153421989), (&#39;superb&#39;, -3.6983442914294127), (&#39;lame&#39;, -3.7237628650876227), (&#39;weak&#39;, -3.7539766748232566), (&#39;boring&#39;, -3.7774470923062404), (&#39;unrealistic&#39;, -3.7794915871901167), (&#39;brilliant&#39;, -3.8046178877757897), (&#39;moving&#39;, -3.815421377712222), (&#39;dreadful&#39;, -3.8296522192547386)]
Progress:0.22 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.0547317910176397), (&#39;fantastic&#39;, -3.355578928810344), (&#39;brilliant&#39;, -3.4240304979280234), (&#39;superb&#39;, -3.53247840304693), (&#39;lame&#39;, -3.5529059291345604), (&#39;remarkable&#39;, -3.6714615288559895), (&#39;laughable&#39;, -3.7091680668061926), (&#39;compelling&#39;, -3.7277432728180258), (&#39;hilarious&#39;, -3.7497939427005686)]
Progress:0.23 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.2705597975021155), (&#39;brilliant&#39;, -3.314712095933311), (&#39;lame&#39;, -3.3518738285992495), (&#39;remarkable&#39;, -3.5563957379128404), (&#39;fantastic&#39;, -3.584503285522282), (&#39;dreadful&#39;, -3.6220446116989073), (&#39;boring&#39;, -3.6242330530004385), (&#39;dumb&#39;, -3.642124204486252), (&#39;unique&#39;, -3.6509023278507424)]
Progress:0.24 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.2797615093129218), (&#39;brilliant&#39;, -3.2886120065096947), (&#39;fantastic&#39;, -3.579494043630086), (&#39;lame&#39;, -3.668514925745507), (&#39;superb&#39;, -3.739984103337931), (&#39;remarkable&#39;, -3.7577465389796716), (&#39;great&#39;, -3.871126358921808), (&#39;boring&#39;, -3.8716290118910877), (&#39;limited&#39;, -3.924013004328151)]
Progress:0.25 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.0598779141463703), (&#39;brilliant&#39;, -3.2827998852030276), (&#39;lame&#39;, -3.5818984128491667), (&#39;fantastic&#39;, -3.6272513430652906), (&#39;superb&#39;, -3.803219948779769), (&#39;great&#39;, -3.8741019735580227), (&#39;remarkable&#39;, -3.8897773367140536), (&#39;lousy&#39;, -3.890195184598431), (&#39;boring&#39;, -3.896875983133506)]
Progress:0.26 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.116602999288676), (&#39;brilliant&#39;, -3.3080882913143097), (&#39;remarkable&#39;, -3.6915554795591565), (&#39;lame&#39;, -3.731040889666555), (&#39;superb&#39;, -3.756428354960779), (&#39;fantastic&#39;, -3.773788440753402), (&#39;pathetic&#39;, -3.805557175021458), (&#39;wonderful&#39;, -3.922350618041276), (&#39;weak&#39;, -3.9660546529282694)]
Progress:0.27 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.9880629424591953), (&#39;brilliant&#39;, -3.347982070320388), (&#39;remarkable&#39;, -3.765660528439731), (&#39;superb&#39;, -3.8160081118121236), (&#39;fantastic&#39;, -3.856183280700724), (&#39;wonderful&#39;, -3.885613821085064), (&#39;lousy&#39;, -3.9536504943777877), (&#39;dreadful&#39;, -3.9696802867986776), (&#39;pathetic&#39;, -4.0026106950305556)]
Progress:0.28 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.08941442209383), (&#39;brilliant&#39;, -3.4744333497141215), (&#39;lousy&#39;, -3.6505773850137455), (&#39;laughable&#39;, -3.7647490067530254), (&#39;fantastic&#39;, -3.8092452691249785), (&#39;dumb&#39;, -3.8143795399770517), (&#39;mediocre&#39;, -3.8335026329879307), (&#39;remarkable&#39;, -3.835116010889034), (&#39;pathetic&#39;, -3.8356200420109197)]
Progress:0.29 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.283623663808263), (&#39;brilliant&#39;, -3.724834614714983), (&#39;laughable&#39;, -3.7533934302028737), (&#39;fantastic&#39;, -3.7994013182531283), (&#39;lousy&#39;, -3.8748228435543606), (&#39;dreadful&#39;, -3.8962098539789496), (&#39;mediocre&#39;, -3.8976022353052673), (&#39;lame&#39;, -3.9508504094595516), (&#39;remarkable&#39;, -3.950944231991155)]
Progress:0.3 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.404903793504964), (&#39;laughable&#39;, -3.8678471165465944), (&#39;breathtaking&#39;, -3.8741566378846506), (&#39;dreadful&#39;, -3.8781256267214936), (&#39;mediocre&#39;, -3.880634980569056), (&#39;fantastic&#39;, -3.8821806572477864), (&#39;lousy&#39;, -3.8853688452745443), (&#39;pathetic&#39;, -3.95840238178235), (&#39;marvelous&#39;, -3.9585673802970334)]
Progress:0.31 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.585210309445897), (&#39;fantastic&#39;, -3.7682870979781264), (&#39;weak&#39;, -3.9053949135706776), (&#39;pathetic&#39;, -3.9404661700614607), (&#39;superb&#39;, -3.998683036447182), (&#39;dreadful&#39;, -3.9990444448287925), (&#39;breathtaking&#39;, -4.005435087870906), (&#39;funeral&#39;, -4.048159885043211), (&#39;marvelous&#39;, -4.0638729729952745)]
Progress:0.32 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.295398906731389), (&#39;fantastic&#39;, -3.743872705547643), (&#39;weak&#39;, -3.8118712912947985), (&#39;pathetic&#39;, -3.8639271199554135), (&#39;great&#39;, -3.939121746279988), (&#39;superb&#39;, -3.9508044526940007), (&#39;lousy&#39;, -4.0273971477734305), (&#39;breathtaking&#39;, -4.028465562393784), (&#39;mediocre&#39;, -4.060745930946747)]
Progress:0.33 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.5114333036777587), (&#39;pathetic&#39;, -3.797795476943267), (&#39;laughable&#39;, -4.050281523561719), (&#39;breathtaking&#39;, -4.059292131342258), (&#39;weak&#39;, -4.0743757208560965), (&#39;fantastic&#39;, -4.113123071728292), (&#39;great&#39;, -4.1794392025148825), (&#39;funeral&#39;, -4.182509643975104), (&#39;marvelous&#39;, -4.182807525259816)]
Progress:0.34 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.234690966658438), (&#39;brilliant&#39;, -3.7749716526517014), (&#39;stupid&#39;, -3.9572010349451494), (&#39;lame&#39;, -3.968293666900254), (&#39;pathetic&#39;, -4.001433729378176), (&#39;fantastic&#39;, -4.044102531694206), (&#39;weak&#39;, -4.094349207383565), (&#39;laughable&#39;, -4.1114468268263415), (&#39;dumb&#39;, -4.149484047093075)]
Progress:0.35 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.121842703452971), (&#39;brilliant&#39;, -3.7761125151632458), (&#39;lame&#39;, -3.9570489139239298), (&#39;pathetic&#39;, -3.9749678916674385), (&#39;weak&#39;, -3.9870059783552465), (&#39;laughable&#39;, -4.078667073850455), (&#39;stupid&#39;, -4.148054454740136), (&#39;breathtaking&#39;, -4.167801198869453), (&#39;dumb&#39;, -4.190480287199553)]
Progress:0.36 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.063833005265869), (&#39;brilliant&#39;, -3.6203743062755716), (&#39;lame&#39;, -3.9024296346663188), (&#39;weak&#39;, -3.9346223656328645), (&#39;pathetic&#39;, -3.951192123951121), (&#39;superb&#39;, -4.031309487084784), (&#39;breathtaking&#39;, -4.035236145134111), (&#39;fantastic&#39;, -4.105398294697464), (&#39;stupid&#39;, -4.105993046040433)]
Progress:0.37 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8685446695081884), (&#39;brilliant&#39;, -3.41900914582724), (&#39;superb&#39;, -3.9036135591406564), (&#39;laughable&#39;, -3.9847487729486066), (&#39;pathetic&#39;, -3.9892747632563257), (&#39;lame&#39;, -3.998008269336891), (&#39;weak&#39;, -4.10949540593884), (&#39;fantastic&#39;, -4.19613853409303), (&#39;breathtaking&#39;, -4.20449381320781)]
Progress:0.38 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.7461339757429237), (&#39;brilliant&#39;, -3.1938379242417714), (&#39;laughable&#39;, -3.810733185304745), (&#39;superb&#39;, -3.852831850322113), (&#39;fantastic&#39;, -3.8601622663268644), (&#39;lame&#39;, -3.9173474630917644), (&#39;pathetic&#39;, -3.9775402663636426), (&#39;breathtaking&#39;, -4.000899829396734), (&#39;marvelous&#39;, -4.080114253658501)]
Progress:0.39 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.7047378804998976), (&#39;brilliant&#39;, -3.212656515425186), (&#39;superb&#39;, -3.5487718043246876), (&#39;fantastic&#39;, -3.7153789901973826), (&#39;great&#39;, -3.9377185784149678), (&#39;pathetic&#39;, -3.9476039577284925), (&#39;laughable&#39;, -3.997742361448161), (&#39;breathtaking&#39;, -4.0288613638212984), (&#39;lame&#39;, -4.09433854250181)]
Progress:0.4 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.6601338239137795), (&#39;brilliant&#39;, -3.397999174364445), (&#39;laughable&#39;, -3.7354570440785357), (&#39;pathetic&#39;, -3.7505335935327992), (&#39;superb&#39;, -3.755228603482433), (&#39;lame&#39;, -3.8176977353618375), (&#39;fantastic&#39;, -3.8748410412834753), (&#39;breathtaking&#39;, -3.879859908160721), (&#39;remarkable&#39;, -3.9621713732302415)]
Progress:0.41 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.723913619118524), (&#39;brilliant&#39;, -3.356315775014877), (&#39;superb&#39;, -3.5127554095203064), (&#39;laughable&#39;, -3.654284796257907), (&#39;pathetic&#39;, -3.7027689398609156), (&#39;fantastic&#39;, -3.802129966420995), (&#39;bad&#39;, -3.830493183231909), (&#39;lame&#39;, -3.836810604457255), (&#39;wonderful&#39;, -3.8407130119169244)]
Progress:0.42 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.07746334039869), (&#39;brilliant&#39;, -3.193579711547745), (&#39;superb&#39;, -3.3174126390259815), (&#39;wonderful&#39;, -3.6484668308286072), (&#39;laughable&#39;, -3.795550928219548), (&#39;pathetic&#39;, -3.876556455593788), (&#39;breathtaking&#39;, -3.877731921309592), (&#39;fantastic&#39;, -3.9403505418977014), (&#39;hilarious&#39;, -4.033289103517084)]
Progress:0.43 [(&#39;terrible&#39;, -0.0), (&#39;brilliant&#39;, -3.2759341801836865), (&#39;horrible&#39;, -3.332535960779125), (&#39;superb&#39;, -3.450915115646111), (&#39;wonderful&#39;, -3.736073235604008), (&#39;great&#39;, -3.8770923114423304), (&#39;fantastic&#39;, -3.953520942341758), (&#39;breathtaking&#39;, -4.001972259106058), (&#39;stupid&#39;, -4.024976367920043), (&#39;pathetic&#39;, -4.031657342379318)]
Progress:0.44 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.2028381673926494), (&#39;brilliant&#39;, -3.269424745519839), (&#39;superb&#39;, -3.598476042818096), (&#39;laughable&#39;, -3.8670405943159656), (&#39;wonderful&#39;, -3.921350117316704), (&#39;pathetic&#39;, -3.967969607661597), (&#39;fantastic&#39;, -3.9911581150606956), (&#39;stupid&#39;, -3.993494320552381), (&#39;hilarious&#39;, -3.994752078276405)]
Progress:0.45 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.76125969755545), (&#39;brilliant&#39;, -3.0972769273708867), (&#39;superb&#39;, -3.5778936913269246), (&#39;bad&#39;, -3.8051113211650023), (&#39;fantastic&#39;, -3.840252606612717), (&#39;terrific&#39;, -3.877918225429699), (&#39;pathetic&#39;, -3.8982546803037494), (&#39;laughable&#39;, -3.9077405277554456), (&#39;wonderful&#39;, -3.9307065519942928)]
Progress:0.46 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8502118880957608), (&#39;superb&#39;, -3.2065352384338097), (&#39;brilliant&#39;, -3.269422329972904), (&#39;laughable&#39;, -3.7342180447598925), (&#39;breathtaking&#39;, -3.8299548621613977), (&#39;lame&#39;, -3.8486592795689245), (&#39;pathetic&#39;, -3.8882063647296867), (&#39;fantastic&#39;, -3.9407940187429285), (&#39;wonderful&#39;, -3.961607993581969)]
Progress:0.47 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.828447511394193), (&#39;brilliant&#39;, -3.4739010546738633), (&#39;superb&#39;, -3.4763893590887167), (&#39;fantastic&#39;, -3.581061496216113), (&#39;lame&#39;, -3.763450316209067), (&#39;laughable&#39;, -3.7901003761664827), (&#39;breathtaking&#39;, -3.9015600040405602), (&#39;pathetic&#39;, -3.930328461414635), (&#39;terrific&#39;, -3.937555087217021)]
Progress:0.48 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.764055614866774), (&#39;brilliant&#39;, -3.255540942187197), (&#39;superb&#39;, -3.3448397624491815), (&#39;lame&#39;, -3.622227718088523), (&#39;fantastic&#39;, -3.692683943977049), (&#39;terrific&#39;, -3.760776750440425), (&#39;pathetic&#39;, -3.8169940139951146), (&#39;laughable&#39;, -3.912082496437288), (&#39;hilarious&#39;, -3.951208495187475)]
Progress:0.49 [(&#39;terrible&#39;, -0.0), (&#39;superb&#39;, -3.069033157557233), (&#39;brilliant&#39;, -3.075599826366681), (&#39;horrible&#39;, -3.1371459667387254), (&#39;fantastic&#39;, -3.486136820103545), (&#39;pathetic&#39;, -3.4891231980994424), (&#39;terrific&#39;, -3.613779679296899), (&#39;laughable&#39;, -3.7082004724298336), (&#39;breathtaking&#39;, -3.7271089590477686), (&#39;lame&#39;, -3.8111642345911108)]
Progress:0.5 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.1115513244796436), (&#39;brilliant&#39;, -3.325645463248577), (&#39;superb&#39;, -3.3919999558850993), (&#39;fantastic&#39;, -3.678968812961023), (&#39;pathetic&#39;, -3.7144591103087508), (&#39;lame&#39;, -3.943067389305184), (&#39;breathtaking&#39;, -3.9898967755073125), (&#39;terrific&#39;, -4.034545537691212), (&#39;bad&#39;, -4.077745111616144)]
Progress:0.51 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.2151202263959062), (&#39;superb&#39;, -3.3319872856113015), (&#39;brilliant&#39;, -3.585345975146444), (&#39;fantastic&#39;, -3.877295766108294), (&#39;lame&#39;, -3.9305456605232334), (&#39;pathetic&#39;, -3.9361484798169575), (&#39;laughable&#39;, -3.970858224271965), (&#39;breathtaking&#39;, -4.103949284803123), (&#39;terrific&#39;, -4.146250533133547)]
Progress:0.52 [(&#39;terrible&#39;, -0.0), (&#39;superb&#39;, -3.137481852849991), (&#39;horrible&#39;, -3.236794071887919), (&#39;brilliant&#39;, -3.306736013265137), (&#39;laughable&#39;, -3.611518747188236), (&#39;fantastic&#39;, -3.681776700322966), (&#39;pathetic&#39;, -3.8116919163194964), (&#39;breathtaking&#39;, -3.9083620063294666), (&#39;ridiculous&#39;, -3.9850643328320907), (&#39;lame&#39;, -4.008609747349892)]
Progress:0.53 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.1187953952376297), (&#39;superb&#39;, -3.182637874102477), (&#39;brilliant&#39;, -3.2824376482394824), (&#39;laughable&#39;, -3.6519872759248497), (&#39;fantastic&#39;, -3.721926078785065), (&#39;hilarious&#39;, -3.8794689701493223), (&#39;pathetic&#39;, -3.9638059582174265), (&#39;phenomenal&#39;, -4.0568740204380065), (&#39;ridiculous&#39;, -4.090693703376699)]
Progress:0.54 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.018596848206083), (&#39;brilliant&#39;, -3.258034509683753), (&#39;laughable&#39;, -3.2807684385238396), (&#39;superb&#39;, -3.287483809014398), (&#39;boring&#39;, -3.4728842738093135), (&#39;fantastic&#39;, -3.663201961070087), (&#39;hilarious&#39;, -3.6835412327372583), (&#39;awful&#39;, -3.7864336064239987), (&#39;pathetic&#39;, -3.894217179719121)]
Progress:0.55 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.153659889053645), (&#39;superb&#39;, -3.3433915053689005), (&#39;brilliant&#39;, -3.4460779267443677), (&#39;laughable&#39;, -3.545883850011711), (&#39;fantastic&#39;, -3.714918885210454), (&#39;ridiculous&#39;, -3.74489374574429), (&#39;breathtaking&#39;, -3.766092568227881), (&#39;hilarious&#39;, -3.845552826705626), (&#39;fabulous&#39;, -3.8902879904219825)]
Progress:0.56 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.101220277024857), (&#39;brilliant&#39;, -3.1523171229315747), (&#39;superb&#39;, -3.2358767524346272), (&#39;fantastic&#39;, -3.536309498831494), (&#39;laughable&#39;, -3.589715282629644), (&#39;ridiculous&#39;, -3.7208229810238502), (&#39;breathtaking&#39;, -3.7274359635157785), (&#39;fabulous&#39;, -3.7919928115968435), (&#39;hilarious&#39;, -3.8146400946044694)]
Progress:0.57 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.116003971443442), (&#39;brilliant&#39;, -3.218689960125203), (&#39;fantastic&#39;, -3.437372639576054), (&#39;laughable&#39;, -3.5612736490176014), (&#39;superb&#39;, -3.6720490963195656), (&#39;ridiculous&#39;, -3.832729568139751), (&#39;boring&#39;, -3.855254773663552), (&#39;breathtaking&#39;, -3.8555376692364667), (&#39;pathetic&#39;, -3.8573814470780494)]
Progress:0.58 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.281888459768499), (&#39;brilliant&#39;, -3.338826309359405), (&#39;fantastic&#39;, -3.4612613718969327), (&#39;laughable&#39;, -3.5130288745616274), (&#39;superb&#39;, -3.634648582801948), (&#39;ridiculous&#39;, -3.6812968714088483), (&#39;breathtaking&#39;, -3.7912556272033546), (&#39;magnificent&#39;, -3.8104038039199937), (&#39;hilarious&#39;, -3.8322968149565564)]
Progress:0.59 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.115825353382858), (&#39;fantastic&#39;, -3.330601629871516), (&#39;brilliant&#39;, -3.395119922672406), (&#39;laughable&#39;, -3.6262326755136316), (&#39;ridiculous&#39;, -3.6561416051953914), (&#39;superb&#39;, -3.695231099437528), (&#39;breathtaking&#39;, -3.74078202325651), (&#39;pathetic&#39;, -3.7857209515497536), (&#39;haunting&#39;, -3.8420642539858147)]
Progress:0.6 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8195865492956487), (&#39;fantastic&#39;, -3.232370381335543), (&#39;brilliant&#39;, -3.335976565938482), (&#39;breathtaking&#39;, -3.687858063147062), (&#39;pathetic&#39;, -3.768774204478926), (&#39;superb&#39;, -3.7890197338099973), (&#39;magnificent&#39;, -3.799677006426847), (&#39;ridiculous&#39;, -3.869594433662081), (&#39;lame&#39;, -3.894094686314818)]
Progress:0.61 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.0728680550525693), (&#39;fantastic&#39;, -3.4148789487094), (&#39;brilliant&#39;, -3.6405216038887076), (&#39;breathtaking&#39;, -3.878636724146299), (&#39;superb&#39;, -3.8841296097657922), (&#39;magnificent&#39;, -3.9715760314093904), (&#39;laughable&#39;, -4.0179682248157205), (&#39;haunting&#39;, -4.026108383185635), (&#39;dreadful&#39;, -4.071013289446259)]
Progress:0.62 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.716024673260475), (&#39;brilliant&#39;, -3.478029319867433), (&#39;fantastic&#39;, -3.5914692184144514), (&#39;magnificent&#39;, -3.896096576227817), (&#39;breathtaking&#39;, -3.9669945204203403), (&#39;dreadful&#39;, -3.9864113085745734), (&#39;haunting&#39;, -4.037195006022838), (&#39;lame&#39;, -4.090543830740831), (&#39;laughable&#39;, -4.113014014158503)]
Progress:0.63 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.787066675583338), (&#39;brilliant&#39;, -3.5632065874846774), (&#39;fantastic&#39;, -3.5686152148042374), (&#39;laughable&#39;, -3.7468970296991944), (&#39;magnificent&#39;, -3.8059870210497464), (&#39;breathtaking&#39;, -3.8409011349625772), (&#39;pathetic&#39;, -3.8887431130308676), (&#39;lame&#39;, -3.9079178109970987), (&#39;ridiculous&#39;, -3.953255269205686)]
Progress:0.64 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.7877712401459362), (&#39;ridiculous&#39;, -3.5506963125858175), (&#39;brilliant&#39;, -3.6385712465624067), (&#39;fantastic&#39;, -3.6454199289205698), (&#39;lame&#39;, -3.7502776389820998), (&#39;breathtaking&#39;, -3.8052086953075173), (&#39;pathetic&#39;, -3.8069043453211315), (&#39;laughable&#39;, -3.8819285563482944), (&#39;fabulous&#39;, -3.9172018691776067)]
Progress:0.65 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.793892106663677), (&#39;ridiculous&#39;, -3.6347211271878526), (&#39;brilliant&#39;, -3.6608966673549728), (&#39;fantastic&#39;, -3.684451923067048), (&#39;pathetic&#39;, -3.697735092884331), (&#39;laughable&#39;, -3.7504626668525454), (&#39;breathtaking&#39;, -3.8168018042374188), (&#39;lame&#39;, -3.852569158591643), (&#39;fabulous&#39;, -3.941128045507945)]
Progress:0.66 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8782063448813595), (&#39;brilliant&#39;, -3.6458256010587387), (&#39;ridiculous&#39;, -3.7279932102516655), (&#39;pathetic&#39;, -3.7911036406493213), (&#39;fantastic&#39;, -3.886606532425245), (&#39;laughable&#39;, -3.9337856656553454), (&#39;magnificent&#39;, -3.9471817113704724), (&#39;lame&#39;, -3.9571954589952023), (&#39;fabulous&#39;, -4.053792408916167)]
Progress:0.67 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.7129508631504513), (&#39;brilliant&#39;, -3.5474335419476457), (&#39;ridiculous&#39;, -3.7496043118441547), (&#39;fantastic&#39;, -3.83715747064835), (&#39;lame&#39;, -3.881438551775267), (&#39;pathetic&#39;, -3.8870390179907077), (&#39;magnificent&#39;, -3.923162866611613), (&#39;wonderful&#39;, -4.012897557187215), (&#39;breathtaking&#39;, -4.014507686455303)]
Progress:0.68 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.6303087341832994), (&#39;brilliant&#39;, -3.3464548670962717), (&#39;superb&#39;, -3.8329287208694915), (&#39;pathetic&#39;, -3.866426361942947), (&#39;fantastic&#39;, -3.8834879982664225), (&#39;magnificent&#39;, -3.887196543128739), (&#39;ridiculous&#39;, -3.9121218075608786), (&#39;lame&#39;, -3.92424998107895), (&#39;breathtaking&#39;, -3.9746015420165093)]
Progress:0.69 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.6135103973992764), (&#39;brilliant&#39;, -3.402121998175835), (&#39;magnificent&#39;, -3.7733815813331697), (&#39;superb&#39;, -3.8378321159447055), (&#39;dreadful&#39;, -3.8650581097411965), (&#39;fantastic&#39;, -3.906230684167045), (&#39;ridiculous&#39;, -3.9089948271258073), (&#39;pathetic&#39;, -4.0062557823786875), (&#39;lame&#39;, -4.020710730093272)]
Progress:0.7 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.4979833559425173), (&#39;brilliant&#39;, -3.255865552391195), (&#39;magnificent&#39;, -3.6999127347411185), (&#39;superb&#39;, -3.7178295174620364), (&#39;fantastic&#39;, -3.7272627016252904), (&#39;pathetic&#39;, -3.7969017784742873), (&#39;dreadful&#39;, -3.830064573021702), (&#39;laughable&#39;, -3.857336414688362), (&#39;breathtaking&#39;, -3.8755912022341588)]
Progress:0.71 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.5284100120738633), (&#39;brilliant&#39;, -3.281729320379148), (&#39;dreadful&#39;, -3.777737120506343), (&#39;pathetic&#39;, -3.8512302324837657), (&#39;superb&#39;, -3.885190532804791), (&#39;fantastic&#39;, -3.947458970406462), (&#39;breathtaking&#39;, -3.9507679021853135), (&#39;laughable&#39;, -4.006033259239), (&#39;wonderful&#39;, -4.021386739658449)]
Progress:0.72 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.9874598365243594), (&#39;brilliant&#39;, -3.102390289998375), (&#39;superb&#39;, -3.828935308506984), (&#39;fantastic&#39;, -3.8582121721695666), (&#39;wonderful&#39;, -3.9848351082158473), (&#39;breathtaking&#39;, -3.9978475436751055), (&#39;dreadful&#39;, -4.007342335405401), (&#39;pathetic&#39;, -4.009034482760945), (&#39;lame&#39;, -4.089250774799445)]
Progress:0.73 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.827466524277995), (&#39;brilliant&#39;, -3.1615349004980704), (&#39;pathetic&#39;, -3.754761363634609), (&#39;fantastic&#39;, -3.887052414431559), (&#39;breathtaking&#39;, -3.8989167249630725), (&#39;dreadful&#39;, -3.9225908526432476), (&#39;wonderful&#39;, -3.9252357707748766), (&#39;horrendous&#39;, -3.935624525206476), (&#39;lame&#39;, -3.9971526569790785)]
Progress:0.74 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.871174611250882), (&#39;brilliant&#39;, -3.2662304871374914), (&#39;fantastic&#39;, -3.7126372149354068), (&#39;stupid&#39;, -3.7610427186750437), (&#39;pathetic&#39;, -3.868718523938397), (&#39;wonderful&#39;, -3.915861343292705), (&#39;horrendous&#39;, -3.937878970536581), (&#39;breathtaking&#39;, -4.091099000317098), (&#39;dreadful&#39;, -4.115363164662117)]
Progress:0.75 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8784825662505376), (&#39;brilliant&#39;, -3.420317591893649), (&#39;fantastic&#39;, -3.700711426575647), (&#39;wonderful&#39;, -3.7476649070734327), (&#39;pathetic&#39;, -3.85414560874648), (&#39;stupid&#39;, -4.064642115058354), (&#39;breathtaking&#39;, -4.107069097594986), (&#39;horrendous&#39;, -4.117593607371204), (&#39;marvelous&#39;, -4.198533120267949)]
Progress:0.76 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.7351023602221867), (&#39;brilliant&#39;, -3.3292753788333735), (&#39;pathetic&#39;, -3.4741009784980177), (&#39;fantastic&#39;, -3.543004745742391), (&#39;wonderful&#39;, -3.5569360231845004), (&#39;laughable&#39;, -3.729303288052469), (&#39;breathtaking&#39;, -3.7621278851937414), (&#39;superb&#39;, -3.7771646516298927), (&#39;horrendous&#39;, -3.8312169831815592)]
Progress:0.77 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.634408523974374), (&#39;brilliant&#39;, -3.257299890095159), (&#39;laughable&#39;, -3.505325447662299), (&#39;pathetic&#39;, -3.587732281294579), (&#39;fantastic&#39;, -3.6096890456186035), (&#39;wonderful&#39;, -3.757919038189487), (&#39;horrendous&#39;, -3.776848542456144), (&#39;breathtaking&#39;, -3.8020651604271873), (&#39;stupid&#39;, -3.849843133097568)]
Progress:0.78 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.9083021453159272), (&#39;brilliant&#39;, -3.5637570785813986), (&#39;laughable&#39;, -3.6023141537641754), (&#39;fantastic&#39;, -3.718684342471911), (&#39;wonderful&#39;, -3.8676216665717167), (&#39;pathetic&#39;, -3.893534918480537), (&#39;marvelous&#39;, -3.902633404629294), (&#39;breathtaking&#39;, -3.9268296014769914), (&#39;stupid&#39;, -3.931904354148739)]
Progress:0.79 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8409967481042555), (&#39;laughable&#39;, -3.6629784212957084), (&#39;brilliant&#39;, -3.703520343106405), (&#39;breathtaking&#39;, -3.7692122106047203), (&#39;dire&#39;, -3.7782376454489426), (&#39;marvelous&#39;, -3.830430524244488), (&#39;fantastic&#39;, -3.8413756531561343), (&#39;dreadful&#39;, -3.851062913917513), (&#39;fabulous&#39;, -3.9000800155318336)]
Progress:0.8 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.304029397344581), (&#39;laughable&#39;, -3.9187750021242604), (&#39;dire&#39;, -3.928264774622541), (&#39;fantastic&#39;, -3.9402315106396992), (&#39;fabulous&#39;, -3.9654548186590945), (&#39;brilliant&#39;, -3.9754621595729556), (&#39;breathtaking&#39;, -4.022526705173569), (&#39;dreadful&#39;, -4.030098805496747), (&#39;superb&#39;, -4.074185181979759)]
Progress:0.81 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.5261949117771114), (&#39;wonderful&#39;, -3.799829704025303), (&#39;fantastic&#39;, -3.8538411000533688), (&#39;fabulous&#39;, -3.9514302007708912), (&#39;superb&#39;, -4.115822303940166), (&#39;phenomenal&#39;, -4.138693154862801), (&#39;breathtaking&#39;, -4.174791226611573), (&#39;dire&#39;, -4.178953114752066), (&#39;brilliant&#39;, -4.182497237485823)]
Progress:0.82 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.3003685747668956), (&#39;fantastic&#39;, -3.9340853614913183), (&#39;superb&#39;, -3.961260915008417), (&#39;fabulous&#39;, -4.007878658764461), (&#39;brilliant&#39;, -4.065608464985201), (&#39;dreadful&#39;, -4.14251077807687), (&#39;fine&#39;, -4.155192490709154), (&#39;wonderful&#39;, -4.164533641845059), (&#39;breathtaking&#39;, -4.168242751216982)]
Progress:0.83 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.6313490178846157), (&#39;superb&#39;, -3.984190496238942), (&#39;brilliant&#39;, -4.111249415296756), (&#39;horrendous&#39;, -4.137903058749896), (&#39;fantastic&#39;, -4.155635728560963), (&#39;fabulous&#39;, -4.160124679896802), (&#39;dire&#39;, -4.206372073063586), (&#39;pathetic&#39;, -4.207383673828694), (&#39;breathtaking&#39;, -4.249720735920193)]
Progress:0.84 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.121141925622775), (&#39;fantastic&#39;, -3.916777891314931), (&#39;superb&#39;, -3.9307132554726247), (&#39;brilliant&#39;, -3.9879462156412235), (&#39;breathtaking&#39;, -4.06663366317498), (&#39;fabulous&#39;, -4.091532394710557), (&#39;dire&#39;, -4.139806758700985), (&#39;horrendous&#39;, -4.218820758657895), (&#39;dreadful&#39;, -4.2555072604343485)]
Progress:0.85 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.157930083625574), (&#39;brilliant&#39;, -3.6797470933005036), (&#39;horrendous&#39;, -3.88339005898192), (&#39;fantastic&#39;, -3.941912246143473), (&#39;dreadful&#39;, -3.9502361637672676), (&#39;horrid&#39;, -3.9696733158315585), (&#39;fabulous&#39;, -3.9899814321583613), (&#39;breathtaking&#39;, -4.004698806658384), (&#39;laughable&#39;, -4.019195837727104)]
Progress:0.86 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.063809454191829), (&#39;brilliant&#39;, -3.1224228106701593), (&#39;superb&#39;, -3.7417939983859947), (&#39;fabulous&#39;, -3.794002107267695), (&#39;fantastic&#39;, -3.8288748193929747), (&#39;horrendous&#39;, -3.8494958345798422), (&#39;breathtaking&#39;, -3.870590254656486), (&#39;dreadful&#39;, -3.8980986000751825), (&#39;laughable&#39;, -3.9107135846608503)]
Progress:0.87 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.77589461895389), (&#39;brilliant&#39;, -3.0476630873570847), (&#39;superb&#39;, -3.724609319591195), (&#39;laughable&#39;, -3.8380294977070912), (&#39;fabulous&#39;, -3.840082370775877), (&#39;horrendous&#39;, -3.8733595209462375), (&#39;breathtaking&#39;, -3.9712340785452014), (&#39;pathetic&#39;, -3.9712948804772825), (&#39;dreadful&#39;, -3.9933202253857556)]
Progress:0.88 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.6091484654509958), (&#39;brilliant&#39;, -2.8341314506077437), (&#39;horrendous&#39;, -3.7801426568925804), (&#39;fabulous&#39;, -3.7980211630192757), (&#39;dreadful&#39;, -3.8374300331569726), (&#39;dire&#39;, -3.9740454560000367), (&#39;pathetic&#39;, -4.005503635622233), (&#39;superb&#39;, -4.00790633550221), (&#39;breathtaking&#39;, -4.010321189622527)]
Progress:0.89 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8061487481057923), (&#39;brilliant&#39;, -3.117537335035275), (&#39;dreadful&#39;, -3.9046270341911518), (&#39;fabulous&#39;, -3.9212021966587542), (&#39;superb&#39;, -3.9224484111277884), (&#39;fantastic&#39;, -3.9287205969094043), (&#39;horrendous&#39;, -3.9334385805439975), (&#39;marvelous&#39;, -4.028031467981574), (&#39;magnificent&#39;, -4.032040729296659)]
Progress:0.9 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8674102428193162), (&#39;brilliant&#39;, -3.414279465320048), (&#39;horrendous&#39;, -3.7415830823871037), (&#39;dreadful&#39;, -3.8115691010949386), (&#39;fabulous&#39;, -3.9524421290768608), (&#39;magnificent&#39;, -3.959911192029792), (&#39;dire&#39;, -4.010516349244781), (&#39;fantastic&#39;, -4.0262126324032455), (&#39;phenomenal&#39;, -4.036118789453933)]
Progress:0.91 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8560766000871163), (&#39;brilliant&#39;, -3.5576203352569715), (&#39;horrendous&#39;, -3.8140242304555803), (&#39;fantastic&#39;, -3.8653865854004907), (&#39;great&#39;, -3.886657278111274), (&#39;magnificent&#39;, -4.0056578358077894), (&#39;dreadful&#39;, -4.024818023296332), (&#39;wonderful&#39;, -4.0362906053936936), (&#39;laughable&#39;, -4.048849544410786)]
Progress:0.92 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.1738162915562578), (&#39;brilliant&#39;, -3.7497642722399624), (&#39;superb&#39;, -3.8339194439996747), (&#39;horrendous&#39;, -3.897149114990593), (&#39;dreadful&#39;, -4.127503205318968), (&#39;breathtaking&#39;, -4.12898889826799), (&#39;fantastic&#39;, -4.146463740527068), (&#39;magnificent&#39;, -4.170777140195071), (&#39;marvelous&#39;, -4.176383921671143)]
Progress:0.93 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.0325921858551794), (&#39;brilliant&#39;, -3.4473822511866015), (&#39;superb&#39;, -3.843042470925995), (&#39;horrendous&#39;, -4.064650432595171), (&#39;dreadful&#39;, -4.091815955645666), (&#39;wonderful&#39;, -4.092865130956425), (&#39;magnificent&#39;, -4.132468047765273), (&#39;breathtaking&#39;, -4.148548961546576), (&#39;stupid&#39;, -4.162609277625845)]
Progress:0.94 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.029565843674032), (&#39;brilliant&#39;, -3.228121816011993), (&#39;superb&#39;, -3.4715404782760153), (&#39;horrendous&#39;, -3.941855977226284), (&#39;pathetic&#39;, -3.9443682048041704), (&#39;phenomenal&#39;, -4.025218871578845), (&#39;dreadful&#39;, -4.0751642715119205), (&#39;breathtaking&#39;, -4.099616272332179), (&#39;hilarious&#39;, -4.1039233085929405)]
Progress:0.95 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.9906497815320066), (&#39;brilliant&#39;, -3.6020470634169026), (&#39;superb&#39;, -3.690858780493361), (&#39;pathetic&#39;, -3.8686169638822925), (&#39;stupid&#39;, -3.9721304495763086), (&#39;dreadful&#39;, -4.018190049438689), (&#39;horrendous&#39;, -4.0453415306557385), (&#39;bad&#39;, -4.08823253895453), (&#39;breathtaking&#39;, -4.089245498585952)]
Progress:0.96 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.896330508329976), (&#39;superb&#39;, -3.6345600224826558), (&#39;brilliant&#39;, -3.6816738329442513), (&#39;pathetic&#39;, -3.7847597216119606), (&#39;masterful&#39;, -3.95700657653414), (&#39;breathtaking&#39;, -4.090595290864077), (&#39;phenomenal&#39;, -4.105380828499431), (&#39;fantastic&#39;, -4.107556763961269), (&#39;horrendous&#39;, -4.125436987345343)]
Progress:0.97 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8950082913538573), (&#39;brilliant&#39;, -3.4129231922796706), (&#39;superb&#39;, -3.5726131055652344), (&#39;masterful&#39;, -3.927594458513282), (&#39;phenomenal&#39;, -3.9642706192398345), (&#39;pathetic&#39;, -3.97682621835208), (&#39;fantastic&#39;, -4.024495902074088), (&#39;marvelous&#39;, -4.145307274629247), (&#39;magnificent&#39;, -4.150151948367563)]
Progress:0.98 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.993295607765446), (&#39;superb&#39;, -3.512848882523045), (&#39;brilliant&#39;, -3.5357941464290548), (&#39;phenomenal&#39;, -3.8630501153381434), (&#39;masterful&#39;, -3.875947385844044), (&#39;pathetic&#39;, -3.9550301077227847), (&#39;marvelous&#39;, -4.0257674836281385), (&#39;terrific&#39;, -4.039200475424797), (&#39;miserable&#39;, -4.047453981705279)]
Progress:0.99 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.996206906543707), (&#39;brilliant&#39;, -3.2519744548350356), (&#39;superb&#39;, -3.695620862068613), (&#39;pathetic&#39;, -3.771017703675723), (&#39;phenomenal&#39;, -3.795246889115822), (&#39;terrific&#39;, -3.930512873228861), (&#39;masterful&#39;, -4.022962019748555), (&#39;fantastic&#39;, -4.037999652020295), (&#39;marvelous&#39;, -4.1087754152647085)]
[(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8727079868976175), (&#39;brilliant&#39;, -3.3788871655393007), (&#39;pathetic&#39;, -3.877319797611651), (&#39;phenomenal&#39;, -3.892570702195353), (&#39;superb&#39;, -3.9095109680194473), (&#39;bad&#39;, -3.949674801907263), (&#39;masterful&#39;, -4.017110299342879), (&#39;marvelous&#39;, -4.117363658337549), (&#39;dreadful&#39;, -4.2133555584662705)]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The Word Embeddings get trained according to the task the neural network is trained on:<ul>
<li>Sentiment Analysis: Embeddings are grouped together depending on how Positive/Negative they are<ul>
<li>Or depending on How they effect a Review being good or bad.</li>
</ul>
</li>
<li>Filling the Blank: Embeddings are grouped together depending on how close/far they are when filling blanks.<ul>
<li>Solve: "<em>I ___ You so much!</em>"<ul>
<li>Possible Solution — "I hate You so much!"</li>
<li>Possible Solution — "I love You so much!"</li>
</ul>
</li>
<li>In this sense, hate &amp; love are pretty close!</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Meaning-is-Derived-from-Loss">Meaning is Derived from Loss<a class="anchor-link" href="#Meaning-is-Derived-from-Loss">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%" file="static/imgs/11/loss_matters.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Neural-Networks-don't-really-LEARN-Data;-they-minimize-Loss-Functions">Neural Networks don't really <strong>LEARN</strong> Data; they minimize Loss Functions<a class="anchor-link" href="#Neural-Networks-don't-really-LEARN-Data;-they-minimize-Loss-Functions">&#182;</a></h3><h3 id="The-Choice-of-Loss-Function-Determines-the-Network's-Knowledge">The Choice of Loss Function Determines the Network's Knowledge<a class="anchor-link" href="#The-Choice-of-Loss-Function-Determines-the-Network's-Knowledge">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Considering Learning is all about Minimizing a Loss Function gives a broader understanding of how neural networks work.</li>
<li>Different Kinds of Layers, Activations, Regularization Techniques, datasets, aren't really that different.<ul>
<li>For Example: If the network is overfitting, you can augment the loss fucntion by choosing simpler non-linearities, adding dropout, enforcing regularizations, adding more data and so on..</li>
<li>All of these techniques will have a similar effect on the loss function and the learning behavior.</li>
</ul>
</li>
<li>With learning, everything is contained within the loss function.<ul>
<li>&amp; <strong>If something is going wrong, remember that the solution is in the Loss Function</strong>.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="King---Man-+-Woman-~=-Queen">King - Man + Woman ~= Queen<a class="anchor-link" href="#King---Man-+-Woman-~=-Queen">&#182;</a></h2><h3 id="Word-Analogies-are-an-interesting-consequence-of-the-previously-trained-network">Word Analogies are an interesting consequence of the previously trained network<a class="anchor-link" href="#Word-Analogies-are-an-interesting-consequence-of-the-previously-trained-network">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>This represents one of the famous properties of word embeddings (or trained vectors).</li>
<li>The task of filling in the blank creates an interesting property called "word analogies".<ul>
<li>whereas you can take different embeddings and perform algebric operations on them.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">analogy</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;terrible&#39;</span><span class="p">,</span> <span class="s1">&#39;good&#39;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;bad&#39;</span><span class="p">]):</span>
    <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W0</span><span class="o">*</span><span class="n">W0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">norms</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="n">norms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># normalize weights for vector-level operations</span>
    <span class="n">normed_weights</span> <span class="o">=</span> <span class="n">W0</span> <span class="o">*</span> <span class="n">norms</span>
    <span class="n">query_vect</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">W0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">positive</span><span class="p">:</span>
        <span class="n">query_vect</span> <span class="o">+=</span> <span class="n">normed_weights</span><span class="p">[</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">negative</span><span class="p">:</span>
        <span class="n">query_vect</span> <span class="o">-=</span> <span class="n">normed_weights</span><span class="p">[</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]]</span>
    
    <span class="n">scores</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">word2index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">raw_difference</span> <span class="o">=</span> <span class="n">W0</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">-</span> <span class="n">query_vect</span>
        <span class="n">squared_difference</span> <span class="o">=</span> <span class="n">raw_difference</span> <span class="o">*</span> <span class="n">raw_difference</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">squared_difference</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">scores</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">analogy</span><span class="p">([</span><span class="s1">&#39;elizabeth&#39;</span><span class="p">,</span> <span class="s1">&#39;he&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;she&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;christopher&#39;, -196.14901513962437),
 (&#39;tom&#39;, -196.63100891837615),
 (&#39;william&#39;, -196.71139862402313),
 (&#39;mr&#39;, -196.78191513069368),
 (&#39;simon&#39;, -196.82182610970864),
 (&#39;it&#39;, -196.82971818242368),
 (&#39;him&#39;, -196.83517620210762),
 (&#39;been&#39;, -196.85949829130325),
 (&#39;gary&#39;, -196.90340914909922)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Word-Analogies">Word Analogies<a class="anchor-link" href="#Word-Analogies">&#182;</a></h2><h3 id="Linear-Compression-of-an-Existing-Property-in-the-Data">Linear Compression of an Existing Property in the Data<a class="anchor-link" href="#Linear-Compression-of-an-Existing-Property-in-the-Data">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:33%" file="static/imgs/11/word_analogies.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">king</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">]</span>
<span class="n">man</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">0</span><span class="p">]</span>
<span class="n">woman</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">8</span><span class="p">]</span>
<span class="n">queen</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span><span class="n">x_i</span> <span class="o">-</span> <span class="n">y_i</span> <span class="k">for</span> <span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">king</span><span class="p">,</span> <span class="n">man</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.09999999999999998, 0.1]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span><span class="n">x_i</span> <span class="o">-</span> <span class="n">y_i</span> <span class="k">for</span> <span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">queen</span><span class="p">,</span> <span class="n">woman</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.1, 0.19999999999999996]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The relative usefulness to the final prediction between "Man"/"King" &amp; "Woman"/"Queen" is similar, Why?<ul>
<li>The difference between "King" and "Man" Leaves a vector of Royalty.</li>
<li><strong>There are a bunch of male/female related words in one grouping, &amp; a bunch of king/queen related words in another grouping.</strong><ul>
<li>&amp; because the relative distance between the two group is constant, it means that the distances between each grouping items will be relatively the same.</li>
</ul>
</li>
<li>This can be traced back to the chosen loss.</li>
</ul>
</li>
<li><strong>This is more about the properties of language than deep learning</strong>.<ul>
<li>Any linear compression of these co-occurent statistics will yield the same results.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h2><h3 id="You've-learned-a-lot-about-Word-embeddings-&amp;-the-impact-of-loss-on-learning">You've learned a lot about Word embeddings &amp; the impact of loss on learning<a class="anchor-link" href="#You've-learned-a-lot-about-Word-embeddings-&amp;-the-impact-of-loss-on-learning">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We've unpacked the principles of using neural networks to model language.</li>
<li><strong>I encourage you to build the examples of this chapter from scratch.</strong></li>
</ul>

</div>
</div>
</div>
</div>
 

