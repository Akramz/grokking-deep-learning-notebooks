---

title: Neural Networks that write like Shakespeare
keywords: fastai
sidebar: home_sidebar

summary: "Recurrent Layers for Varible-length data"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 12.RNNs.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this Chapter:</p>
<ul>
<li>The Challenge of arbitrary length</li>
<li>The surprising power of averaged word vectors</li>
<li>The limitations of bag-of-words vectors</li>
<li>Using identity vectors to sum word embeddings</li>
<li>Learning the transition matrices</li>
<li>Learning to create useful sentence vectors</li>
<li>Forward Propagation in Python</li>
<li>Forward Propagation and backpropagation with arbitrary length</li>
<li>Weight update with arbitrary length<blockquote><p>"There is something magical about recurrent neural networks." â€” Andrej Karpathy "<a href="http: //karpathy.github.io/2015/05/21/rnn-effectiveness/">The unreasonable effectiveness of Recurrent Neural Networks</a>".</p>
</blockquote>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Challenge-of-Arbitrary-Length">The Challenge of Arbitrary Length<a class="anchor-link" href="#The-Challenge-of-Arbitrary-Length">&#182;</a></h2><h3 id="Let's-Model-Arbitrary-Long-Sequences-of-Data-using-Neural-Networks!">Let's Model Arbitrary Long Sequences of Data using Neural Networks!<a class="anchor-link" href="#Let's-Model-Arbitrary-Long-Sequences-of-Data-using-Neural-Networks!">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width: 50%;" file="static/imgs/12/stacked_embeddings.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Do-comparisons-really-matter?">Do comparisons really matter?<a class="anchor-link" href="#Do-comparisons-really-matter?">&#182;</a></h2><h3 id="Why-you-should-care-about-whether-you-can-compare-two-sentence-vectors?">Why you should care about whether you can compare two sentence vectors?<a class="anchor-link" href="#Why-you-should-care-about-whether-you-can-compare-two-sentence-vectors?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:33%" file="static/imgs/12/sentence_avg.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Suprising-Power-of-Averaged-Word-Vectors">The Suprising Power of Averaged Word Vectors<a class="anchor-link" href="#The-Suprising-Power-of-Averaged-Word-Vectors">&#182;</a></h2><h3 id="It's-the-amazingly-powerful-go-to-tool-for-neural-prediction">It's the amazingly powerful go-to tool for neural prediction<a class="anchor-link" href="#It's-the-amazingly-powerful-go-to-tool-for-neural-prediction">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>To play w/ the word embeddings, let's first train them:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">IMDB_PATH</span> <span class="o">=</span> <span class="s1">&#39;/Users/mohamedakramzaytar/data/2019/Q2/kaggle/IMDB/reviews.txt&#39;</span>
<span class="n">IMDB_LABEL_PATH</span> <span class="o">=</span> <span class="s1">&#39;/Users/mohamedakramzaytar/data/2019/Q2/kaggle/IMDB/labels.txt&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">IMDB_PATH</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">raw_reviews</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">),</span> <span class="n">raw_reviews</span><span class="p">))</span>
<span class="n">word_counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
<span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
        <span class="n">word_counter</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">word_counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">()</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">word_counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">())))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">):</span>
    <span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">concatenated</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">input_dataset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="n">review_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">review</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">review_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word2index</span><span class="p">[</span><span class="n">token</span><span class="p">])</span>
            <span class="n">concatenated</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word2index</span><span class="p">[</span><span class="n">token</span><span class="p">])</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="s2">&quot;&quot;</span>
    <span class="n">input_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">review_indices</span><span class="p">)</span>
<span class="n">concatenated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">concatenated</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="p">(</span><span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">hidden_size</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">negative</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span>
<span class="n">W0</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.2</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">*</span><span class="mi">0</span>
<span class="n">layer_2_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">negative</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">layer_2_target</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">similar</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s1">&#39;beautiful&#39;</span><span class="p">):</span>
    <span class="n">target_index</span> <span class="o">=</span> <span class="n">word2index</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
    
    <span class="n">scores</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">word2index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">raw_difference</span> <span class="o">=</span> <span class="n">W0</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">-</span> <span class="n">W0</span><span class="p">[</span><span class="n">target_index</span><span class="p">]</span>
        <span class="n">squared_difference</span> <span class="o">=</span> <span class="n">raw_difference</span> <span class="o">*</span> <span class="n">raw_difference</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">squared_difference</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">scores</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">review_i</span><span class="p">,</span> <span class="n">review</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_dataset</span> <span class="o">*</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">target_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">review</span><span class="p">)):</span>
        <span class="n">target_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">review</span><span class="p">[</span><span class="n">target_i</span><span class="p">]]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">concatenated</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">negative</span><span class="p">)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">concatenated</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()])</span>
        <span class="n">left_context</span> <span class="o">=</span> <span class="n">review</span><span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_i</span><span class="o">-</span><span class="n">window</span><span class="p">):</span><span class="n">target_i</span><span class="p">]</span>
        <span class="n">right_context</span> <span class="o">=</span> <span class="n">review</span><span class="p">[</span><span class="n">target_i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">review</span><span class="p">),</span> <span class="n">target_i</span><span class="o">+</span><span class="n">window</span><span class="p">)]</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">W0</span><span class="p">[</span><span class="n">left_context</span><span class="o">+</span><span class="n">right_context</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">[</span><span class="n">target_samples</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="n">layer_2</span> <span class="o">-</span> <span class="n">layer_2_target</span>
        <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">[</span><span class="n">target_samples</span><span class="p">])</span>
        <span class="n">W0</span><span class="p">[</span><span class="n">left_context</span><span class="o">+</span><span class="n">right_context</span><span class="p">]</span> <span class="o">-=</span> <span class="n">layer_1_delta</span><span class="o">*</span><span class="n">lr</span>
        <span class="n">W1</span><span class="p">[</span><span class="n">target_samples</span><span class="p">]</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_2_delta</span><span class="p">,</span> <span class="n">layer_1</span><span class="p">)</span><span class="o">*</span><span class="n">lr</span>
    <span class="k">if</span><span class="p">(</span><span class="n">review_i</span> <span class="o">%</span> <span class="mi">5000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">Progress:&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">review_i</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span><span class="o">*</span><span class="n">epochs</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;terrible&#39;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;terrible&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Progress:0.0 [(&#39;terrible&#39;, -0.0), (&#39;blonds&#39;, -0.3654412638186205), (&#39;attorneys&#39;, -0.367364060533589), (&#39;scholl&#39;, -0.37857095718170775), (&#39;wobbled&#39;, -0.3846620588625614), (&#39;amigos&#39;, -0.38828169492535225), (&#39;everone&#39;, -0.39031209722516463), (&#39;liven&#39;, -0.3916415195643817), (&#39;dalmations&#39;, -0.39196846770427124), (&#39;songmaking&#39;, -0.39706417374877395)]
Progress:0.1 [(&#39;terrible&#39;, -0.0), (&#39;unique&#39;, -2.102853834978891), (&#39;deeply&#39;, -2.1269095545304975), (&#39;fantastic&#39;, -2.134201302034517), (&#39;teenager&#39;, -2.141660779348933), (&#39;student&#39;, -2.159428257086483), (&#39;l&#39;, -2.193384034424099), (&#39;magnificent&#39;, -2.2123980782900663), (&#39;chair&#39;, -2.2322289168112253), (&#39;tough&#39;, -2.234419307670878)]
Progress:0.2 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.9320848761835907), (&#39;fantastic&#39;, -3.2986277104215103), (&#39;brilliant&#39;, -3.39900604739518), (&#39;lame&#39;, -3.5567762284556257), (&#39;superb&#39;, -3.58729188938931), (&#39;compelling&#39;, -3.650515192612599), (&#39;remarkable&#39;, -3.661610806593889), (&#39;fascinating&#39;, -3.7767323824299095), (&#39;tedious&#39;, -3.7822610442162423)]
Progress:0.3 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.442134112634085), (&#39;laughable&#39;, -3.794718218181005), (&#39;marvelous&#39;, -3.8202060659252752), (&#39;remarkable&#39;, -3.8489043019109346), (&#39;dreadful&#39;, -3.8523152880445566), (&#39;fantastic&#39;, -3.8793518032202665), (&#39;forgettable&#39;, -3.8825373704875488), (&#39;breathtaking&#39;, -3.888474155120369), (&#39;tremendous&#39;, -3.9092436158012336)]
Progress:0.4 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.019398168600297), (&#39;brilliant&#39;, -3.555897858020765), (&#39;pathetic&#39;, -3.759742016568757), (&#39;superb&#39;, -3.818176728146027), (&#39;breathtaking&#39;, -3.832505411197472), (&#39;remarkable&#39;, -3.861882094518598), (&#39;laughable&#39;, -3.8626760955820854), (&#39;fantastic&#39;, -3.9829597922734505), (&#39;lame&#39;, -3.985391021953064)]
Progress:0.5 [(&#39;terrible&#39;, -0.0), (&#39;brilliant&#39;, -3.263409473564162), (&#39;horrible&#39;, -3.3257291932923043), (&#39;superb&#39;, -3.386505815808378), (&#39;pathetic&#39;, -3.7188214193483278), (&#39;fantastic&#39;, -3.8043822546206107), (&#39;lame&#39;, -3.958477886124808), (&#39;breathtaking&#39;, -3.9864987802579437), (&#39;wonderful&#39;, -4.069469563974056), (&#39;remarkable&#39;, -4.098199445710329)]
Progress:0.6 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.8820283809129323), (&#39;fantastic&#39;, -3.153066697809395), (&#39;brilliant&#39;, -3.1718054206060753), (&#39;magnificent&#39;, -3.625771965133177), (&#39;pathetic&#39;, -3.67401816209855), (&#39;breathtaking&#39;, -3.683531786913266), (&#39;superb&#39;, -3.7919301655102373), (&#39;ridiculous&#39;, -3.816617747025522), (&#39;haunting&#39;, -3.877146969135773)]
Progress:0.7 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.487184770113473), (&#39;brilliant&#39;, -3.2608184466592416), (&#39;superb&#39;, -3.7209070138265594), (&#39;magnificent&#39;, -3.752719885109285), (&#39;fantastic&#39;, -3.779011571886598), (&#39;pathetic&#39;, -3.9118019539504534), (&#39;breathtaking&#39;, -3.932868343976472), (&#39;laughable&#39;, -3.957784479381653), (&#39;dreadful&#39;, -3.9657950074030124)]
Progress:0.8 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -3.2084712099485304), (&#39;dire&#39;, -3.828204505116444), (&#39;brilliant&#39;, -3.8445598322595105), (&#39;laughable&#39;, -3.8971270807551788), (&#39;superb&#39;, -3.9378133975662104), (&#39;fantastic&#39;, -3.946023227306032), (&#39;breathtaking&#39;, -3.9796126583730755), (&#39;fabulous&#39;, -4.047230017186402), (&#39;horrid&#39;, -4.050682228588375)]
Progress:0.9 [(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.914691624455943), (&#39;brilliant&#39;, -3.2874781332349823), (&#39;phenomenal&#39;, -3.826553075420352), (&#39;dreadful&#39;, -3.8266455497639122), (&#39;horrendous&#39;, -3.8684057341209255), (&#39;dire&#39;, -3.8977971769868556), (&#39;marvelous&#39;, -3.941399910237248), (&#39;breathtaking&#39;, -3.9705020504168718), (&#39;fabulous&#39;, -4.03673712983776)]
[(&#39;terrible&#39;, -0.0), (&#39;horrible&#39;, -2.753529112565692), (&#39;brilliant&#39;, -3.2977000768673816), (&#39;pathetic&#39;, -3.734530531813245), (&#39;phenomenal&#39;, -3.785243297594829), (&#39;superb&#39;, -3.8438918745684942), (&#39;masterful&#39;, -3.9395594508693987), (&#39;marvelous&#39;, -3.9873328037364986), (&#39;mediocre&#39;, -4.031029456908627), (&#39;bad&#39;, -4.05999901148217)]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Let's experiment with average sentence embeddings:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W0</span><span class="o">*</span><span class="n">W0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">norms</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">norms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">normed_weights</span> <span class="o">=</span> <span class="n">W0</span><span class="o">*</span><span class="n">norms</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">make_sent_vect</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="c1"># 1st part get index of each word</span>
    <span class="c1"># 2nd part filters only words in vocab</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">word2index</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">word2index</span><span class="p">,</span> <span class="n">words</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">normed_weights</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">reviews_to_vectors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="n">reviews_to_vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">make_sent_vect</span><span class="p">(</span><span class="n">review</span><span class="p">))</span>
<span class="n">reviews_to_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">reviews_to_vectors</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">most_similar_reviews</span><span class="p">(</span><span class="n">review</span><span class="p">):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">make_sent_vect</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reviews_to_vectors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">)):</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>
    <span class="n">most_similar</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">most_similar</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">raw_reviews</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">40</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">most_similar</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">most_similar_reviews</span><span class="p">([</span><span class="s1">&#39;beautiful&#39;</span><span class="p">,</span> <span class="s1">&#39;amazing&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;if you havn  t seen this movie i highly &#39;,
 &#39;i have never seen such terrible performa&#39;,
 &#39;i think this show is definitely the grea&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>there appear to be interesting statistical information within these vectors, such as when negative &amp; embeddings cluster together</strong>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-is-information-stored-in-these-embeddings?">How is information stored in these embeddings?<a class="anchor-link" href="#How-is-information-stored-in-these-embeddings?">&#182;</a></h2><h3 id="When-you-average-word-embeddings,-average-shapes-remain">When you average word embeddings, average shapes remain<a class="anchor-link" href="#When-you-average-word-embeddings,-average-shapes-remain">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width: 66%;" file="static/imgs/12/word_vector.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-does-a-Neural-Network-use-embeddings?">How does a Neural Network use embeddings?<a class="anchor-link" href="#How-does-a-Neural-Network-use-embeddings?">&#182;</a></h2><h3 id="Neural-Networks-detect-the-curves-that-have-correlation-with-the-target-label">Neural Networks detect the curves that have correlation with the target label<a class="anchor-link" href="#Neural-Networks-detect-the-curves-that-have-correlation-with-the-target-label">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The Neural Network simply looks for various bumps and variations in the input layer and compresses that information to predict the target label (missing word/sentiment/...)</li>
<li>Through training, the Neural Network shapes the word embeddings in such a way that it clusters them, all in the goal for it to make easier predictions of the target label.<ul>
<li>It compresses the signal in a way that allows it to minimize its loss function -&gt; correctly predict the target label.</li>
</ul>
</li>
<li>Think about when you'll have longer sentences, the loger the sentence, the more the true signal will be averaged to zero, since you will have a lot of average words to links concepts &amp; ideas in the sentence, so avereging word embeddings is a bit mushy.<ul>
<li>The longer the sentence, the more likely that it will average out to be a straight line.<ul>
<li>A Vector of near zeros.</li>
</ul>
</li>
</ul>
</li>
<li>In short, this concept of storing a sentence in a fixed length vector doesn't decay nicely.</li>
<li>That being said, typical sentences aren't that long anyway.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Limitations-of-Bag-of-Words-Vectors">The Limitations of Bag-of-Words Vectors<a class="anchor-link" href="#The-Limitations-of-Bag-of-Words-Vectors">&#182;</a></h2><h3 id="Order-becomes-irrelevant-when-you-average-word-embeddings">Order becomes irrelevant when you average word embeddings<a class="anchor-link" href="#Order-becomes-irrelevant-when-you-average-word-embeddings">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>The biggest issue with averaged word embeddings is that they lose the order information</strong>.</li>
<li>This approach also ignores grammar and syntax.</li>
<li>This way of averaging or summing a bunch of words to have a sentence/text representation is called the bag-of-words approach.<ul>
<li>A Bag, because order isn't preserved.</li>
</ul>
</li>
<li>We want a way to represent sentence vectors that preserve order and yield different representations for different word order.</li>
<li>More importantly, <strong>the way in which order changes the resulting vector should be learned</strong>.<ul>
<li>In this way, the neural network will find an order representation that minimizes its loss function and yield interesting properties about word order in general.</li>
</ul>
</li>
<li>One of the most famous and successful ways of generating vectors for sequences are Recurrent Neural Networks (RNNs).</li>
<li>Identity matrices have one property: if you multiply any vector by them, you'll get the same vector.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using-Identity-Vectors-to-sum-word-embeddings">Using Identity Vectors to sum word embeddings<a class="anchor-link" href="#Using-Identity-Vectors-to-sum-word-embeddings">&#182;</a></h2><h3 id="Let's-implement-the-same-logic-using-a-different-approach">Let's implement the same logic using a different approach<a class="anchor-link" href="#Let's-implement-the-same-logic-using-a-different-approach">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width: 33%;" file="static/imgs/12/standard_sum.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Matrices-that-change-absolutely-nothing">Matrices that change absolutely nothing<a class="anchor-link" href="#Matrices-that-change-absolutely-nothing">&#182;</a></h2><h3 id="Let's-create-sentence-embeddings-using-the-Identity-matrix-in-Python">Let's create sentence embeddings using the Identity matrix in Python<a class="anchor-link" href="#Let's-create-sentence-embeddings-using-the-Identity-matrix-in-Python">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">identity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">identity</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">a</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">),</span> <span class="n">b</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">),</span> <span class="n">c</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">),</span> <span class="n">d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(array([1., 2., 3.]),
 array([0.1, 0.2, 0.3]),
 array([-1. , -0.5,  0. ]),
 array([0., 0., 0.]))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">this</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">movie</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">rocks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">this</span> <span class="o">+</span> <span class="n">movie</span> <span class="o">+</span> <span class="n">rocks</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(((</span><span class="n">this</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span> <span class="o">+</span> <span class="n">movie</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span> <span class="o">+</span> <span class="n">rocks</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[13 15 17]
[13. 15. 17.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>we yielded the same results just because the identity matrix is a very special type of matrix.<ul>
<li>In fact, <strong>the identity matrix is the only matrix capable of returning the same vector as doing direct sum</strong>, no other matrix has this guarantee.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-the-Transition-Matrices">Learning the Transition Matrices<a class="anchor-link" href="#Learning-the-Transition-Matrices">&#182;</a></h2><h3 id="What-if-you-allowed-the-identity-matrices-to-change-to-minimize-the-loss?">What if you allowed the identity matrices to change to minimize the loss?<a class="anchor-link" href="#What-if-you-allowed-the-identity-matrices-to-change-to-minimize-the-loss?">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width: 66%;" file="static/imgs/12/LM.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-to-Create-Useful-Sentence-Vectors">Learning to Create Useful Sentence Vectors<a class="anchor-link" href="#Learning-to-Create-Useful-Sentence-Vectors">&#182;</a></h2><h3 id="Create-the-Sentence-Vector,-Make-a-Prediction,-&amp;-Modify-the-sentence-vector-via-its-parts.">Create the Sentence Vector, Make a Prediction, &amp; Modify the sentence vector via its parts.<a class="anchor-link" href="#Create-the-Sentence-Vector,-Make-a-Prediction,-&amp;-Modify-the-sentence-vector-via-its-parts.">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width: 50%;" file="static/imgs/12/primitive_RNN.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Forward-Propagation-in-Python">Forward Propagation in Python<a class="anchor-link" href="#Forward-Propagation-in-Python">&#182;</a></h2><h3 id="Let's-take-this-Idea-&amp;-see-how-to-perform-a-forward-propagation-for-our-network">Let's take this Idea &amp; see how to perform a forward propagation for our network<a class="anchor-link" href="#Let's-take-this-Idea-&amp;-see-how-to-perform-a-forward-propagation-for-our-network">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Now that you have a conceptual idea of what you're trying to build, let's check out a toy version in Python.</li>
<li>First, let's create the weights (I am using a limited vocab of 9 words):</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># initial word embeddings</span>
<span class="n">word_vects</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;yankees&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;bears&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;braves&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;sox&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;lose&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;defeat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;beat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;tie&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># sentence embedding to output classification weights</span>
<span class="n">sent2output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_vects</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># initial weight matrices</span>
<span class="n">identity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>This code creates 3 sets of weights:<ul>
<li>A Dictionnary of Word Embeddings.</li>
<li>The Identity or Transition Matrix.</li>
<li>A Classification Layer.</li>
</ul>
</li>
<li>The Classification layer serves to predict the next word over the word vocab, using the sentence vector representation.</li>
<li>With these tools, forward propagation is trivial, let's take an example:<ul>
<li>"red sox defeat" -&gt; "yankees":</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># akramz solution</span>
<span class="n">sent_repr</span> <span class="o">=</span> <span class="p">((</span><span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span> <span class="o">+</span> <span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;sox&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span> <span class="o">+</span> <span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;defeat&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">sent_repr</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sent2output</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[0., 0., 0., 0., 0., 0., 0., 0., 0.]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># book&#39;s solution</span>
<span class="n">layer_0</span> <span class="o">=</span> <span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">]</span>
<span class="n">layer_1</span> <span class="o">=</span> <span class="n">layer_0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span> <span class="o">+</span> <span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;sox&#39;</span><span class="p">]</span>
<span class="n">layer_2</span> <span class="o">=</span> <span class="n">layer_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span> <span class="o">+</span> <span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;defeat&#39;</span><span class="p">]</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">layer_2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sent2output</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,
        0.11111111, 0.11111111, 0.11111111, 0.11111111]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-do-you-backpropagate-into-this?">How do you backpropagate into this?<a class="anchor-link" href="#How-do-you-backpropagate-into-this?">&#182;</a></h2><h3 id="It-might-seem-trickier,-but-they're-the-same-steps-you-already-learned">It might seem trickier, but they're the same steps you already learned<a class="anchor-link" href="#It-might-seem-trickier,-but-they're-the-same-steps-you-already-learned">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width: 66%;" file="static/imgs/12/RNN_Architecture.jpg" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Which direction should I backprop in?<ul>
<li>You could go back through the identity matrix and further, &amp; you could also calculate the gradients over the individual word embeddings injected in each layer.</li>
</ul>
</li>
<li>When you add two vectors together during forward propagation, you will backpropagate the same gradient into both sides of addition.</li>
<li>When you generate <code>layer_2_delta</code>, you backpropagate it twice, once across the identity matrix to create <code>layer_1_delta</code> and again to <code>word_vectors['defeat']</code>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>  <span class="c1"># one-hot vector for yankees</span>
<span class="n">pred_delta</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">layer_2_delta</span> <span class="o">=</span> <span class="n">pred_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sent2output</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">defeat_delta</span> <span class="o">=</span> <span class="n">layer_2_delta</span> <span class="o">*</span> <span class="mi">1</span>
<span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">layer_2_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">sox_delta</span> <span class="o">=</span> <span class="n">layer_1_delta</span> <span class="o">*</span> <span class="mi">1</span>
<span class="n">layer_0_delta</span> <span class="o">=</span> <span class="n">layer_1_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">identity</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># which is `red_delta`</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">01</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">]</span> <span class="o">-=</span> <span class="n">layer_0_delta</span><span class="o">*</span><span class="n">lr</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;sox&#39;</span><span class="p">]</span> <span class="o">-=</span> <span class="n">sox_delta</span><span class="o">*</span><span class="n">lr</span>
<span class="n">word_vects</span><span class="p">[</span><span class="s1">&#39;defeat&#39;</span><span class="p">]</span> <span class="o">-=</span> <span class="n">defeat_delta</span><span class="o">*</span><span class="n">lr</span>
<span class="n">identity</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_0</span><span class="p">,</span> <span class="n">layer_1_delta</span><span class="p">)</span><span class="o">*</span><span class="n">lr</span>
<span class="n">identity</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span> <span class="n">layer_2_delta</span><span class="p">)</span><span class="o">*</span><span class="n">lr</span>
<span class="n">sent2output</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_2</span><span class="p">,</span> <span class="n">pred_delta</span><span class="p">)</span><span class="o">*</span><span class="n">lr</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word_vects</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;bears&#39;: array([[0., 0., 0.]]),
 &#39;beat&#39;: array([[0., 0., 0.]]),
 &#39;braves&#39;: array([[0., 0., 0.]]),
 &#39;defeat&#39;: array([[0.00431805, 0.00286998, 0.00065565]]),
 &#39;lose&#39;: array([[0., 0., 0.]]),
 &#39;red&#39;: array([[0.00431805, 0.00286998, 0.00065565]]),
 &#39;sox&#39;: array([[0.00431805, 0.00286998, 0.00065565]]),
 &#39;tie&#39;: array([[0., 0., 0.]]),
 &#39;yankees&#39;: array([[0., 0., 0.]])}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Let's-Train-it!">Let's Train it!<a class="anchor-link" href="#Let's-Train-it!">&#182;</a></h2><h3 id="You-have-all-the-tools;-let's-train-the-network-on-a-toy-corpus">You have all the tools; let's train the network on a toy corpus<a class="anchor-link" href="#You-have-all-the-tools;-let's-train-the-network-on-a-toy-corpus">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Let's first train the network on a toy dataset called "Babi dataset".</li>
<li>This dataset is a synthetically generated Q/A corpus to teach machines how to answer questions about an environment.</li>
<li>First let's download and decompress the Babi dataset using bash commands:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-1.tar.gz
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--2019-05-17 10:31:47--  http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-1.tar.gz
Resolving www.thespermwhale.com (www.thespermwhale.com)... 69.65.3.213
Connecting to www.thespermwhale.com (www.thespermwhale.com)|69.65.3.213|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1282454 (1.2M) [application/x-gzip]
Saving to: &#39;tasks_1-20_v1-1.tar.gz&#39;

tasks_1-20_v1-1.tar 100%[===================&gt;]   1.22M   871KB/s    in 1.4s    

2019-05-17 10:31:49 (871 KB/s) - &#39;tasks_1-20_v1-1.tar.gz&#39; saved [1282454/1282454]

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>mv tasks_1-20_v1-1.tar.gz static/data/
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>tar -xvf static/data/tasks_1-20_v1-1.tar.gz
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>x tasksv11/
x tasksv11/en/
x tasksv11/._LICENSE
x tasksv11/LICENSE
x tasksv11/README
x tasksv11/shuffled/
x tasksv11/shuffled/qa10_indefinite-knowledge_test.txt
x tasksv11/shuffled/qa10_indefinite-knowledge_train.txt
x tasksv11/shuffled/qa11_basic-coreference_test.txt
x tasksv11/shuffled/qa11_basic-coreference_train.txt
x tasksv11/shuffled/qa12_conjunction_test.txt
x tasksv11/shuffled/qa12_conjunction_train.txt
x tasksv11/shuffled/qa13_compound-coreference_test.txt
x tasksv11/shuffled/qa13_compound-coreference_train.txt
x tasksv11/shuffled/qa14_time-reasoning_test.txt
x tasksv11/shuffled/qa14_time-reasoning_train.txt
x tasksv11/shuffled/qa15_basic-deduction_test.txt
x tasksv11/shuffled/qa15_basic-deduction_train.txt
x tasksv11/shuffled/qa16_basic-induction_test.txt
x tasksv11/shuffled/qa16_basic-induction_train.txt
x tasksv11/shuffled/qa17_positional-reasoning_test.txt
x tasksv11/shuffled/qa17_positional-reasoning_train.txt
x tasksv11/shuffled/qa18_size-reasoning_test.txt
x tasksv11/shuffled/qa18_size-reasoning_train.txt
x tasksv11/shuffled/qa19_path-finding_test.txt
x tasksv11/shuffled/qa19_path-finding_train.txt
x tasksv11/shuffled/qa1_single-supporting-fact_test.txt
x tasksv11/shuffled/qa1_single-supporting-fact_train.txt
x tasksv11/shuffled/qa20_agents-motivations_test.txt
x tasksv11/shuffled/qa20_agents-motivations_train.txt
x tasksv11/shuffled/qa2_two-supporting-facts_test.txt
x tasksv11/shuffled/qa2_two-supporting-facts_train.txt
x tasksv11/shuffled/qa3_three-supporting-facts_test.txt
x tasksv11/shuffled/qa3_three-supporting-facts_train.txt
x tasksv11/shuffled/qa4_two-arg-relations_test.txt
x tasksv11/shuffled/qa4_two-arg-relations_train.txt
x tasksv11/shuffled/qa5_three-arg-relations_test.txt
x tasksv11/shuffled/qa5_three-arg-relations_train.txt
x tasksv11/shuffled/qa6_yes-no-questions_test.txt
x tasksv11/shuffled/qa6_yes-no-questions_train.txt
x tasksv11/shuffled/qa7_counting_test.txt
x tasksv11/shuffled/qa7_counting_train.txt
x tasksv11/shuffled/qa8_lists-sets_test.txt
x tasksv11/shuffled/qa8_lists-sets_train.txt
x tasksv11/shuffled/qa9_simple-negation_test.txt
x tasksv11/shuffled/qa9_simple-negation_train.txt
x tasksv11/en/qa10_indefinite-knowledge_test.txt
x tasksv11/en/qa10_indefinite-knowledge_train.txt
x tasksv11/en/qa11_basic-coreference_test.txt
x tasksv11/en/qa11_basic-coreference_train.txt
x tasksv11/en/qa12_conjunction_test.txt
x tasksv11/en/qa12_conjunction_train.txt
x tasksv11/en/qa13_compound-coreference_test.txt
x tasksv11/en/qa13_compound-coreference_train.txt
x tasksv11/en/qa14_time-reasoning_test.txt
x tasksv11/en/qa14_time-reasoning_train.txt
x tasksv11/en/qa15_basic-deduction_test.txt
x tasksv11/en/qa15_basic-deduction_train.txt
x tasksv11/en/qa16_basic-induction_test.txt
x tasksv11/en/qa16_basic-induction_train.txt
x tasksv11/en/qa17_positional-reasoning_test.txt
x tasksv11/en/qa17_positional-reasoning_train.txt
x tasksv11/en/qa18_size-reasoning_test.txt
x tasksv11/en/qa18_size-reasoning_train.txt
x tasksv11/en/qa19_path-finding_test.txt
x tasksv11/en/qa19_path-finding_train.txt
x tasksv11/en/qa1_single-supporting-fact_test.txt
x tasksv11/en/qa1_single-supporting-fact_train.txt
x tasksv11/en/qa20_agents-motivations_test.txt
x tasksv11/en/qa20_agents-motivations_train.txt
x tasksv11/en/qa2_two-supporting-facts_test.txt
x tasksv11/en/qa2_two-supporting-facts_train.txt
x tasksv11/en/qa3_three-supporting-facts_test.txt
x tasksv11/en/qa3_three-supporting-facts_train.txt
x tasksv11/en/qa4_two-arg-relations_test.txt
x tasksv11/en/qa4_two-arg-relations_train.txt
x tasksv11/en/qa5_three-arg-relations_test.txt
x tasksv11/en/qa5_three-arg-relations_train.txt
x tasksv11/en/qa6_yes-no-questions_test.txt
x tasksv11/en/qa6_yes-no-questions_train.txt
x tasksv11/en/qa7_counting_test.txt
x tasksv11/en/qa7_counting_train.txt
x tasksv11/en/qa8_lists-sets_test.txt
x tasksv11/en/qa8_lists-sets_train.txt
x tasksv11/en/qa9_simple-negation_test.txt
x tasksv11/en/qa9_simple-negation_train.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>With some simple Python, you can open, clean, &amp; preprocess the data to feed it to the recurrent neural network:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;static/data/tasksv11/en/qa1_single-supporting-fact_train.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">raw</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]:</span>
    <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[[&#39;mary&#39;, &#39;moved&#39;, &#39;to&#39;, &#39;the&#39;, &#39;bathroom.&#39;],
 [&#39;john&#39;, &#39;went&#39;, &#39;to&#39;, &#39;the&#39;, &#39;hallway.&#39;],
 [&#39;where&#39;, &#39;is&#39;, &#39;mary?&#39;, &#39;\tbathroom\t1&#39;]]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>This dataset contains a lot of simple statements and questions.<ul>
<li>Each Question is followed by the correct answer.</li>
</ul>
</li>
<li>When used in the Context of QA, the neural network reads the statements then answers the question.</li>
<li>For now, your network will attempt to finish each sentence when given one or more starting words.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setting-Things-Up">Setting Things Up<a class="anchor-link" href="#Setting-Things-Up">&#182;</a></h2><h3 id="Before-you-can-create-matrices,-you-need-to-learn-how-many-parameters-you-have.">Before you can create matrices, you need to learn how many parameters you have.<a class="anchor-link" href="#Before-you-can-create-matrices,-you-need-to-learn-how-many-parameters-you-have.">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sent</span><span class="p">:</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">):</span>
    <span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sent2indices</span><span class="p">(</span><span class="n">sent</span><span class="p">):</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sent</span><span class="p">:</span>
        <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">indices</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="n">e_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">e_v</span> <span class="o">/</span> <span class="n">e_v</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>we set the word embedding size to 10.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embed_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
<span class="n">W0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">embed_size</span><span class="p">)</span>
<span class="n">empty_sentence_embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">embed_size</span><span class="p">)</span>
<span class="n">W1</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
<span class="c1"># target vocab vectors for the loss function</span>
<span class="n">y_hots</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W0</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">W1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((10, 10), (10, 82))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Forward-Propagation-with-Arbitrary-Length">Forward Propagation with Arbitrary Length<a class="anchor-link" href="#Forward-Propagation-with-Arbitrary-Length">&#182;</a></h2><h3 id="You'll-forward-propagate-using-the-same-logic-described-earlier">You'll forward propagate using the same logic described earlier<a class="anchor-link" href="#You'll-forward-propagate-using-the-same-logic-described-earlier">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%;" file="static/imgs/12/enhanced_RNNs.jpg" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">sent</span><span class="p">):</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;hidden&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">empty_sentence_embedding</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
    
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1"># forward propagates</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">target_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sent</span><span class="p">)):</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># tries to predict the next term</span>
        <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;hidden&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">))</span>
        <span class="c1"># `sent[target_i]` gets actual word, which is a number that represent word in vocab, then we get its prediction in the proba distribution</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">][</span><span class="n">sent</span><span class="p">[</span><span class="n">target_i</span><span class="p">]])</span>
        <span class="c1"># generates the next hidden state</span>
        <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;hidden&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;hidden&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W0</span><span class="p">)</span> <span class="o">+</span> <span class="n">word_embeddings</span><span class="p">[</span><span class="n">sent</span><span class="p">[</span><span class="n">target_i</span><span class="p">]]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layers</span><span class="p">,</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>The List called "layers" represent a new way of doing forward propagation.</strong></li>
<li>Notice that you end up doing more forward propagation if the sentence length is longer.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Backpropagation-with-Arbitrary-Length">Backpropagation with Arbitrary Length<a class="anchor-link" href="#Backpropagation-with-Arbitrary-Length">&#182;</a></h2><h3 id="You'll-backpropagate-using-the-same-logic-described-earlier">You'll backpropagate using the same logic described earlier<a class="anchor-link" href="#You'll-backpropagate-using-the-same-logic-described-earlier">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Let's implement backpropagation over arbitrary sequence lengths.</li>
<li>the most important object is the <strong>layers</strong> list, which has two vectors<ul>
<li><code>layer['state']</code></li>
<li><code>layer['previous_hidden']</code></li>
</ul>
</li>
<li>In order to backpropagate, you'll take the output's gradient and add a new objec to each list called <code>layer['state_delta']</code> which will represent the gradient at that layer.</li>
<li>You're building the same logic in a way that it can consume the variable-length sequences from the forward propagation logic.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;went&#39;, &#39;to&#39;, &#39;the&#39;, &#39;hallway.&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30000</span><span class="p">):</span>
    <span class="c1"># forward propagation</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">001</span>
    <span class="c1"># getting sentence indices w/o 1st word</span>
    <span class="c1"># why it leaves the first word of each sentence? -&gt; to use it instead of &quot;NaN&quot; as first layer[&#39;hidden&#39;]</span>
    <span class="n">sent</span> <span class="o">=</span> <span class="n">sent2indices</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="nb">iter</span><span class="o">%</span><span class="k">len</span>(sentences)][1:])  
    <span class="n">layers</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>  <span class="c1"># predicts, returns hidden layer embeddings + loss</span>
    
    <span class="c1"># backpropagation</span>
    <span class="k">for</span> <span class="n">layer_i</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">))):</span>  <span class="c1"># loop over hidden states (layers)</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">layer_i</span><span class="p">]</span>  <span class="c1"># get corresponding layer</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">sent</span><span class="p">[</span><span class="n">layer_i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># get target word</span>
        
        <span class="c1"># If not the 1st layer</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">layer_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>  <span class="c1"># if not first layer</span>
            <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;output_delta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_hots</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>  <span class="c1"># delta</span>
            <span class="n">new_hidden_delta</span> <span class="o">=</span> <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;output_delta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>  <span class="c1"># gradient</span>
            
            <span class="c1"># If last layer, don&#39;t pull from a later one, because it doesn&#39;t exist</span>
            <span class="c1"># seems that for each hidden layer, its hidden delta is depedent upon the last decoding operation + next layer gradient</span>
            <span class="k">if</span><span class="p">(</span><span class="n">layer_i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_hidden_delta</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_hidden_delta</span> <span class="o">+</span> <span class="n">layers</span><span class="p">[</span><span class="n">layer_i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W0</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># if the first layer</span>
            <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">layer_i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W0</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%;" file="static/imgs/12/storing_info_RNN.jpg" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Weight-update-with-arbitrary-length">Weight update with arbitrary length<a class="anchor-link" href="#Weight-update-with-arbitrary-length">&#182;</a></h2><h3 id="You'll-update-weights-using-the-same-logic-describe-earlier">You'll update weights using the same logic describe earlier<a class="anchor-link" href="#You'll-update-weights-using-the-same-logic-describe-earlier">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>After having stored the gradients for each layer, now we need to add the Weight Update Code:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30000</span><span class="p">):</span>
    <span class="c1"># forward propagation</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">001</span>
    <span class="c1"># getting sentence indices w/o 1st word</span>
    <span class="c1"># why it leaves the first word of each sentence? -&gt; to use it instead of &quot;NaN&quot; as first layer[&#39;hidden&#39;]</span>
    <span class="n">sent</span> <span class="o">=</span> <span class="n">sent2indices</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="nb">iter</span><span class="o">%</span><span class="k">len</span>(sentences)][1:])  
    <span class="n">layers</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>  <span class="c1"># predicts, returns hidden layer embeddings + loss</span>
    
    <span class="c1"># backpropagation</span>
    <span class="k">for</span> <span class="n">layer_i</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">))):</span>  <span class="c1"># loop over hidden states (layers)</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">layer_i</span><span class="p">]</span>  <span class="c1"># get corresponding layer</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">sent</span><span class="p">[</span><span class="n">layer_i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># get target word</span>
        
        <span class="c1"># If not the 1st layer</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">layer_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>  <span class="c1"># if not first layer</span>
            <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;output_delta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_hots</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>  <span class="c1"># delta</span>
            <span class="n">new_hidden_delta</span> <span class="o">=</span> <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;output_delta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>  <span class="c1"># gradient</span>
            
            <span class="c1"># If last layer, don&#39;t pull from a later one, because it doesn&#39;t exist</span>
            <span class="c1"># seems that for each hidden layer, its hidden delta is depedent upon the last decoding operation + next layer gradient</span>
            <span class="k">if</span><span class="p">(</span><span class="n">layer_i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_hidden_delta</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_hidden_delta</span> <span class="o">+</span> <span class="n">layers</span><span class="p">[</span><span class="n">layer_i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W0</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># if the first layer</span>
            <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">layer_i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W0</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
    
    <span class="c1"># Update weights of NaN Embedding</span>
    <span class="n">empty_sentence_embedding</span> <span class="o">-=</span> <span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">lr</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sent</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">layer_i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="c1"># update decoder</span>
        <span class="n">W1</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_i</span><span class="p">][</span><span class="s2">&quot;hidden&quot;</span><span class="p">],</span> <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;output_delta&#39;</span><span class="p">])</span><span class="o">*</span><span class="n">lr</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sent</span><span class="p">))</span>
        <span class="n">embed_i</span> <span class="o">=</span> <span class="n">sent</span><span class="p">[</span><span class="n">layer_i</span><span class="p">]</span>
        <span class="c1"># update embeddings</span>
        <span class="n">word_embeddings</span><span class="p">[</span><span class="n">embed_i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">layers</span><span class="p">[</span><span class="n">layer_i</span><span class="p">][</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">]</span><span class="o">*</span><span class="n">lr</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sent</span><span class="p">))</span>
        <span class="c1"># update encoder</span>
        <span class="n">W0</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_i</span><span class="p">][</span><span class="s1">&#39;hidden&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;hidden_delta&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">lr</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sent</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="nb">iter</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Perplexity :&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">sent</span><span class="p">))))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Perplexity :81.91346989524257
Perplexity :81.79164804556522
Perplexity :81.59136670120363
Perplexity :81.21617876879513
Perplexity :80.46101504475695
Perplexity :78.81151765899324
Perplexity :74.57593512893804
Perplexity :58.196352288038895
Perplexity :30.665797467081802
Perplexity :20.852192551772724
Perplexity :19.04945943831619
Perplexity :17.626854858639998
Perplexity :15.61871693979982
Perplexity :12.630565276246934
Perplexity :9.303686888390308
Perplexity :7.371916951350519
Perplexity :6.33961157289624
Perplexity :5.634372087983678
Perplexity :5.208649397251203
Perplexity :4.937183016678388
Perplexity :4.758495401236964
Perplexity :4.648590542164584
Perplexity :4.578039220744333
Perplexity :4.514585657013284
Perplexity :4.44146200313975
Perplexity :4.356558965071526
Perplexity :4.2645645179658525
Perplexity :4.1708183240915195
Perplexity :4.079941605049494
Perplexity :3.9976836650012704
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>What is Perplexity ?</strong><ul>
<li>In information theory, preplexity is a measurement that predicts how well a probability distribution or a probability model predicts a sample.<ul>
<li>It may be used to compare probability models.</li>
</ul>
</li>
<li>A low Perplexity indicate that the model is good at predicting a sample.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Execution-and-Output-Analysis">Execution and Output Analysis<a class="anchor-link" href="#Execution-and-Output-Analysis">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Perplexity is the probability of the corrent label (word), passed through a log function, negated, and exponentiated (e^x).</li>
<li>But what it represents theoritically is the difference between two probability distributions.</li>
<li>Perplexity is high when two probability distributions doesn't match, and it is low (approaching 1) when the two distributions are close to each other.</li>
<li>But this metric hardly tells you what's going on in the weights.<ul>
<li>Perplexity has faced some critisicm over the years (particularly in the language modeling community)<ul>
<li>for being overused as a metric</li>
</ul>
</li>
</ul>
</li>
<li>Let's look a little more closely at the predictions:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sent_index</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">l</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">sent2indices</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="n">sent_index</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="n">sent_index</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;sandra&#39;, &#39;moved&#39;, &#39;to&#39;, &#39;the&#39;, &#39;garden.&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">each_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">l</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">sentences</span><span class="p">[</span><span class="n">sent_index</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="n">true</span> <span class="o">=</span> <span class="n">sentences</span><span class="p">[</span><span class="n">sent_index</span><span class="p">][</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">each_layer</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prev Input:&quot;</span> <span class="o">+</span> <span class="nb">input</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39; &#39;</span> <span class="o">*</span> <span class="p">(</span><span class="mi">12</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">)))</span> <span class="o">+</span> <span class="s2">&quot;True: &quot;</span> <span class="o">+</span> <span class="n">true</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39; &#39;</span> <span class="o">*</span> <span class="p">(</span><span class="mi">15</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">true</span><span class="p">)))</span> <span class="o">+</span> <span class="s2">&quot;Pred: &quot;</span> <span class="o">+</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Prev Input:sandra      True: moved          Pred: is
Prev Input:moved       True: to             Pred: to
Prev Input:to          True: the            Pred: the
Prev Input:the         True: garden.        Pred: bedroom.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>This code takes a sentence and predicts the word the model think is most likely.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Looking-at-predictions-can-help-you-understand-what's-going-on">Looking at predictions can help you understand what's going on<a class="anchor-link" href="#Looking-at-predictions-can-help-you-understand-what's-going-on">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>You can look at the predictions of the neural network as it trains to understand not only what kind of patterns it picks up, but also in the order in which it does so.</li>
<li>Neural Networks tend to start off random.</li>
<li>After some amount of training, the neural network picks up the most frequent word and predicts it as a default.<ul>
<li>This is an extremely common error in recurrent neural networks.</li>
</ul>
</li>
<li>It's important to know that there is almost no way this network can predict the next word perfectly.<ul>
<li>More context is needed to solve this task.</li>
<li>But the fact that it's unsolvable, creates educational analysis for the ways in which it fails.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h2><h3 id="Recurrent-Neural-Networks-Predict-over-arbitrary-Length-Sequences">Recurrent Neural Networks Predict over arbitrary Length Sequences<a class="anchor-link" href="#Recurrent-Neural-Networks-Predict-over-arbitrary-Length-Sequences">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>In this chapter, you learned how to create a vector representaion of arbitrary long sentences.</li>
<li>How does a neural network fit a variable length sequence into a fixed size vector?<ul>
<li>The truth is, sentence vectors don't encode everything in the vector.</li>
</ul>
</li>
<li>The name of the game in recurrent neural networks is not just what these vectors remember, but also what they forget.</li>
<li>In the case of predicting the next word, RNNs learn that only the last few words matter.</li>
</ul>

</div>
</div>
</div>
</div>
 

