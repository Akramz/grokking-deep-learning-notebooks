---

title: Learning to Write like Shakespeare: Long short-term memory
keywords: fastai
sidebar: home_sidebar


---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 14.LSTMs_LM.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this chapter:</p>
<ul>
<li>Character Language Modeling</li>
<li>Truncated Backpropagation</li>
<li>Vanishing &amp; Exploding Gradients</li>
<li>A Toy Example of RNN backpropagation</li>
<li>Long Short-term memory (LSTM) cells<blockquote><p>"Lord, what fools these mortals be" â€” William Shakespeare: A Midsummer night's dream.</p>
</blockquote>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Requirements">Requirements<a class="anchor-link" href="#Requirements">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Tensor</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">creation_op</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">autograd</span> <span class="o">=</span> <span class="n">autograd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parents</span> <span class="o">=</span> <span class="n">parents</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">=</span> <span class="n">creation_op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span> <span class="nb">id</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="nb">id</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="n">parents</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">parent</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">:</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">children</span><span class="p">):</span>
                    <span class="n">parent</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="bp">self</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">parent</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="bp">self</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        
    <span class="k">def</span> <span class="nf">all_grads_propagated</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">grads_count</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">grads_count</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span> <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>
    
    <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> 
                          <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">],</span> 
                          <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__sub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">-</span><span class="n">other</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
                         <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">],</span>
                         <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">-</span><span class="n">other</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
                         <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">],</span>
                         <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span>
                         <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">],</span>
                         <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;sum_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__neg__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">],</span>
                         <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;neg&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;Tensor(&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span> <span class="o">+</span> <span class="s1">&#39;)&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="fm">__str__</span><span class="p">())</span>
    
    <span class="k">def</span> <span class="nf">expand</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">copies</span><span class="p">):</span>
        <span class="n">trans_cmd</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
        <span class="n">trans_cmd</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">copies</span><span class="p">]</span>
        <span class="n">new_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">copies</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>
        <span class="n">new_data</span> <span class="o">=</span> <span class="n">new_data</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">trans_cmd</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">new_data</span><span class="p">,</span> 
                         <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">],</span>
                         <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;expand_&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span>
                         <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">],</span>
                         <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
    
    <span class="k">def</span> <span class="nf">mm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="p">),</span>
                         <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span>
                         <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;mm&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)),</span>
                          <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">],</span>
                          <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)))</span>
    
    <span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">),</span>
                         <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">],</span>
                         <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">index_select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="n">new</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">indices</span><span class="o">.</span><span class="n">data</span><span class="p">],</span>
                        <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">],</span>
                        <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;index_select&quot;</span><span class="p">)</span>
            <span class="n">new</span><span class="o">.</span><span class="n">index_select_indices</span> <span class="o">=</span> <span class="n">indices</span>
            <span class="k">return</span> <span class="n">new</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">indices</span><span class="o">.</span><span class="n">data</span><span class="p">])</span>
    
    <span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">softmax_output</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">temp</span><span class="p">,</span>
                                       <span class="n">axis</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                       <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">softmax_output</span>
    
    <span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_indices</span><span class="p">):</span>
        <span class="n">temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">softmax_output</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">temp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span>  <span class="n">target_indices</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">softmax_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">target_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="n">t</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">target_dist</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span>
                        <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">],</span>
                        <span class="n">creation_op</span><span class="o">=</span><span class="s2">&quot;cross_entropy&quot;</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">softmax_output</span> <span class="o">=</span> <span class="n">softmax_output</span>
            <span class="n">out</span><span class="o">.</span><span class="n">target_dist</span> <span class="o">=</span> <span class="n">target_dist</span>
            <span class="k">return</span> <span class="n">out</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grad</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">grad_origin</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">autograd</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">grad</span> <span class="o">==</span> <span class="kc">None</span><span class="p">):</span>
                <span class="n">grad</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">grad_origin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">grad_origin</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;cannot backprop more than once&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">grad_origin</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">+=</span> <span class="n">grad</span>
            <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">parents</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_grads_propagated</span><span class="p">()</span> <span class="ow">or</span> <span class="n">grad_origin</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)):</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s2">&quot;+&quot;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">grad_origin</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">grad_origin</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s2">&quot;neg&quot;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="fm">__neg__</span><span class="p">())</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;-&#39;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">grad_origin</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="fm">__neg__</span><span class="p">(),</span> <span class="n">grad_origin</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;*&#39;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">grad_origin</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">grad_origin</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;mm&#39;</span><span class="p">):</span>
                    <span class="n">activation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># usually an activation function</span>
                    <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># usually a weights matrix</span>
                    <span class="n">activation</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">transpose</span><span class="p">()))</span>
                    <span class="n">weights</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;T&#39;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
                <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;sum&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span><span class="p">):</span>
                    <span class="n">dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
                    <span class="n">ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">ds</span><span class="p">))</span>
                <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;expand&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span><span class="p">):</span>
                    <span class="n">dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">):</span>
                    <span class="n">ones</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span> <span class="o">*</span> <span class="p">(</span><span class="n">ones</span> <span class="o">-</span> <span class="bp">self</span><span class="p">)))</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;tanh&#39;</span><span class="p">):</span>
                    <span class="n">ones</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="p">(</span><span class="n">ones</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span> <span class="o">*</span> <span class="bp">self</span><span class="p">)))</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;index_select&#39;</span><span class="p">):</span>
                    <span class="n">new_grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                    <span class="n">indices_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_select_indices</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                    <span class="n">grad_</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices_</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices_</span><span class="p">)):</span>
                        <span class="n">new_grad</span><span class="p">[</span><span class="n">indices_</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">grad_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">new_grad</span><span class="p">))</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;cross_entropy&#39;</span><span class="p">):</span>
                    <span class="n">dx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax_output</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_dist</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">dx</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">get_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Tanh</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="n">n_inputs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_outputs</span><span class="p">),</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="c1"># expand for broadcasting</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
        <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Embedding</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="c1"># this initialization style is a convention from word2vec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="n">dim</span><span class="p">,</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Cross Entropy Layer</span>
<span class="k">class</span> <span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SGD</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="n">parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        
    <span class="k">def</span> <span class="nf">zero</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span> <span class="o">*=</span> <span class="mi">0</span>
    
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">zero</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">zero</span><span class="p">):</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span> <span class="o">*=</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RNNCell</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span> <span class="o">=</span> <span class="n">n_inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_output</span> <span class="o">=</span> <span class="n">n_output</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">()</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">&#39;tanh&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">Tanh</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Non-Linearity not found&quot;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">w_ih</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_hh</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_ho</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_output</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_ih</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_hh</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_ho</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">from_prev_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_hh</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_ih</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">+</span> <span class="n">from_prev_hidden</span>
        <span class="n">new_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">combined</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_ho</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">new_hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">new_hidden</span>

    <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)),</span><span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Character-Language-Modeling">Character Language Modeling<a class="anchor-link" href="#Character-Language-Modeling">&#182;</a></h2><h3 id="Let's-tackle-a-more-challenging-task-with-RNN">Let's tackle a more challenging task with RNN<a class="anchor-link" href="#Let's-tackle-a-more-challenging-task-with-RNN">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>In this chapter, You'll attempt language modeling over a much more challenging dataset:<ul>
<li><strong>The Works of Shakespeare</strong></li>
</ul>
</li>
<li>Instead of learning to predict next words based on the previous sequence of words, now you'll learn how to predict characters.</li>
<li>So we are building a Character-based Language Model using the Works of Shakespeare:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;static/data/Shakespeare/shakespear.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">raw</span><span class="p">))</span>
<span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">):</span>
    <span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">word2index</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">raw</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embed</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RNNCell</span><span class="p">(</span><span class="n">n_inputs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_output</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">parameters</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span> <span class="o">+</span> <span class="n">embed</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We initialized the embeddings to be of dimensionality 8 and the hidden vector to be of size 512.</li>
<li>The Output weights are initialized to be of weight of 0s.</li>
<li>finally, we initialize the cross entropy loss function and the stochastic gradient optimizer.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Need-for-truncated-backpropagation">The Need for truncated backpropagation<a class="anchor-link" href="#The-Need-for-truncated-backpropagation">&#182;</a></h2><h3 id="Backpropagating-through-100,000-character-is-intractable">Backpropagating through 100,000 character is intractable<a class="anchor-link" href="#Backpropagating-through-100,000-character-is-intractable">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>One of the more challenging of reading RNN code is the mini-batching logic for feeding in data.</li>
<li>The previous RNN Setup had an inner loop of 5 words fed to the network to predict the sixth.</li>
<li>You might ask: "Why iterate to 5?"<ul>
<li>As it turns out, the previous dataset didn't have any example longer than 6 words.</li>
</ul>
</li>
<li>Even more important is the backpropagation step -&gt;<ul>
<li>in the case of MNIST, the gradients always backpropagated all the way through the network.</li>
</ul>
</li>
<li>The same logic applied to a vanilla RNN architecture, with a short loop, you can backpropagate all the way to the first input word.<ul>
<li>You can do this because you aren't feeding that many data points at a time.</li>
<li>But the shakespeare dataset has 100K characters.</li>
</ul>
</li>
<li>This is too many to backpropagate through, so what should we do?</li>
<li><strong>You don't!</strong>, you backpropagate for a fixed number of steps into the past and then stop.</li>
<li>This is called <strong>truncated backpropagation</strong>, and it's the industry standard.</li>
<li>The length you backpropagate becomes another tunable hyperparameter of the network, like batch size of alpha (learning rate).</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Truncated-Backpropagation">Truncated Backpropagation<a class="anchor-link" href="#Truncated-Backpropagation">&#182;</a></h2><h3 id="Technically,-It-weakens-the-theoritical-Maximum-of-the-neural-network">Technically, It weakens the theoritical Maximum of the neural network<a class="anchor-link" href="#Technically,-It-weakens-the-theoritical-Maximum-of-the-neural-network">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The downside of using truncated backpropagation is that it limits the memory of the neural network, meaning it shortens the distance a neural network can take to remember things.<ul>
<li>Cutting off gradients after, let's say five timesteps, meaning the neural network can't learn to remember events that are longer than five timesteps in the past.</li>
</ul>
</li>
<li>For language modeling, the truncation variable is called <code>bptt</code>, and it's usually set between 16 and 64:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">bptt</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># how far the model can look in the past â€” input sequence size?</span>
<span class="n">n_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">raw_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The other downside of truncated backpropagation is that it makes the internal mini-batching loop a bit more complex.</li>
<li>You pretend that instead of having one big dataset, you have a bunch of small datasets of <code>bptt</code> size.</li>
<li>You need to group the datasets accordingly:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trimmed_indices</span> <span class="o">=</span> <span class="n">raw_indices</span><span class="p">[:</span><span class="n">n_batches</span><span class="o">*</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">batched_indices</span> <span class="o">=</span> <span class="n">trimmed_indices</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">)</span>
<span class="n">batched_indices</span> <span class="o">=</span> <span class="n">batched_indices</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_batched_indices</span> <span class="o">=</span> <span class="n">batched_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">output_batched_indices</span> <span class="o">=</span> <span class="n">batched_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_bptt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">bptt</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_batches</span> <span class="o">=</span> <span class="n">input_batched_indices</span><span class="p">[:</span><span class="n">n_bptt</span><span class="o">*</span><span class="n">bptt</span><span class="p">]</span>
<span class="n">input_batches</span> <span class="o">=</span> <span class="n">input_batches</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_bptt</span><span class="p">,</span> <span class="n">bptt</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">output_batches</span> <span class="o">=</span> <span class="n">output_batched_indices</span><span class="p">[:</span><span class="n">n_bptt</span><span class="o">*</span><span class="n">bptt</span><span class="p">]</span>
<span class="n">output_batches</span> <span class="o">=</span> <span class="n">output_batches</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_bptt</span><span class="p">,</span> <span class="n">bptt</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">min_loss</span> <span class="o">=</span> <span class="mi">1000</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The Top Line Makes the Dataset an even multiple between <code>batch_size</code> and <code>n_batches</code>.</li>
<li>The Second and third lines reshape the dataset so that each column is a section of the initial <code>indices</code> array.</li>
<li>If <code>batch_size</code> was set to 8:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">raw</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">raw_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>That,
[32 59 31 19 49]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Those are the Five Basic Characters in the Shakespeare Dataset.</li>
<li>Following are the first 5 rows of the output of the transformation combined within <code>batched_indices</code>:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">batched_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[32 30 58 16 25 59 32 48 48 31 31 11 25 48 49 22 48 51 59 58 11 31 48 48
  48 50 48 50 50 48 48  6]
 [59 22 22 16 57 11 31 24 51  6 27 11 27 19 48 22 44 25 25 22 27 36 44 13
  59  6 43 10  6 10 42 48]
 [31 22 60 11 11 31 27 55 25 48 27 58 13 59 33 45 11 24 27 22 13 11  5 11
  11  9 25 49 48 25 25 44]
 [19  4 32  5 48  5 44 48 24  6 48 48 30 11 11  2 11 49 51 34 55 48 25 11
   5 27 24 22  0  5 10 25]
 [49  2 50 60 33 48 25  5 48 25 33  7 22 48 48 46  6 48 48 25 30 51 33 57
  49 31 27  2 24 11 11 51]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>See how the indices for the phrase "That," are in the first column on the left?<ul>
<li>This is a standard construction.</li>
</ul>
</li>
<li>The reason there are N columns is because the batch size is N.</li>
<li>This tensor is then used to construct a list of smaller data sets, each with length bptt.</li>
<li>Notice that the target indices are the input indices offten by one row (so that the network predicts the next character):</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">input_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[32 30 58 16 25 59 32 48 48 31 31 11 25 48 49 22 48 51 59 58 11 31 48 48
  48 50 48 50 50 48 48  6]
 [59 22 22 16 57 11 31 24 51  6 27 11 27 19 48 22 44 25 25 22 27 36 44 13
  59  6 43 10  6 10 42 48]
 [31 22 60 11 11 31 27 55 25 48 27 58 13 59 33 45 11 24 27 22 13 11  5 11
  11  9 25 49 48 25 25 44]
 [19  4 32  5 48  5 44 48 24  6 48 48 30 11 11  2 11 49 51 34 55 48 25 11
   5 27 24 22  0  5 10 25]
 [49  2 50 60 33 48 25  5 48 25 33  7 22 48 48 46  6 48 48 25 30 51 33 57
  49 31 27  2 24 11 11 51]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[59 22 22 16 57 11 31 24 51  6 27 11 27 19 48 22 44 25 25 22 27 36 44 13
  59  6 43 10  6 10 42 48]
 [31 22 60 11 11 31 27 55 25 48 27 58 13 59 33 45 11 24 27 22 13 11  5 11
  11  9 25 49 48 25 25 44]
 [19  4 32  5 48  5 44 48 24  6 48 48 30 11 11  2 11 49 51 34 55 48 25 11
   5 27 24 22  0  5 10 25]
 [49  2 50 60 33 48 25  5 48 25 33  7 22 48 48 46  6 48 48 25 30 51 33 57
  49 31 27  2 24 11 11 51]
 [48 39 55 13 50 11 19 11 33 48 11 59 22 13 33 18 48 10 44 55 22 25 48 48
  48 33 13  6 16 48 49 55]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>This type of preprocessing technique doesn't have much to do with deep learning theory.</li>
<li>It's just a particularly complex part of setting up RNNs that you'll run into from time to time.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Let's-see-how-to-iterate-using-truncated-backpropagation">Let's see how to iterate using truncated backpropagation<a class="anchor-link" href="#Let's-see-how-to-iterate-using-truncated-backpropagation">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The following example shows truncated backpropagation in practice.</li>
<li>The only difference is that you generate a batch_loss at each step</li>
<li>After every bptt steps, you backpropagate and perform a weight update.</li>
<li>then you keep reading through the dataset like nothing happened<ul>
<li>using the hidden state from before.</li>
<li>the hidden state only gets a reset with each epoch.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">generate_sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">init_char</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">word2index</span><span class="p">[</span><span class="n">init_char</span><span class="p">]]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">rnn_input</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">rnn_input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="c1"># temperature for sampling, higher -&gt; greedier</span>
        <span class="n">output</span><span class="o">.</span><span class="n">data</span> <span class="o">*=</span> <span class="mi">10</span>
        <span class="n">temp_dist</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">softmax</span><span class="p">()</span>
        <span class="n">temp_dist</span> <span class="o">/=</span> <span class="n">temp_dist</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        
        <span class="c1"># samples from pred</span>
        <span class="n">m</span> <span class="o">=</span> <span class="p">(</span><span class="n">temp_dist</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">m</span><span class="p">]</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">m</span><span class="p">]))</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">c</span>
    <span class="k">return</span> <span class="n">s</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">iterations</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">min_loss</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">n_loss</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_batches</span><span class="p">)):</span>
            
            <span class="n">hidden</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">hidden</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bptt</span><span class="p">):</span>
                <span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_batches</span><span class="p">[</span><span class="n">batch_i</span><span class="p">][</span><span class="n">t</span><span class="p">],</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">rnn_input</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
                <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">rnn_input</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="n">hidden</span><span class="p">)</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">output_batches</span><span class="p">[</span><span class="n">batch_i</span><span class="p">][</span><span class="n">t</span><span class="p">],</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">batch_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
                <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">batch_loss</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">batch_loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="o">/</span><span class="n">bptt</span>
                
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">batch_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">epoch_loss</span> <span class="o">&lt;</span> <span class="n">min_loss</span><span class="p">):</span>
                <span class="n">min_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span>
            <span class="n">log</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\r</span><span class="s2"> Iter:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">iter</span><span class="p">)</span>
            <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - Alpha:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">alpha</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
            <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - Batch &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">batch_i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_batches</span><span class="p">))</span>
            <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - Min Loss:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">min_loss</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
            <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - Loss:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">batch_i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - &quot;</span> <span class="o">+</span> <span class="n">generate_sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">init_char</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">batch_i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">log</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*=</span> <span class="mf">0.99</span> 
        <span class="nb">print</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> Iter:0 - Alpha:0.05 - Batch 191/195 - Min Loss:1.324 - Loss:1.3867314989794643
 Iter:1 - Alpha:0.049 - Batch 191/195 - Min Loss:1.201 - Loss:1.2161565398772538
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-Sample-of-the-Output">A Sample of the Output<a class="anchor-link" href="#A-Sample-of-the-Output">&#182;</a></h2><h3 id="By-sampling-from-the-Predictions-of-the-Model,-you-can-write-Shakespeare!">By sampling from the Predictions of the Model, you can write Shakespeare!<a class="anchor-link" href="#By-sampling-from-the-Predictions-of-the-Model,-you-can-write-Shakespeare!">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The following code uses a subset of the training logic to make predictions using the model.</li>
<li>You store the predictions in a string and return the string version as output of the function.</li>
<li>The sample that's generated looks quite shakespearnian and even includes characters talking:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">generate_sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">init_char</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
at hSe whe whe whe whe She whe whe whe whe whe She whe whe whe whe the whe whe the whe whe whe whe whe whe whe whe whe whe whe whe whe whe SS whe She whe whe whe whe She whe whe whe She whe whe whe whe She whe whe She whe whe whe Se whe whe whe whe whe whe whe She whe She whe whe the She whe She whe whe whe whe whe whe whe whe She SS She whe whe whe whe whe whe whe whe She whe She She whe whe whe whe whe She whe whe whe whe whe whe whe whe whe whe whe whe whe whe She She whe She whe whe whe whe She She whe whe She whe whe She whe whe whe whe She whe whe She whe whe whe whe whe whe whe whe She whe whe whe the whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe She She whe whe whe whe whe whe She whe whe whe whe whe whe whe She She whe whe whe whe whe She She whe whe whe She whe whe whe whe whe whe whe whe whe whe whe She whe She whe whe whe She whe whe whe whe whe She whe whe whe whe whe whe whe whe whe whe whe She whe whe She whe whe She whe whe whe whe whe She She whe whe She whe whe whe She whe She whe whe whe whe whe whe She whe whe whe She we whe whe whe whe whe whe whe She whe whe whe whe She whe whe whe whe whe whe whe She whe whe whe whe whe whe whe whe SS She She whe whe whe whe whe She whe whe whe whe whe whe whe She whe whe whe whe whe She whe whe whe whe whe whe whe She whe whe She whe whe whe whe She She whe we whe whe whe whe whe whe whe whe She whe whe whe Se whe whe whe whe whe She whe whe whe whe whe whe whe whe She whe She whe whe She whe whe whe She whe whe whe whe whe whe She whe whe whe She the whe whe whe whe She SS whe whe whe whe whe whe whe whe whe She whe whe She whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe She She whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe She She whe whe whe whe whe whe whe whe whe whe whe whe She She whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe whe She whe whe whe whe whe whe whe whe whe 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Vanishing-&amp;-Exploding-Gradients">Vanishing &amp; Exploding Gradients<a class="anchor-link" href="#Vanishing-&amp;-Exploding-Gradients">&#182;</a></h2><h3 id="Vanilla-RNNs-Suffer-from-Vanishing-&amp;-Exploding-Gradients">Vanilla RNNs Suffer from Vanishing &amp; Exploding Gradients<a class="anchor-link" href="#Vanilla-RNNs-Suffer-from-Vanishing-&amp;-Exploding-Gradients">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The whole idea was to be able to combine the word embeddings in a way that order mattered.</li>
<li>You did this by learning a matrix that transforms the vector representation of all of the previous embeddings into the next time step.</li>
<li>Forward Propagation then became a 2-step process:<ul>
<li><strong>Start with the first word embedding</strong>.</li>
<li><strong>Multiply it by the shared weight matrix</strong>.</li>
<li><strong>Add the Next Embedding</strong>.</li>
</ul>
</li>
<li>&amp; you loop over this process, repeating until you've read the entire series of words.</li>
<li>An additional non-linearity was added to the hidden-state generation process.</li>
<li>Thus, forward propagation becomes a 3-step process, applying the activation function was added.</li>
<li>This non-linearity plays an important role in stabalizing the network.<ul>
<li>Meaning, no matter how long the sequence of words is, the hidden states are forced to stay between the values of the non-linearity.</li>
</ul>
</li>
<li><strong>But backpropagation happens in a slightly different way than forward propagation</strong>.<ul>
<li>Which doesn't have this nice property.</li>
<li>Backpropagation tends to lead to either extremely large or extremely small values.<ul>
<li>Large values can cause divergence (NaNs).</li>
<li>&amp; Extremely small values keep the netword from learning (small updates).</li>
</ul>
</li>
</ul>
</li>
<li>Let's take a closer look at RNNs backpropagation:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-Toy-Example-of-RNN-backpropagation">A Toy Example of RNN backpropagation<a class="anchor-link" href="#A-Toy-Example-of-RNN-backpropagation">&#182;</a></h2><h3 id="To-see-vanishing/exploding-gradients-firsthand,-Let's-synthesize-an-Example">To see vanishing/exploding gradients firsthand, Let's synthesize an Example<a class="anchor-link" href="#To-see-vanishing/exploding-gradients-firsthand,-Let's-synthesize-an-Example">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The following example shows a recurrent backpropagation loop for <code>sigmoid</code> and <code>relu</code> activations.</li>
<li>During Backprop:<ul>
<li>ReLU: Gradients become Large as a result of matrix Multiplication.</li>
<li>Sigmoid: Gradients become small as a result of the slope of the sigmoid curvature in much of its domain of definition (flat tails).</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">sigmoid</span><span class="p">,</span> <span class="n">relu</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)),</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">activation</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sigmoid-Activations">Sigmoid Activations<a class="anchor-link" href="#Sigmoid-Activations">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">activations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">activation</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">activation</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
    <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[0.93940638 0.96852968]
[0.9919462  0.99121735]
[0.99301385 0.99302901]
[0.9930713  0.99307098]
[0.99307285 0.99307285]
[0.99307291 0.99307291]
[0.99307291 0.99307291]
[0.99307291 0.99307291]
[0.99307291 0.99307291]
[0.99307291 0.99307291]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sigmoid-Gradients">Sigmoid Gradients<a class="anchor-link" href="#Sigmoid-Gradients">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">activations</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">activation</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">activations</span><span class="p">):</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="n">activation</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">activation</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradient</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="n">gradient</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">gradient</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[0.03439552 0.03439552]
 [0.03439552 0.03439552]
 [0.03439552 0.03439552]
 [0.03439552 0.03439552]
 [0.03439552 0.03439552]
 [0.03439552 0.03439552]
 [0.03439552 0.03439552]
 [0.03439552 0.03439552]
 [0.03439552 0.03439552]
 [0.03439552 0.03439552]]
[[0.00118305 0.00118305]
 [0.00118305 0.00118305]
 [0.00118305 0.00118305]
 [0.00118305 0.00118305]
 [0.00118305 0.00118305]
 [0.00118305 0.00118305]
 [0.00118305 0.00118305]
 [0.00118305 0.00118305]
 [0.00118305 0.00118305]
 [0.00118305 0.00118305]]
[[4.06916726e-05 4.06916726e-05]
 [4.06916726e-05 4.06916726e-05]
 [4.06916726e-05 4.06916726e-05]
 [4.06916726e-05 4.06916726e-05]
 [4.06916726e-05 4.06916726e-05]
 [4.06916726e-05 4.06916726e-05]
 [4.06916726e-05 4.06916726e-05]
 [4.06916726e-05 4.06916726e-05]
 [4.06916726e-05 4.06916726e-05]
 [4.06916726e-05 4.06916726e-05]]
[[1.39961115e-06 1.39961115e-06]
 [1.39961115e-06 1.39961115e-06]
 [1.39961115e-06 1.39961115e-06]
 [1.39961115e-06 1.39961115e-06]
 [1.39961115e-06 1.39961115e-06]
 [1.39961115e-06 1.39961115e-06]
 [1.39961115e-06 1.39961115e-06]
 [1.39961115e-06 1.39961115e-06]
 [1.39961115e-06 1.39961115e-06]
 [1.39961115e-06 1.39961115e-06]]
[[4.81403643e-08 4.81403637e-08]
 [4.81403643e-08 4.81403637e-08]
 [4.81403643e-08 4.81403637e-08]
 [4.81403643e-08 4.81403637e-08]
 [4.81403643e-08 4.81403637e-08]
 [4.81403643e-08 4.81403637e-08]
 [4.81403643e-08 4.81403637e-08]
 [4.81403643e-08 4.81403637e-08]
 [4.81403643e-08 4.81403637e-08]
 [4.81403643e-08 4.81403637e-08]]
[[1.65582672e-09 1.65582765e-09]
 [1.65582672e-09 1.65582765e-09]
 [1.65582672e-09 1.65582765e-09]
 [1.65582672e-09 1.65582765e-09]
 [1.65582672e-09 1.65582765e-09]
 [1.65582672e-09 1.65582765e-09]
 [1.65582672e-09 1.65582765e-09]
 [1.65582672e-09 1.65582765e-09]
 [1.65582672e-09 1.65582765e-09]
 [1.65582672e-09 1.65582765e-09]]
[[5.69682675e-11 5.69667160e-11]
 [5.69682675e-11 5.69667160e-11]
 [5.69682675e-11 5.69667160e-11]
 [5.69682675e-11 5.69667160e-11]
 [5.69682675e-11 5.69667160e-11]
 [5.69682675e-11 5.69667160e-11]
 [5.69682675e-11 5.69667160e-11]
 [5.69682675e-11 5.69667160e-11]
 [5.69682675e-11 5.69667160e-11]
 [5.69682675e-11 5.69667160e-11]]
[[1.97259346e-12 1.97517920e-12]
 [1.97259346e-12 1.97517920e-12]
 [1.97259346e-12 1.97517920e-12]
 [1.97259346e-12 1.97517920e-12]
 [1.97259346e-12 1.97517920e-12]
 [1.97259346e-12 1.97517920e-12]
 [1.97259346e-12 1.97517920e-12]
 [1.97259346e-12 1.97517920e-12]
 [1.97259346e-12 1.97517920e-12]
 [1.97259346e-12 1.97517920e-12]]
[[8.45387597e-14 8.02306381e-14]
 [8.45387597e-14 8.02306381e-14]
 [8.45387597e-14 8.02306381e-14]
 [8.45387597e-14 8.02306381e-14]
 [8.45387597e-14 8.02306381e-14]
 [8.45387597e-14 8.02306381e-14]
 [8.45387597e-14 8.02306381e-14]
 [8.45387597e-14 8.02306381e-14]
 [8.45387597e-14 8.02306381e-14]
 [8.45387597e-14 8.02306381e-14]]
[[1.45938177e-14 2.16938983e-14]
 [1.45938177e-14 2.16938983e-14]
 [1.45938177e-14 2.16938983e-14]
 [1.45938177e-14 2.16938983e-14]
 [1.45938177e-14 2.16938983e-14]
 [1.45938177e-14 2.16938983e-14]
 [1.45938177e-14 2.16938983e-14]
 [1.45938177e-14 2.16938983e-14]
 [1.45938177e-14 2.16938983e-14]
 [1.45938177e-14 2.16938983e-14]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ReLU-Activations">ReLU Activations<a class="anchor-link" href="#ReLU-Activations">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">activations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">activation</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">activation</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
    <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[4.8135251  4.72615519]
[23.71814585 23.98025559]
[119.63916823 118.852839  ]
[595.05052421 597.40951192]
[2984.68857188 2977.61160877]
[14895.13500696 14916.36589628]
[74560.59859209 74496.90592414]
[372548.22228863 372739.30029248]
[1863505.42345854 1862932.18944699]
[9315234.18124649 9316953.88328115]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ReLU-Gradients">ReLU Gradients<a class="anchor-link" href="#ReLU-Gradients">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">activation</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">activations</span><span class="p">):</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="p">((</span><span class="n">activation</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradient</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">gradient</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[5. 5.]
[25. 25.]
[125. 125.]
[625. 625.]
[3125. 3125.]
[15625. 15625.]
[78125. 78125.]
[390625. 390625.]
[1953125. 1953125.]
[9765625. 9765625.]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Long-short-term-Memory-(LSTM)-Cells">Long short-term Memory (LSTM) Cells<a class="anchor-link" href="#Long-short-term-Memory-(LSTM)-Cells">&#182;</a></h2><h3 id="LSTMs-are-the-industry-standard-model-to-counter-vanishing/exploding-gradients">LSTMs are the industry standard model to counter vanishing/exploding gradients<a class="anchor-link" href="#LSTMs-are-the-industry-standard-model-to-counter-vanishing/exploding-gradients">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The problem with vanishing (sigmoid) / exploding (matrix multiplication) is the combination of matrix multiplication and non-linearity being used to form the next hidden state.</li>
<li>The Solution that LSTMs provide is quite simple:<ul>
<li><strong>The Gated Copy Trick</strong><ul>
<li><strong>LSTMs create the next hidden state by copying the previous hidden state and then adding or removing information as necessary.</strong></li>
<li><strong>The mechanisms the LSTM uses for adding &amp; removing information are called gates</strong>.</li>
</ul>
</li>
</ul>
</li>
<li>The LSTM has 2 hidden state vectors:<ul>
<li><strong>h</strong>: for hidden.</li>
<li><strong>cell</strong>.</li>
</ul>
</li>
<li>The one you care about is cell.</li>
<li><strong>Each new cell is the previous cell + u</strong>.<ul>
<li>weighted by i and f.<ul>
<li><strong>f</strong> is the forget gate.<ul>
<li>If it takes a value of <strong>0</strong> the next cell will erase what it saw previously.</li>
</ul>
</li>
<li>If i is 1, It will fully add in the value of u to create the new cell.</li>
<li>o is an output gate that controls how much of the cells state the output prediction is allowed to see.</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
    <span class="n">prev_hidden</span><span class="p">,</span> <span class="n">prev_cell</span> <span class="o">=</span> <span class="p">(</span><span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xf</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">hf</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">prev_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>  <span class="c1"># forget gate</span>
    <span class="n">i</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">hi</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">prev_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
    <span class="n">o</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xo</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ho</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">prev_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>  <span class="c1"># output gate</span>
    <span class="n">u</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xc</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">prev_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
    
    <span class="n">cell</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span> <span class="o">*</span> <span class="n">prev_cell</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">u</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">o</span> <span class="o">*</span> <span class="n">cell</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_ho</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%" file="static/imgs/14/LSTM_cell.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>There are 3 gates, f, i, o. &amp; a cell update vector u.</li>
<li><strong>Think of these as forget, Input, Output, and Update.</strong></li>
<li>They work together to ensure that any information to be stored in $c$ can be so without requiring each update of $c$ to have any matrix multiplications or non-linearities applied to it.</li>
<li>In Other words, <strong>you're avoiding ever calling nonlinearity(c) or c.dot(weights)</strong>.</li>
<li>This is what allows the LSTM to store Information across a time series without worrying about vanishing or exploding gradients.<ul>
<li><strong>Each Step is a Copy plus an Update.</strong></li>
</ul>
</li>
<li>The hidden value $h$ is then a masked version of the cell that's used for prediction.</li>
<li>Each gate has its own weight matrices.</li>
<li>One last possible critique is about $h$.<ul>
<li>Clearly it's still prone to vanishing &amp; exploding gradients.</li>
<li><strong>Exploding gradients aren't really a problem, Only vanishing gradients.</strong></li>
<li>But this ends up being Okay because h is conditioned on c, which can carry long range information.</li>
<li>The kind of information vanishing gradients can't learn to carry.</li>
</ul>
</li>
<li><strong>All long range information is transported using c</strong>.<ul>
<li>and h is only a localized interpretaion of c</li>
</ul>
</li>
<li>In short, <strong>c can learn to transport information over long distances, so it doesn't matter if h can't.</strong></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Long-Short-term-Memory-Layer">The Long-Short term Memory Layer<a class="anchor-link" href="#The-Long-Short-term-Memory-Layer">&#182;</a></h2><h3 id="You-can-use-the-Autograd-system-to-implement-an-LSTM">You can use the Autograd system to implement an LSTM<a class="anchor-link" href="#You-can-use-the-Autograd-system-to-implement-an-LSTM">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">LSTMCell</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_output</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span> <span class="o">=</span> <span class="n">n_inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="n">n_output</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">xf</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xi</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xo</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xc</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">hf</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hi</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ho</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hc</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">w_ho</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xf</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xo</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xc</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hf</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hi</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ho</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_ho</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">prev_hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">prev_cell</span> <span class="o">=</span> <span class="n">hidden</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">f</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xf</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">hf</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">prev_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
        <span class="n">i</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xi</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">hi</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">prev_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
        <span class="n">o</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xo</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">ho</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">prev_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
        <span class="n">g</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xc</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">hc</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">prev_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
        <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span> <span class="o">*</span> <span class="n">prev_cell</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">g</span><span class="p">)</span> 
        <span class="n">h</span> <span class="o">=</span> <span class="n">o</span> <span class="o">*</span> <span class="n">c</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
        
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_ho</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)),</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)),</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">h</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">c</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Upgrading-the-Character-Language-Model">Upgrading the Character Language Model<a class="anchor-link" href="#Upgrading-the-Character-Language-Model">&#182;</a></h2><h3 id="Let's-Swap-out-the-Vanilla-RNN-with-the-new-LSTMCell">Let's Swap out the Vanilla RNN with the new LSTMCell<a class="anchor-link" href="#Let's-Swap-out-the-Vanilla-RNN-with-the-new-LSTMCell">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Let's train an LSTM-based Model to predict Shakespeare.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;static/data/Shakespeare/shakespear.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">raw</span><span class="p">))</span>
<span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">):</span>
    <span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">word2index</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">raw</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embed</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LSTMCell</span><span class="p">(</span><span class="n">n_inputs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">n_output</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">parameters</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span> <span class="o">+</span> <span class="n">embed</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">bptt</span> <span class="o">=</span> <span class="mi">25</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">raw_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trimmed_indices</span> <span class="o">=</span> <span class="n">raw_indices</span><span class="p">[:</span><span class="n">n_batches</span><span class="o">*</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">batched_indices</span> <span class="o">=</span> <span class="n">trimmed_indices</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">)</span>
<span class="n">batched_indices</span> <span class="o">=</span> <span class="n">batched_indices</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_batched_indices</span> <span class="o">=</span> <span class="n">batched_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">output_batched_indices</span> <span class="o">=</span> <span class="n">batched_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_bptt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">bptt</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_batches</span> <span class="o">=</span> <span class="n">input_batched_indices</span><span class="p">[:</span><span class="n">n_bptt</span><span class="o">*</span><span class="n">bptt</span><span class="p">]</span>
<span class="n">input_batches</span> <span class="o">=</span> <span class="n">input_batches</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_bptt</span><span class="p">,</span> <span class="n">bptt</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">output_batches</span> <span class="o">=</span> <span class="n">output_batched_indices</span><span class="p">[:</span><span class="n">n_bptt</span><span class="o">*</span><span class="n">bptt</span><span class="p">]</span>
<span class="n">output_batches</span> <span class="o">=</span> <span class="n">output_batches</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_bptt</span><span class="p">,</span> <span class="n">bptt</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">min_loss</span> <span class="o">=</span> <span class="mi">1000</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-the-LSTM-character-Language-Model">Training the LSTM character Language Model<a class="anchor-link" href="#Training-the-LSTM-character-Language-Model">&#182;</a></h2><h3 id="The-training-Logic-also-hasn't-changed-much">The training Logic also hasn't changed much<a class="anchor-link" href="#The-training-Logic-also-hasn't-changed-much">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The only real change you have to make from the vanilla RNN logic is the truncated backpropagation logic.<ul>
<li>Because there are two hidden vectors per timestep instead of one.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">iterations</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">min_loss</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">n_loss</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_batches</span><span class="p">)):</span>
            
            <span class="n">hidden</span> <span class="o">=</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                      <span class="n">Tensor</span><span class="p">(</span><span class="n">hidden</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            
            <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bptt</span><span class="p">):</span>
                <span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_batches</span><span class="p">[</span><span class="n">batch_i</span><span class="p">][</span><span class="n">t</span><span class="p">],</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">rnn_input</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
                <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">rnn_input</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="n">hidden</span><span class="p">)</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">output_batches</span><span class="p">[</span><span class="n">batch_i</span><span class="p">][</span><span class="n">t</span><span class="p">],</span> <span class="n">autograd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">batch_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
                <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">batch_loss</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">batch_loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="o">/</span><span class="n">bptt</span>
                
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">batch_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">epoch_loss</span> <span class="o">&lt;</span> <span class="n">min_loss</span><span class="p">):</span>
                <span class="n">min_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span>
            <span class="n">log</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\r</span><span class="s2"> Iter:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">iter</span><span class="p">)</span>
            <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - Alpha:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">alpha</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
            <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - Batch &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">batch_i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_batches</span><span class="p">))</span>
            <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - Min Loss:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">min_loss</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
            <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - Loss:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">batch_i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; - &quot;</span> <span class="o">+</span> <span class="n">generate_sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">init_char</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">batch_i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">log</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*=</span> <span class="mf">0.99</span> 
        <span class="nb">print</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tuning-the-LSTM-character-language-model">Tuning the LSTM character language model<a class="anchor-link" href="#Tuning-the-LSTM-character-language-model">&#182;</a></h2><h3 id="I-spent-two-days-tuning-this-model,-&amp;-It-trained-overnight">I spent two days tuning this model, &amp; It trained overnight<a class="anchor-link" href="#I-spent-two-days-tuning-this-model,-&amp;-It-trained-overnight">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:75%;" file="static/imgs/14/generated_sample.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h2><h3 id="LSTMs-are-incredibly-powerful-Models.">LSTMs are incredibly powerful Models.<a class="anchor-link" href="#LSTMs-are-incredibly-powerful-Models.">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Language is an incredibly complex statistical distribution to learn, and the fact that LSTMs can do so well, still baffles me.</li>
<li>Small variants of this model either are or have recently been the state of the art in a wide variety of tasks.</li>
</ul>

</div>
</div>
</div>
</div>
 

