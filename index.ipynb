{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebooks â€” Grokking Deep Learning by Andrew W. Trask\n",
    "> https://www.manning.com/books/grokking-deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img style=\"width:100%\" src=\"static/imgs/Cover.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grokking Deep Learning was written to help **give you a foundation in deep learning** so that you can **master a major deep learning framework**.\n",
    "   - Requires no math background beyond basic arithmetic.\n",
    "   - Doesn't rely on a high-level library that might hide what's going on.\n",
    "   - Anyone can read this book and understand how deep learning really works.\n",
    "   - You won't just read the theory, you'll discover it yourself.\n",
    "\n",
    "> (You can Buy the Book from [Manning Publications](https://www.manning.com/books/grokking-deep-learning) or [Amazon](https://www.amazon.com/Grokking-Deep-Learning-Andrew-Trask/dp/1617293709))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap\n",
    "\n",
    "\"Grokking Deep Learning\" has 16 Chapters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introducing Deep Learning: Why you should Learn It?\n",
    "2. fundamental Concepts: How Do Machines Learn?\n",
    "3. [Introduction to Neural Learning](03.forward_propagation.ipynb): Forward Propagation\n",
    "4. [Introduction to Neural Learning](04.gradient_descent.ipynb): Gradient Descent\n",
    "5. [Learning Multiple Weights at a Time](05.Generalizing_GD.ipynb): Generalizing Gradient Descent\n",
    "6. [Building your first deep neural network](06.Back_propagation.ipynb): Introduction to Backpropagation\n",
    "7. How to Picture Neural Networks: In your Head & on Paper\n",
    "8. [Learning Signal & Ignoring Noise](08.Regularization_Batching.ipynb): Introduction to Regularization & Batching\n",
    "9. [Modeling Probabilities & Non-Linearities](09.Probabilities_Non-Linearities.ipynb): Activation Functions\n",
    "10. [Neural Learning about Edges & Corners](10.Intro_to_CNNs.ipynb): Introduction to Convolutional Neural Networks\n",
    "11. [Neural Networks that Understand Language](11.NNs_that_Understand_Language.ipynb): King - Man + Woman == ?\n",
    "12. [Neural Networks that write like Shakespeare](12.RNNs.ipynb): Recurrent Layers for Variable Length Data\n",
    "13. [Introducing Automatic Optimization](13.DL_framework.ipynb): Let's build a deep learning framework\n",
    "14. [Learning to Write like Shakespeare](14.LSTMs_LM.ipynb): Long Short-term Memory\n",
    "15. Deep Learning on Unseen Data: Introducing Federated Learning\n",
    "16. Where to Go from Here: A brief Guide\n",
    "\n",
    "> Missing Notebooks are mostly based on original content from the Book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
